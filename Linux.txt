http://ru.opensuse.org/VirtualBox
HAL (Hardware Abstraction Level) - слой абстрагирования (нужен для того чтобы ОС могла работать с любым железом)
dbus - шина по которой интерфейс ОС общался с HAL
udev - менеджер устройств linux (похож на plug in play) м. динамически удалять и устанавливать у-ва
|- знак пайплайн Pipeline
Кирилл Семаев : или вот понятней ссылка: http://inflin.narod.ru/lin/lin13.htm  (но верхняя подробней)
manage-bde X: -lock
manage-bde X: -unlock –password
Кирилл Семаев : Конфигурация компьютера\Административные шабло-ны\Компоненты Windows\Шифрование диска BitLocker.
Выделите элемент «Диски операционной системы» и дважды щелкните на политике «Требовать дополнительной аутентификации при запуске» (Require Additional Authentication at Startup). Настраиваем его (allow bitlocker without compatible TPM)
Cipher /E C:\Test.txt
Cipher /D C:\Test.txt
clear или ctrl+l очистка экрана
в SysV посмотреть список служб/сервисов:
service --status-all
в SystemD просмотреть список служб с их статусом:
systemctl list-unit-files
в SystemD sysпросмотр сервисов запущенных в текущий момент:
systemctl list-units -t service
отключение | включение запуска сервиса при загрузке (автозагрузка служб):
sudo systemctl [disable | enable] имя_демона
проверить включен ли сервис в автозагрузку:
systemctl is-enabled имя_демона
просмотр сервисов остановленных в аварийном режиме:
systemctl list-units -t service --failed
uptime - как долго запущена система
папка lost+found создается на томах диска
ctrl+alt+t запуск терминала в граф. среде
обновит информацию о пакетах (кэш), содержащихся в репозиториях, чтобы в процессе обновления получить самые последние версии пакетов:
apt-get update
#существует 2 варианта обновления: dist-upgrade и upgrade. Предпочтительнее первый вариант.При конфликтах пакетов Ubuntu попытается обновите наиболее важные пакеты за счет менее важных.
Поэтому команда dist-upgrade может установить дополнительные пакеты или удалить один из конфликтующих пакетов:
apt-get dist-upgrade
apt-cache search делаем поиск пакета связанный с названием
apt-cache dpkg apache2 смотрим информацию (возможные версии, и адреса и названия пакетов) по apache2 
чтобы заблокировать обновление определенного пакета (программы) в Ubuntu:
sudo echo 'имя_пакета hold' | sudo dpkg --set-selections
#имя пакета берется из команды, которой вы ставили этот пакет:
#sudo apt-get install имя_пакета
или
apt-mark hold package_name
или
aptitude hold package_name
данной командой можно просмотреть все статусы пакетов в системе
(выведется весь список установленных пакетов и можно просмотреть у которых стоит статус hold - то есть заблокированы для обновления):
dpkg --get-selections
Данной командой можно просмотреть статус определенного пакета:
dpkg --get-selections | grep 'имя_пакета'
чтобы разблокировать обновление пакета:
apt-mark unhold package_name
или
aptitude unhold package_name
еще просмотреть информацию об установленном пакете можно:
dpkg -s <имя_пакета>
чтобы просмотреть используемые пакетом файлы:
dpkg -L <имя_пакета>
покажет все установленные приложения. После команды —get-selections можно указать критерий отбора:
dpkg --get-selections dev* | less
pcmci - плата расширения для ноутбуков
корректная деинсталяция пакета со всеми установленными зависимостями:
sudo apt-get autoremove имя_программы
#на образе srvweb деинсталлировать пакет libapache2-mod-security2
#sudo apt-get autoremove libapache2-mod-security2
#попутно удаляет modsecurity-crs, libyajl2, libapache2-mod-security2, lublua5.1-0
что бы наверняка удалить все что было установлено вместе с пакетом, можно посмотреть лог apt:
cat /var/log/apt/history.log | more #покажет какие дополнительные пакеты были установлены вместе с основной установкой пакета

РАБОТА С ЖЕЛЕЗОМ
================

HAL - программная прослойка представляющая абстракцию железа для ОС (использовалась раньше)
Dbus - программная шина, кот-я позволяет процессам обмениваться инф-ей м/у собой (позв. получить инф-ю об оборудовании от ядра и передать ее для ПО)
#через Dbus софт работает с хардом
UDEV - менеджер устройств (современный аналог HAL)
#работает на уровне пол-ля, управляется событиями (включение/отключение у-ва, сохраняет имена у-в при переподключении)
вывести список модулей ядра (программный объект код которого расширяет ф-ционал ядра):
#вывод драйверов и пакетов расширений
lsmod
вывести инф-ю о модуле e1000 (показывал в lsmod, явл-ся драйвером сет.карты):
покажет всю инфу о сет.карте
удалим драйвер сет.карты:
rmmod e1000
мягкая установка модуля ядра e1000:
modprobe e1000
посмотреть инф-ю о шине pci:
lspci
чтобы узнать все выполняемые команды ls:
ls <tab>
чтобы посмотреть устр-ва usb, а также корневые хабы шин usb:
lsusb
если не установлена установить пакет usbutils
apt-get install usbutils

Devfs - виртуальная ф-ловая система находится в ОЗУ и монтируется в директорию /dev (туда записываются ф-лы устройств)(раньше сама devfs создавала это каталог, сейчас это делает udev)
#содержит те ф-лы, при помощи которых м. обращаться непосредственно к у-вам
содержит директории:
	mem - слепок оперативной памяти (образ)
	null - пустое у-во (в него всегда происходит запись, вне зависимости от объема и он всегда возвращает "успех")
	#используем его, если что-то хотим отправить в мусор (лишний вывод ПО, ошибки программы) (если это отправить в dev/null оно там исчезнет)
	random,	urandom - символьные псевдоустройства (генераторы случайных чисел, дают интерфейс к системному генератору случ.чисел)
	tty - аппаратный терминал (teletype)
	pts - псевдотерминал
	sdx - блочные у-ва (носители инф-ии sda,sdb..)
запустим команду htop и удалим весь вывод, отправив в пустое у-во, туда же отправим все ошибки:
#допустим, если мы хотим в скриптах не видеть предупреждения, при этом мы не получаем к-либо ошибки
htop > /dev/null 2>&1
получим 1-ю строчку с устройства dev/urandom и отправим эту инф-ю в домаш. директорию, в ф-л test:
head -l /dev/urandom > ~/test
#запишет случ. строчку, случ. длины, со случ. байтами
Sysfs - виртуальная ф-ловая система выводит на уровень пол-ля инф-ю от ядра Linux о присутствующих в системе ус-в и драйверах
(сейчас явл. частью udev)
содержит директории:
#содержит ф-лы, которые предоставляют инф-ю об у-вах
#монтируется в корневую директорию /sys
	devices/ - все у-ва зарегестрированные в ядре, содержит в виде дерева
	bus/ - перечень программных шин
	drivers/ - драйверы
	block/ - блочные у-ва(носители инф-ии, появятся только в том сл., если в ОС есть устройство и драйвер к нему)
	class/ - группировка у-в по классам
посмотреть инф-ю о сетевой карте enp0s3 (-a аттрибуты -p путь)
udevadm info -a -p /sys/class/net/enp0s3
следить события по ядру:
udevadm monitor --property --kernel
протестируй события с блочным у-вом sda:
udevadm test /sys/block/sda
Procfs - виртуальная ф-ловая система, монтируется в директорию /proc, содержит иерархическое представление о всех поцессах в системе
#предоставляет метод обращения к обмену инф-ии м/у ядром и пол-ским пространством
#все изменения б. действовать до перезагрузки
содержит директории:
	PID/ - информация о конкретном процессе
	cpuinfo - сведения о ЦП
	devices - перечень настроенных у-в
	mounts - смонтированные ф-ловые системы
	sys/ - доступная для редактирования инф-я о системе
покажет инф-ю о процессоре:
cat /proc/cpuinfo
покажет инф-ю о смонтированных у-вах:
cat /proc/mounts
покажет максимальное возможное к-во одновременно открытых ф-лов:
cat /proc/sys/fs/file-max
#м. ее сдесь отредактировать и сохранить, она сразу применится
в CentOS включение форвардинга м/у сетевыми картами находится в ф-ле:
cat /proc/sys/net/ipv4/ip_forward #по умолчанию в нем стоит 0
например можем его включить:
echo 1 > /proc/sys/net/ipv4/ip_forward
---------------------------------------------------------------------

МОНИТОРИНГ CPU, ПАМЯТИ, HDD
===========================

узнать версию CentOS (работает во всех Linux. Посмотреть ф-лы содержащие слово release):
cat /etc/*release*
Посмотреть версию ядра:
uname -r
покажет метрики CPU:
vmstat
покажет изменение производительности CPU в реальном времени:
watch vmstat
показывает инф-ю:
procs - процессы
	r - к-во выполняемых(running) процессов #среднее к-во потоков ядра исполняемых и ждущих исполнения,
		если это число > к-ва ядер, значит есть потоки кот-е у нас ждут ядро, если <= то все в порядке
	b - к-во процессов, кот-е блокированы (block) #процессы кот-е находятся в состоянии неприрываемого сна,
		их нельзя убить, это процессы кот-е ждут ответов от дисков, иногда от системы распределения памяти,
		чаще всего это говорит о том, что у нас медленный диск, он заставляет систему ждать
memory - память
	swpd – количество блоков памяти, перемещённых в swap (к-во памяти выделенной под swap)
	free – свободная память (без учёта памяти, занятой буферам и кэшом, тоже, что выводит free в колонке Mem:free
	buff – буфер памяти (страницы памятити, кот-е зарезервированы системой для к-либо процессов) #ее могут называть heap 
	cache – кеш, находятся ф-лы кот-е недавно были использованы системой и хранятся в ОЗУ
swap - раздел подкачки
	si (swap in) – количество блоков в секунду, которое система считывает из раздела или файла swap в память
	so (swap out) – и наоборот, количество блоков в секунду, которое система перемещает из памяти в swap
io - система ввода/вывода
	bi (blocks in) – количество блоков в секунду, считанных с диска
	bo (blocks out) – количество блоков в секунду, записанных на диск
system - системные параметры
	in (interrupts) – количество сигналов прерываний в секунду, кот-е поступают от програм. или аппаратного обеспечения
		которые говорят о наступлении к-либо события (напр-р пол-ль нажал клавишу)
	cs (context switches) – количество переключений между задачами
cpu - параметры ЦП
	us (user time) - % время CPU используемое на выполнение кода, кот-й выполняется на уровне пол-ля, польз-ий уровень
	sy (system time) – % время CPU используемое на выполнение задач ядра, уровень системы
	id (idle) - % простоя, время в бездействии (ожидании задач)
	wa (wait) - % времени ожидания ответа от диска (если значение >=50 значит диск медленный, значит 50% времени ЦП ждет ответа от диска)
	st (stolen time) - украденное время, как много времени ожидает виртуальная машина ответа от гипервизора (как быстро гипервизор отвечает,
		говорит о необходимости дополнительного выделения ресурсов процессора) 
vmstat -a #добавит пункты в вывод в разделе memory
	inactive - память, кот-я была выделена под процесс, но этот процесс более не активен
	active - активная память кот-я используется к-либо процессом
vmstat -s -расширенный вывод инф-ии о памяти
free -h #вывод инф-ии в удобочитаемом формате (human)
	shared - память являющаяся общей для к-либо процессов (монтируется в каталог /tempfs)
	available - доступная память (free+cache)
swapon -s #покажет инф-ю о свопе, куда монтируется

команда top
показывает в заголовке:
текущее время, up (uptime) время работы системы, users (сколько пол-лей в системе),
	 load everage (ср. загрузка на посл.минуту, посл. 5мин.,посл 15мин.)
			1-макс.загрузка 1-го ядра, 2- макс. загрузка 2-х ядер...
нажав 1 увидим загрузку каждого ядра
теже параметры us, sy, ni(nice level)-какая ч. CPU занята выполнением процессов с измененными приоритетами
id, wa, hi (hardware interrups) аппарат.прерывания, si (software interrups) программ. прерывания
колонка S-process status:
	R-running - запущенный
	S-sleeping - процесс спит
	D-uninterrupted sleep - непрерываемый сон (ждет ответа от диска/памяти)
по умолчанию сортируется по CPU, нажав "shift"+">" сортировка переместится к столбцу вправо, "shift"+"<" к столбцу влево 
shift+m сортировка по памяти
shift+f м.выбрать столбец по которому хотим отсортировать, после нажать -s (сортировать), потом -q (вернуться в top) 
shift+r ревервивная сортировка
чтобы поставить htop, вначале нужно установить пакет epel-release:
yum install epel-release
потом ставим htop:
yum install htop
htop через F5 покажет дерево процессов, F4 фильтрует
F1 - справка;
F2 - настройки;
F3 - поиск процесса;
F4 - сортировка списка процессов (от большего к меньшему или от меньшего к большему);
F5 - устанавливает древовидное отображение (корни - родительские процессы, а листья - дочерние) и наоборот;
F6 - открывает панель с выбором параметра сортировки процессов;
F7 - увеличить приоритет выполнения текущего процесса;
F8 - уменьшить приоритет выполнения текущего процесса;
F9 - убить процесс;
F10 - выйти из программы.
установим программу stress (проверка ситемы на стресс)
yum install stress
запустим стресс cpu на 1 ядро:
stress -c 1
запустим стресс ОЗУ
запустим 1 worker (рабочего), кот-й б. выполнять операцию malloc(memory allocation) выделения памяти, и позволим ему выделить 2ГБ ОЗУ:
stress --vm | --vm-bytes 2048M
установим программу iotop (InputOutputTop):
yum install iotop
#работает с подсистемой ввода/вывода
где
Total DISK READ - показ-ет пропускную способность м/у кодом (процессами, ядром) и подсис. ввода/вывода (как мы работаем вообще с подсис.в/в)
Actual DISK READ - пок. как система ввода/вывода обращается к железу (реально сколько считывает с диска)
также по записи на диск Total DISK WRITE, Actual DISK WRITE
TID - thread id - id потока (по tid-у м. потом запустить ps -ef и найти pid процесса)
PRIO - приоритет в/в
	idle - класс приоритета, когда процесс м.получить доступ к диску, когда др. программы не хотят к нему обращаться
	be/число - best enfort, 0-7,чем меньше число - тем выше приоритет
	rt/число - real time, высокий приоритет (первые получают доступ к диску)
USER - пол-ль от которого запущен thread
SWAPIN - на сколько этим процессом задействуем swap
IO - сколько затрачиваем % от подсистемы в/в на обработку TID-а
установим пакет sysstat:
yum install sysstat
программа iostat
его вывод м.заскриптовать под zabbix
	avg-cpu - средняя загрузка по cpu
	%user - пол-ль
	%nice - уровень приоритета
	%system - на ск-ко загружена система
	%steal - кто ворует время у нас (ждем от гипервизора ответа)
	%idle - простой процесса
также выводит инф-ю по всем смонтированным HDD:
	tps - к-во запросов в сек. (обращений к диску)
	KB_read/s - кбайт считано в секунду
	KB_wrtn/s - кбайт записано в секунду
	KB_read - всего кбайт считано
	KB_wrtn - всего кбайт записано
iostat -x расширенный вывод:
	rrqm/s - read request/sec запрос на чтение в сек.
	wrqm/s - запрос на запись в сек.
	r/s и w/s - факт. к-во запросов чтения/записи в сек.
	rkB/s и wkB/s - чтение и запись в кбайтах/сек
	avgrq-sz - average request size - средний размер запроса к дисковой подсистеме (измеряется в секторах)
	avgqu-sz - сред. длина запроса
	await - сколько ждем по операции (в милисек)
		r_await
		w_await
	%util - утилизация процессора (какую часть процессора занимают операции по работе с HDD)
sar - счетчик производительности
sar 1 5 #1-интервал 5-к-во запросов соберет инфу по CPU
sar -b 1 1 #соберет инф. по HDD
sar -bv 1 1 #вывод расширенной инф. по дискам
sar -d 1 1 #вывод в разрезе по дискам
-------------------------------------------------------------------------------------------------------------------------------------

СИСТЕМА МОНИТОРИНГА COLLECTD 
============================

yum install epel-release
yum install collectd
откроем файл конфигурации /etc/collectd.conf
в нем для работы со статистикой есть плагин rrdtool, раскомментируем секцию этого плагина
а также то место, где плагин подключается: LoadPlugin rrdtool
#rrdtool - набор утилит для работы с кольцевой базой данных rrd
делаем установку данной утилиты, web-сервер apache, демон который покажет статистику collectd-web
yum install rrdtool httpd collectd-web
т.к. настройки конфиг-ии мы изменили, нам нужно его перезапустить
systemctl start collectd
стартуем сервер apache:
systemctl start  httpd
получим с него вэб-страницу по умолчанию:
curl http://127.0.0.1
конфиг apache находится в ф-ле /etc/httpd/conf/httpd.conf
открываем его и смотрим в конце путь подключения конф. ф-лов:
IncludeOptional conf.d/*.conf
смотрим эту директорию и видим, что там лежит конф. ф-л /etc/httpd/conf.d/collectd.conf
открываем этот ф-л и видим в начале ф-ла:
Alias /collectd/ /usr/share/collectd/collection3/
и видим диресторию где лежат скрипты cgi:
<Directory "/usr/share/collectd/collection3/bin">
	Options ExecCGI
	AddHandler cgi-script .cgi
	Require local
</Directory>
выходим и проверяем страницу плагина, заходим по алиасу:
curl http://127.0.0.1/collectd/bin/index.cgi
теперь пробуем зайти на эту страницу с удаленной машины, для этого в конфиге apache
изменим директиву в секциях, разрешив доступ всем, а не только с локального хоста:
<Directory "/usr/share/collectd/collection3/">
	#Require local
	Require all granted
	DirectoryIndex bin/index.cgi
	DirectoryIndexRedirect on
</Directory> 
<Directory "/usr/share/collectd/collection3/share/">
	Require all granted
</Directory>
<Directory "/usr/share/collectd/collection3/bin/">
	Options ExecCGI
	AddHandler cgi-script .cgi
	#Require local
	Require all granted
</Directory>
сохр,вых
делаем рестарт apache:
systemctl reload httpd
теперь все заработало
м. посмотреть какие плагины есть к collectd:
yum search collectd
-------------------------------------------------------------------------------------

Troubleshoting
==============

посредством top находим самый грузящий процесс, находим его pid
потом командой отыскиваем сам процесс и pid родительского процесса <pid2>(указывается рядом справа):
ps -ef | grep <pid1>
потом ищем программу родительского процесса:
ps -ef | grep <pid2>
и смотрим информацию о грузящем приложении
либо
в htop нажимаем <F5> показывает дерево поцессов
можем посмотреть открытые ф-лы грузящего процесса по pid-у:
lsof -p <pid>
если нет связи с хостом, проверим по каким портам работают программы на хосте:
netstat -ntulp

КОММАНДЫ ФИЛЬТРАЦИИ И ВЫВОДА НА ЭКРАН
=====================================
clear - очистить экран

CAT - для объединения ф-лов и печати на стандартный вывод
вывод 2-х ф-лов на экран:
cat hello1.txt hello2.txt
объеденить 2 ф-ла и вывести в третий:
cat hello1.txt hello2.txt > hello3.txt

CUT - удаляет секции из каждой строчки файла
вырезать 2,3,5 символы в ф-ле hello1.txt:
cut -c 2,3,5 hello1.txt

EXPAND - заменяет символы табуляции на пробелы
UNEXPAND - заменяет пробелы в табы

FMT - форматирует вывод текста
игнорирует все символы переноса каретки в файле(если просто без ключа):
fmt hallo1.txt
форматирование текста, чтобы в одной строке было не более 5 символов (переносы меняет на пробелы, если строка 2 сим. - не трогает)
fmt -w 5 hello1.txt

HEAD - показывает первую часть ф-лов
без ключа показывает первые 10 строк:
head hello1.txt
показать первые 2 строчки:
head -n 2 hello1.txt

OD - превращает вывод файлов в другие форматы
без ключей конвертирует вывод в восьмеричный код:
od hello1.txt
в символы asci:
od -c hello1.txt

JOIN - объединяет строчки файлов по общему полю

LESS - позволяет постранично читать ф-л (нажимая PageDown), выполнять поиск
less hello1.txt
просмотреть системный журнал отфильтровав по слову semaev постранично:
grep semaev /var/log/auth.log | less

more - фильтр для просмотра ф-лов
paste 1.txt #выводит на экран, для просмотра след. страницы просит нажать кнопку


NL - нумерует строки
nl hello1.txt

PASTE - позволяет построчно вставлять в файл (одна строка из одного и другого, 2-я стр. из одного и др.)
paste 1.txt 2.txt

PR - показывает как будет выглядить текст при выводе на печать

SED - потоковый редактор вывода для фильтрации и трансформации текста
редактировать/edit(ключ -е) заменить/substitute (аргумент s) 'socks' на слово 'peaple' в ф-ле 2.txt:
sed -e 's/socks/peaple/' 2.txt
заменить оо на аа:
sed -e 's/oo/aa/' 2.txt
тоже самое, но уже с сохранением вывода в ф-л 3.txt:
sed -e 's/oo/aa/' 2.txt > 3.txt
ключ -re используя регулярные выражения
заменить если строка начинается с B или b, то заменить на С:
sed -re 's/^(B|b)/C/' 1.txt
 
SORT - сортирует строки в текст. ф-лах по к-нибудь признаку
без ключа по алфавиту, с ключем -r в обратном порядке

SPLIT - делит вывод файла на куски
разделить файл 1.txt на ф-лы содержащие по 2 строчки (ключ -l) исходного ф-ла:
split -l 2 1.txt
создались 2 файла xaa и xab (в каждом по 2 строчки)
разделить по размеру 5 байт (ключ -b):
split -b 5 1.txt
появилось 4 файла xaa,xab,xac,xad

TAIL - показывает последнюю часть файла
без ключей - часть лога на лист
последние 5 записей:
tail -n 5 hello1.txt
посмотреть системный журнал отфильтровав по слову semaev последнюю строчку:
grep semaev /var/log/auth.log | tail -n 1

TR - переводит или удаляет символы
трансформирует у Hello заглавные буквы в прописные (ключ -t трансформировать):
echo Hello | tr -t A-Z a-z
hello
превратить l в L:
echo Hello | tr -t l L
HeLLo
удалить букву l (ключ -d):
echo Hello | tr -d l
Heo
объеденить соседние буквы l:
echo Hello | tr -s l
Helo

UNIQ - ищет уникальные и дублирующиеся строки
покажет уникальные строчки:
uniq 1.txt
покажет количество повторений строчки (пишет рядом число повторений):
uniq -c 1.txt
покажет только дублирующиеся строчки:
uniq -d 1.txt
покажет только неповторяющиеся строчки:
uniq -u 1.txt

WC (work count)- показывает кол-во строк, слов, байт в файле

wc 1.txt
вывод в виде (строк слов байт имя ф-ла):
4 8 29 1.txt
покажи только количество слов (ключ -w):
8 1.txt
вывод информации по всем ф-лам текущего каталога:
wc *
----------------------------------------------------------------------------

РАБОТА С ФАЙЛАМИ И ДИРРЕКТОРИЯМИ
================================

TOUCH - меняет отметки времени файла
Можно создавать пустые ф-лы и менять время доступа к ф-лу
создать пустой файл:
touch 1.txt

MKDIR - создать папку
ls -l - расширенный вывод (списком) содержимого папки
ls -lH - покажет также символы объекта (первый символ),где l -link, d -directory, b -block(блочное у-во,драйверы), c -character(у-ва поточных данных,драйверы)
ls * - покажет все, включая вложения
ls *.* - покажет файлы которые имеют расширения
ls [ab]* - покажет все что начинается с а или b
ls [!a-m]* - покажет все, кроме файлов начинающихся с a по m
ll - расширенный вывод списка
lsblk - покажет список дисков и разделов

CP - копирование ф-лов, папок
скопировать файл:
cp 1.txt cop1.txt
скопировать папку с содержимым (ключ -R)в др. папку:
cp -R folder1 folder2
скопировать архив 1.zip в папку folder 2
cp 1.zip "Folder 2"/1.zip

MV - перенос, переименование ф-лов
перенести ф-л из папки folder1 в текущий каталог:
mv folder1/1.txt .

RM - удаляет файлы и папки
rm 1.txt - удалить файл 1.txt
удалить папку с содержимым (ключ -r) игнорируя предупреждения (ключ -f)
rm -rf folder1
для удаления ф-ла по его inod:
find . -inum 782263 -exec rm -i {} \;
где 782263 - номер inod

RMDIR - удаляет пустые папки

FILE - определяет тип файла
например:
file 14.jpg
14.jpg: JPEG image data, EXIF standart
расскажет про все ф-лы в папке:
file *

FIND - поиск файлов в директории
найти все в текущем каталоге:
find .
найти все в тек. каталоге у чего имя (ключ -name) начинается с 'In':
find . -name "In*"
найти все что начинается с заглавной буквы и имеет расширение:
find . -name "[A-Z]*.*"
найти все, что > 5 МБайт:
find . -size +5M
найти все, что < 5 МБайт:
find . -size -5M
найти все, что имеет тип файл 
find . -type f
найти все, что имеет тип директория 
find . -type d
найти все, к чему мы имели доступ (ключ -atime) access time не раньше чем 5 дней:
find . -atime +5
найти все, что изменялось (ключ -ctime) change time не раньше чем 5 дней:
find . -ctime +5

grep	- утилита поиска (м.б. с ключем -e -f -r);
egrep	- расширенный grep (понимает сложные);
fgrep	- быстрый grep (не понимает рег. выражений);
rgrep	- рекурсивный grep (ищет во вложенных ф-лах и папках);
sed	- потоковый текстовый редактор.

найти сочетание оо в содержимом ф-ла 1.txt:
grep oo 1.txt
тоже самое с нумерацией строк:
grep -n oo 1.txt
тоже самое без чувствительности к регистру (по умолчанию чувствителен)
grep -i oo 1.txt
ищет в списке ф-лов названия с сочетанием ile:
ls | grep ile
ищет в содержимом ф-ла:
cat1.txt | grep ile

АРХИВИРОВАНИЕ
=============
CPIO - двоичный архиватор
взять все из текущей папки и положить (ключ -o) на уровень выше (> ..) и создать файл архива test.cpio:
ls | cpio -o > ../test.cpio
собрать все ф-лы *.txt в архив test2.cpio:
find . -name "*.txt" | cpio -o > test2.cpio
взять все из архива test2.cpio находящегося на уровень выше:
cpio -id < ../test2.cpio

DD - конвертирует и копирует ф-лы
скопировать диск (вместе с разделами) /dev/sdb (input file) в образ диска disk1.img (output file):
dd if=/dev/sdb of=disk1.img
записать образ диска на флешку (bs - к-во байт чтения/записи, по умол. 512Кб):
dd if=disk1.img of=/dev/sdd bs=1M
(предварительно проверив подключенные диски с разделами ком. lsblk)

GZIP (GNU ZIP) - архиватор
сделать архив образа disk1.img:
gzip disk1.img
преобразует ф-л в disk1.img.gz
распаковать ф-л из этого архива:
gunzip disk1.img.gz
преобразует ф-л в disk1.img

BZIP2 - архиватор (лучше сжимает)
сделать архив образа disk1.img:
bzip2 disk1.img
преобразует ф-л в disk1.img.bz2
распаковать ф-л из этого архива:
bunzip2 disk1.img.bz2
преобразует ф-л в disk1.img

XZ - архиватор
сделать архив образа disk1.img:
xz disk1.img
преобразует ф-л в disk1.img.xz
распаковать ф-л из этого архива:
unxz disk1.img.xz
преобразует ф-л в disk1.img

TAR - архиватор
создать ф-л архива archive.tar из папки folder
(create verbose(процесс) file):
tar cvf archive.tar folder
рядом с папкой создается архив с именем archive.tar

создать ф-л архива используя архиватор gzip:
tar cvfz archive.tar.gz folder 
рядом с папкой создается архив с именем archive.tar.gz

распаковать архив archive.tar:
tar xvf archive.tar
распаковать архив modsecurity-2.9.2.tar.gz используя GZIP,GZIP2 в папку archive:
tar xfvz modsecurity-2.9.2.tar.gz -C ./archive

--------------------------------------

ГРУППОВЫЕ СИМВОЛЫ
=================
* - все что угодно
? - любой символ
! - не
[ac] - а или с
[a-c] - a,b,c
-----------------

РЕГУЛЯРНЫЕ ВЫРАЖЕНИЯ
====================
\<text	- слова начинающиеся с text;
text\>	- слова заканчивающиеся на text;
^	- начало строки;
$	- конец строки;
[a-z]	- диапазон от а до z;
[^t]	- не буква t;
\[	- воспринять символ [ буквально;
.	- любой символ;
a|z	- a или z.

ищет сочетания ple в файле 1.txt:
grep ple 1.txt
ищет сочетание ple в начале строк ф-ла 1.txt:
grep ^ple 1.txt
ищет сочетание ple в конце строк ф-ла 1.txt:
grep ple$ 1.txt
поиск условия: в начале строки начиналось с b или d:
egrep '^(b|d)' 1.txt

выполнение команд:
выполняет команды одну за другой:
команда1;команда2
выполняет команду2, если команда1 была выполнена успешно:
команда1&&команда2
выполняет команду2, если команда1 возвращает ошибку:
команда1||команда2
запускает команду в фоновом режиме:
команда&
выполняет обе команды в одной и той же оболочке:
(команда1;команда2)

механизмы подстановки в bash:
любой символ:
?
любое количество любых символов (в т.ч. ни одного), но не *-файлы:
*
любые файлы и каталоги, в т.ч. из всех подкаталогов:
**
один из символов, указанных в скобках:
[abc]
символ из указанного диапазона:
[a-f]
любые символы, кроме тех, что указаны в скобках:
[!abc]
аналогично предыдущему:
[^abc]
сокращенное обозначение домашнего каталога:
~
текущий каталог:
.
каталог на один уровень выше:
..
возвращает ab1 ab2 ab3:
ab{1,2,3}
возвращает а1 а2 а3 а4:
a{1..4}
арифметические вычисления:
$[3*4]
замена команды результатом ее выполнения:
`команда`
вариант аналогичный предыдущему:
$(команда)
Последовательность символов  [a,b,e-h]*  означает файлы, имена которых начинаются с
a ,  b ,  e ,  f ,  g  или  h . Если первый символ, указанный в квадратных скобках, - это
^  или  ! , то допустимы все символы, кроме указанных в скобках.
отдельно стоящий дефис ( - ) означает любой спецсимвол.

чтобы разбить команду на 2 строки исп-ся "\"

вызов справки:
команда -help
man команда
help команда
info команда

ПОТОКИ КОНВЕЙРЫ И ПЕРЕНАПРАВЛЕНИЯ ВВОДА И ВЫВОДА
================================================
Stdin(0) - стандартный ввод;
Stdout(1) - стандартный вывод;
Stderr(2) - стандартный вывод ошибки;
> - передать в;
>> - дописать в;
< - взять из;
| - отправить следующей команде;
Tee - отправить в файл и на стандартный вывод;
Xargs - построчнопередать на вывод команде;

отправить результат ошибки выполнения команды ls (2) в файл result.txt (ф-ла bob не существует):
ls bob 2> result.txt
в файле появится "ls:невозможно получить доступ к bob: нет такого ф-ла или каталога"
отправить результат выполнения команды ls (1-использ-ся по умолчанию) в файл result.txt (если ф-л bob существует):
ls bob 1> result.txt
вывести результат работы команды в ф-л result.txt, а если возникнут ошибки - в ф-л error.txt:
ls bob > result.txt 2> error.txt

КОНВЕЙР ПЕРЕДАЧИ РЕЗУЛЬТАТА КОМАНД
===================================
выбрать в списке файлы с буквой "r":  
ls | grep r
отправить вывод списка на экран и в файл:
ls | tee output.txt
построчное выполнение результата команды делает xargs
например найти текстовые ф-лы и их удалить:
find . -name "*.txt" | xargs rm -f

РАБОТА С ПАРАЛЛЕЛЬНЫМИ ПРОЦЕССАМИ
=================================
бездействие 1000сек.
sleep 1000
бездействие 1000сек. в фоновом процессе:
sleep 1000 &
покажет
[1] 2215
(можно остановить процесс ctrl+Z)
выполняемые процессы:
jobs
покажет
[1]+ Выполняется sleep 1000 &
[2]- Остановлено sleep 1000
перейти к фоновому процессу foreground (в данн. случае 2):
fg 2
вновь запустить фоновый процесс 1 background:
bg 1
ps - snapshot текущего состояния процессов
ключ -eo выводить выбранные столбцы
ps -eo user,pid,pcpu(цпу),nice(приоритет),comm(описание)
ключ aux (all user x (executable)-видеть даже те процессы, кот. были запущены вне нашего терминала)
ключ alx (l-list) -подробный список, где колонка NI (nice) - приоритет процесса (-20 максимальный +19 минимальный)
например вывести только процессы sleep:
ps aux | grep sleep
показать процессы для пол-ля max:
ps -U max -u max u
показать процессы apache или httpd:
ps aux | egrep '(apache|httpd)'
выдать 10 процессов, потребляющих наибольшее количество памяти:
ps -auxf | sort -nr -k 4 | head -10
выдать 10 процессов, потребляющих наибольший ресурс процессора:
ps -auxf | sort -nr -k 3 | head -10
закрыть - q

убиваются процессы ком. kill id_процесса:
kill 2215
завершить все процессы с именем sleep:
killall sleep
exit - закрыть терминал
При завершении сессии все запущенные процессы прервутся, чтобы они не завершались есть
программа nohup:
nohup sleep 1000 &
покажет:
nohup: ввод игнорируется, вывод добавляется в "nohup.out"
pstree - показывает иерархический снимок процессов
pgrep - поиск и вывод процессов
найти все проц. с именем sleep:
pgrep sleep
покажет только id процессов
покажет id и имя процесса:
pgrep sleep -l
покажет все процессы пользователя semaev:
pgrep -u semaev -l
pkill завершает процессы
завершить процессы с именем sleep:
pkill sleep
top - диспетчер задач в реальном времени
+- сортировка
по умолчанию сортирует по загрузке процессора.
Чтобы завершить к-либо процесс нажимаем "k" и вводим номер процесса
по умолчанию предлагает завершаить процесс с сигналом 15 (sigterm) (мягкое завершение).
Вводим 15
завершаить процесс с сигналом 9 (sigkill) (жесткое завершение)
q - выход из программы
uptime - показывает как долго запущена система, а также load average (3 цифры)
1-я - загрузка в посл. минуту
2-я - загрузка в посл. 5 минут
3-я - загрузка в посл. 15 мин.
screen - запустить еще одно работающее окно в пределах одного терминала
поработать в нем, затем нажать
Ctrl+A после чего нажать D. Это как бы свернет окно.
Чтобы вернуться к скрину нужно набрать screeen -r
Чтобы завершить скрин набираем exit.
Если хотим создать неск. окон, нужно создать для них псевдонимы:
например в отдельном окне пустим пинг:
screen -S yandex ping ya.ru
посмотреть запущенные скрины:
screen -ls
перейти к скрину:
screen -r yandex

установить минимальный приоритет процесса:
nice -n 19 sleep 2000 &
установить максимальный приоритет процесса:
nice -n -20 sleep 2000 &
проверяем:
ps -eo user,pid,nice,comm | grep sleep
переустановить приоритет действующему процессу:
renice 5 -p 2572
покажет
2572 (идентификатор процесса) старый приоритет 19, новый приоритет 5
изменить приоритет задач для пользователя semaev:
renice 15 -u semaev

имеющаяся в распоряжении память:
free
информация о состоянии систем IDE и SCSI и всех связанных с ними устройств:
lsscsi
информация о компонентах pci:
lspci
подробный (verbose) список всех USB-интерфейсов и устройств (пакет  usbutils):
lsusb -v
-------------------------------
Если команда  unmount  возвращает ошибку
Device is busy  (Устройство занято), это означает, что данные с CD-ROM использу-
ются другой программой. Такая реакция возникает и в том случае, если какой-ли-
бо из каталогов диска открыт в одной из оболочек. Выполните в нем команду  cd ,
чтобы перейти в домашний каталог. Если требуется найти процесс, из-за которо-
го возникает такая ошибка, воспользуйтесь командой  fuser  - выполните  fuser -m
/cdrom 
-------------------------------

УСТАНОВКА ОГРАНИЧЕНИЙ НА КОЛ-ВО ВХОДОВ, ЗАПУЩ. ПРОЦЕССОВ И ИСП. ОЗУ
===================================================================

покажет текущие ограничения для пол-ля (-a all) для текущего сеанса консоли:
используется обычно для ограничения ресурсов выполнения к-либо скрипта/задачи
ulimit (user limit)
ulimit -a
покажет напр-р:
file size		(blocks, -f)	unlimited #текущий размер ф-ла кот-й м. создать пол-ль
max locked memory	(kbytes, -l)	64 #ск-ко пол-ль м. испол-ть заблокированной памяти
max memory size		(kbytes, -m)	unlimited #кол-во памяти кот-е м. использ-ть пол-ль
cpu time		(seconds, -t)	unlimited #время процессора используемое пол-лем
max user processes	(-u)		15666 #макс. кол-во процессов
зададим размер ф-лов 0:
ulimit -f 0
проверим установленное значение:
ulimit -f
покажет 0
после этого пол-лю не даст создать ф-л
для редактирования глобальных настроек системы или отдельных пол-лей используется ф-л:
/etc/security/limits.conf
где:
<domain> - домен (пол-ль,группа,групповые символы)
<type> - тип (soft(будут выскакивать события) и hard(не можем преодалеть) ограничения)
<item> - то к чему относится (размер данных, макс.кол-во открытых ф-лов,кол-во запущ.процессов,кол-во одновременных входов в систему и т.д.)
<value> - значение
ключ	- maxlogins - кол-во одновременных входов для пол-ля (одновременных сеансов)
	- maxsyslogins - ограничение всех сеансов в системе (допустим ограничение для 10 пол-лей на терминальнике)
	- nproc - кол-во запускаемых процессов
	- as - address space limit (KB) ограничение кол-ва памяти
	- chroot - изменяет корневую директорию
запишем в ф-ле:
@student	hard	nproc		20 #например ограничение для группы пол-лей student не более 20 процессов:
ftp		-	chroot		/ftp #для пол-ля ftp изменяет корневую директорию на /ftp 
semaev		hard	nproc		40 #пол-лю семаев разрешен запуск не более 40 процессов
*		hard	maxlogins	1 #всем жесткое ограничение на кол-во одновременных входов в систему не больше 1
---------------------------------------------------------------------------------------------------------------------------------------------

TAR
===
Архивы, запакованные с помощью программы  gzip , обычно имеют расширения
*.tgz  или  *.tar.gz . Архив устанавливается на компьютере благодаря программе  tar.
Отображение содержимого архива:
tar -tzf archiv.tar.gz
Распаковка файлов относительно текущего каталога:
tar -xzf archiv.tar.gz 
Распаковка в один каталог:
tar -xzf archiv.tar.gz -C dir




TOP
===
top - диспетчер процессов (для выхода нажать Q)
-------------------
Команда  top  обладает способностью интерактивного приема команд. При этом
процессы можно останавливать ( K  - kill ) или изменять их приоритет ( R )
-------------------
Процессы могут находиться в различных состояниях. Чаще всего встречаются
состояния  R  (running)  и  S  (sleeping, то есть сейчас процесс не выполняет никаких
задач и ожидает ввода информации). Кроме того, выполнение программы можно
временно прервать, переведя ее в состояние  T  (stopped).
-------------------
В столбце  PID  указаны номера процессов. Зная номер процесса, можно прину-
дительно остановить вышедшие из-под контроля программы или фоновые про-
цессы с помощью команды  kill .
-------------------
Когда вы знаете названия программ и хотите
выяснить соответствующий программе номер процесса (PID), поможет команда pidof:
pidof программа
-------------------
Можно завершать процессы и с помощью команды  top : просто
нажмите клавишу  K  и дополнительно - номер процесса, а также желаемый сигнал.


KILL
====
Эта команда посылает действующему процессу сигналы, специфи-
цируемые благодаря номеру  PID  (его можно узнать с помощью команды  top  или  ps ).
Чтобы «аккуратно» завершить программу, используется сигнал 15 ( kill  задейству-
ет этот сигнал по умолчанию). Если это не помогает, необходимо применить сигнал 9
(в данном случае - для процесса 2725):
kill -92725


KILLALL
=======
Эта команда гораздо удобнее, так как при ее использовании
можно указывать не номер процесса, а название программы. Правда, в данном
случае будут завершены все процессы с таким именем:
killall -9 firefox



показывает свободное место для всех сегментов ф-ловой системы:
df -h
покажет точки монтирования разделов и тип ф-ловой системы:
df -Th
сколько дискового пространства требует каталог, включая подкаталоги (-h удобочитаемость):
du -h

rm –rf windows удаление со всем содержимым


CP
==
копирование каталога вместе со всем содержимым (рекурсия):
cp -r
если надо сохранить информацию о правах при копировании:
cp -a
копирует все C-файлы из каталога  project  в текущий каталог:
cp project/*.c .
бэкап всех файлов каталога /etc:
cp -a /etc/* /etc-backup

Можно проверить работу с джокерными символами командой  echo jokerzeichen . Она показывает все
имена файлов, охватываемые комбинацией с джокерным символом, и выводит эти
имена на экран, не изменяя при этом имен файлов.

grep Поиск текста в текстовом файле
find Поиск файлов по имени, дате, размеру и т. д.
locate Поиск файлов по имени


FIND
====
Следующая команда ищет все файлы в текущем каталоге и во всех подкаталогах,
названия которых начинаются с  .e :
find -name '.e*'
--------------------------
Команда  find  производит поиск, начиная с каталога  /usr/share/texmf , и ищет все
файлы вида  *.tex  в каталоге, название которого оканчивается на  latex:
find /usr/share/texmf -path '*latex/*.tex'
--------------------------
Ищет все каталоги, находящиеся в  /etc/ . Обычные
файлы, располагающиеся в  /etc/. , среди результатов не показываются. Список
результатов упорядочивается по алфавиту с помощью команды  sort  (по умолчанию
такой сортировки не происходит).
find /etc -type d | sort
--------------------------
Ищет все файлы в (под)каталогах  /home , принадле-
жащих пользователям группы  users , причем искомые файлы должны были каким-
либо образом быть изменены в течение последних пяти дней (содержание, права
доступа и т. д.):
find /home -group users -mtime -5
--------------------------
Команда  find -mtime +5  находит такие файлы, которые были изменены ранее,
чем пять дней назад, а команда  -mtime 5  возвращает файлы, которые были измене-
ны ровно пять дней назад. 
--------------------------
Следующая команда удаляет все резервные копии, содержащиеся в данном
каталоге и во всех подкаталогах. При этом  find  строит список всех сомнительных
файлов и передает его команде  rm  через подстановку команды  ($(команда)):
rm $(find . -name '*~')
--------------------------
Следующая команда показывает,как выполнить поиск файлов,
в названиях которых содержится последовательность
символов  abcde , в  /etc  и во всех его подкаталогах:
find -type f -exec grep -q abcde {} \; -print

GREP
====
Следующая команда просматривает все TEX-файлы текущего каталога в поис-
ках последовательности символов  emacs . Список всех найденных строк (перед
каждой из которых указывается имя файла) отображается на экране:
grep emacs *.tex
--------------------------
Команда  grep  с параметром  -v  возвращает в качестве результата все строки,
в которых отсутствует заданный шаблон поиска.
--------------------------
Удаляет из  configfile  все строки, которые
начинаются с символа  #  (то есть все комментарии). Следующая команда  cat  до-
полнительно удаляет все пустые строки. Конечный результат сохраняется в файле
nocomments:
grep -v '^#' configfile | cat -s > nocomments  
--------------------------
В следующем примере команда  grep  отфильтровывает из списка всех установленных пакетов те,
в которых содержится последовательность символов  mysql  без учета регистра.
Команда  sort  сортирует полученный список:
rpm -qa | grep -i mysql | sort

CAT
====
слияние и вывод файлов на экран



/sbin
stat mount.cifs свойства
chmod 4755 mount.cifs
ls просмотр директории
ls - l /windows/myfile.txt просмотр прав доступа
smbclient –L win8 –U username  отобразить ресурсы, предоставленные в общий доступ на windows-машине
Mount –t cifs –o username монтировать сетевую папку


Install-WindowsFeature –Name Failover-Clustering –IncludeManagementTools


http://faqpc.ru/kak-ustanovit-ubuntu-server-14-04-1-lts/

ПО для изменения размера разделов:
resize2fs

shift+вверх/вниз перелистывание в консоли

LS
==
вывод списка ф-лов/папок текущей директории с правами безопасности и датой:
(десять первых символов в начале строки указывают тип файла и биты доступа.
дефис ( - ) для обычного файла,  d  для каталога (directory),
b  или  c  для файла устройства (block или char) или  l  для символьной ссылки.)
ls -l
с отображением скрытых файлов (у которых вначале точка):
ls -a
сортировка по времени:
ls -t
по размеру:
ls -S
по расширению:
ls -X
сортировка в обратном порядке:
ls -r
с отображением inod:
ls -i
с отображением ф-лов в подкаталогах:
ls -R
пример комбинации параметров:
ls -laR
постраничный показ ф-ла:
less файл
постраничный показ каталога:
ls -l | less
для одновременного вывода на экран и записи в ф-л исп. команда tree:
ls | tree файл
Вывод в файл1 (обычно отсортирован). Копия вывода передается sort, а затем
происходит сортировка по размеру ф-ла (5-й столбец, т.е. +4) и сохраняет в файл2:
ls -l | tree файл1 | sort +4 > файл2
--------------------------------------------------------------------------------
 
ПРАВА ДОСТУПА К ФАЙЛУ
=====================
девять битов доступа ( rwxrwxrwx  для  read/write/execute  - для владельца файла,
членов группы владельца и всех остальных)
-----------------------------
Если  michael  пожелает, чтобы этот файл был доступен для чтения только поль-
зователям группы  users  и был недоступен для пользователей, не входящих в эту
группу, нужно будет деактивировать последний  r -бит. Для этого применяется
команда  chmod:
michael$ chmod o-r  файл .txt
michael$ ls  файл .txt -l
-rw-r----- 1 michael users 3529 Oct 4 15:43 файл.txt
-----------------------------
Необходимо добавить "только чтение" для группы пользователей dokuteam.
Дополнительно изменяем групповую отнесенность
с помощью команды  chgrp :
michael$ chgrp dokuteam  файл .txt
michael$ ls  файл .txt -l
-rw-r----- 1 michael dokuteam 3529 Oct 4 15:43 файл.txt
-----------------------------
в восьмеричной системе:
Каждая цифра составляется из величин  4 ,  2  и  1  для  r ,  w  и  x 
соответственно. Таким образом,  660  означает  rw-rw---- ,  777  означает  rwxrwxrwx . Три
специальных бита  Setuid ,  Setgid  и  Sticky  имеют восьмеричные значения  4000 ,  2000 
и  1000
например:
chmod 640  файл .txt
------------------------------
При установки прав доступа к каталогам:
В принципе девять битов доступа применимы и при работе с каталогами, но в таком
случае их значение несколько отличается:  r -бит позволяет другим пользователям
просмотреть содержимое каталога с помощью команды  ls . Кроме того,  x -бит дает
возможность перейти в этот каталог с помощью  cd . Если поставить и  x , и  w , то в ка-
талоге можно создавать новые файлы.
------------------------------
назначение прав:
chmod
chmod 755 mydir (если добавить 1 бит перед цифрами можно запустить любому от имени владельца ф-ла или гр. владельца)
Тут символы есть: u (user) g (group) o (others)
И к правам добавляется бит S (переустановить идентификатор) (или в цифрах – 2 это группа, 4 это пользователь)
например chmod 4755 file.txt запуск от имени владельца ф-ла

ctrl+D выход из режима SU

chown смена владельца
chown user:users mydir смена владельца и группы владельца на папку

СОЗДАНИЕ И ЗАПУСК СКРИПТА
=========================
1.Создать файл с расширением .sh
2.Записать в начало файла:
#!/bin/bash
потом тело скрипта
3.Сделать файл исполняемым:
Для этого введите команду chmod +x и имя файла скрипта
chmod +x hello.sh
4.Теперь запускаем его:
./hello.sh
или
sh hello.sh

MV (переименовать файл)
======================
mv опции файл-источник файл-приемник
опции:
-f — заменять файл, если он уже существует;
-i — спрашивать, нужно ли заменять существующие файлы;
-n — не заменять существующие файлы;
-u — заменять файл только если он был изменен;
-v — вывести список обработанных файлов;
чтобы переименовать достаточно:
mv file newfile

RENAME (переименовать файл, массовое переименование)
==========================
$ rename опции ‘s/старое_имя/новое_имя‘ файлы
или:
$ rename опции старое_имя новое_имя файлы
опции:
-v — вывести список обработанных файлов;
-n — тестовый режим, на самом деле никакие действия выполнены не будут;
-f — принудительно перезаписывать существующие файлы;

например, переименуем все htm файлы из текущей папки в .html:
rename 's\.htm/\.html/' *.htm

модификаторы:
g (Global) — применять ко всем найденным вхождениям;
i (Case Censitive) — не учитывать регистр.

Модификаторы размещаются в конце регулярного выражения, перед закрывающей кавычкой.
Перед тем, как использовать такую конструкцию, желательно ее проверить, чтобы убедиться,
что вы не допустили нигде ошибок, тут на помощь приходит опция -n.
Заменим все вхождения DSC на photo в именах наших фотографий:
rename -n 's/DSC/photo/gi' *.jpeg

Можно использовать не только обычную замену, но и полноценные регулярные выражения чтобы
выполнить пакетное переименование файлов linux, например, переделаем все имена в нижний регистр:
rename 'y/A-Z/a-z/'*.jpeg


посмотреть версию Linux
=======================
cat /proc/version
или
dmesg | grep "Linux version"

Чтобы узнать версию дистрибутива:
lsb_release -a
или
вывести содержимое файлов "*-release", находящихся в директории /etc
cat /etc/*-release
--------------------------------------------------------------------

РАБОТА С BASH
=============
Псевдонимы позволяют запускать команды с к-либо ключами
чтобы добавить псевдоним в пользовательских настройках bash редактируем файл .bashrc в профиле:
vi ~/.bashrc
к примеру будет команда forhowlong:
в конец ф-ла дописываем строку:
alias forhowlong='uptime -p'
выходим и запускаем bash снова, чтобы он применил изменения:
bash

Функция отличается от псевдонима тем, что можно написать к-либо последовательность команд
Создадим ф-ю WTF:
function WTF() {
echo "your name is:";
whoami;
echo "today is:";
date;
echo "you are here:";
pwd;
}

передача аргументов в ф-ю:
создадим ф-ю
передает значение даты в файл с названием 1-го аргумента ф-ии
фильтрует лог по этому аргументу и дозаписывает в это ф-л:
function showlog() {
date > $1.txt;
grep $1 /var/log/auth.log | tail -n 1 >> $1.txt;
}
выходим, перезапускаем bash
пишем:
showlog semaev
проверяем
в файл semaev.txt записалась дата и последняя строчка лога

создадим такую-же ф-ю, только вторым аргументом будет ко-лво считываемых с конца ф-ла строк:
function showlog() {
date > $1.txt;
grep $1 /var/log/auth.log | tail -n $2 >> $1.txt;
}
выходим, перезапускаем bash
пишем:
showlog semaev 3
дополнительно узнать:
http://linuxgeeks.ru/bash-2.htm

переменные:
добавить в переменную PATH еще один путь:
PATH=$PATH:/home/semaev
добавляем эту переменную в переменные среды:
export PATH
проверяем
env

Для редактирования переменных среды у пользователя, редактируем файл:
vi ~/.profile или ~/.bash_profile
---------------------------------------------------------------------

BASH-СКРИПТЫ
============

создадим простой скрипт:
vi script
#!/bin/bash
echo "Are you hungry?"
read VALUE
if [ $VALUE = "YES" ];
then
echo "Make some dinner"
else
echo "Continue working"
#fi-говорит о том, что скрипт будет завершен
fi
Добавляем права на запуск ф-ла:
chmod u+x script
Можем поставить права на запуск скрипта всем пользователям от имени владельца скрипта
(добавим SUID sticky-бит для пользователя):
chmod u+s script

& - и
&& - вополнит следующее действие, если предыдущее справедливо
| (PiPline) - передает значение следующей команде (конвейер)
|| - выполняет следующее действие, если предыдущее не справедливо
-e - справедливо (существует)

запуск программы словом test или условие в []
работа программы test:
может вывести результат работы программы через $?
чтобы увидеть значение результата: echo $?
0 - результат положительный
не 0 - результат отрицательный


test 100 -gt 50 && echo "Yes" || echo "No"
или
if [ -e /home/semaev ];
then
echo "Found it"
else
echo "No semaev in home folders"
fi

Для работы с почтой необходимо установить пакет mailutils
отправить письмо пользователю root:
mail -s "info" root

подстановка:
зададим переменной х значение даты
переменная y получает результат выполнения команды uptime -p:
x=$(date)
y=`uptime -p`
echo " Today is $x and we are $y"

использование циклов:
создадим скрипт loop_for_1
в нем пишем:
#!/bin/bash
for x in 1 3 7
do
echo $x
done

добавляем права исполнения на этот скрипт:
chmod +x loop_for_1
запускаем скрипт:
./loop_for_1
покажет:
1
3
7

можно указать последовательность (seq) от 3 до 8:
for x in `seq 3 8`
do
echo $x
done

передадим переменной значение результата команды ls ~(тильда)
покажет список ф-лов родительской папки пользователя:
files=`ls ~`
for x in $files
do
echo $x
done

пока перем. х не равна 5 выводить значение переменной:
x=1
while [ $x -ne 5 ]
do
echo $x
x=$(($x+1))
done

пока переменная не будет = stop, будет повторять вводимые значения:
echo "Type all you want, or type STOP to stop script"
x="Go"
while [ $x != "STOP" ]
do
read x
echo $x
done


РАБОТА С ЖЕСТКИМ ДИСКОМ
=======================
Посмотреть разделы на диске:
fdisk -l
нумерация дисков 1-4 только для основных разделов, 5 и более для логических
Нумерация последней буквы для физ. дисков (serial drive a,b,c)
/dev/sda, sdb, sdc
начинаем работу с диском sdb:
fdisk /dev/sdb
m - для справки
n - добавление нового раздела
t - поменять тип раздела
L - список кодов типов раздела
p - таблица разделов
w - записать изменения
mkswap - форматирование раздела подкачки:
mkswap /dev/sdb2
swapon - включить раздел подкачки:
swapon /dev/sdb2
посмотреть какие есть разделы подкачки:
swapon -s
выключить раздел подкачки:
swapoff /dev/sdb2
mkfs - строит файловую систему
форматирование под файловую систему (ключ -t тип) ext2:
mkfs -t ext2 /dev/sdb1
чтобы переформатировать в другую файл. систему (напр. xfs) используем ключ -f (force):
mkfs -t xfs -f /dev/sdb1
#ф-ловую систему xfs нельзя уменьшить, а м. только увеличить, увеличим логический раздел lvm на 900МБ:
#lvextend --size +900Mg /dev/vg01/lv01
#м. увеличить в блоках посмотрев текущее к-во блоков (xfs_info):xfs_growfs /mnt/ -D 128000 (доведет до к-ва блоков, соотв-но увел-ся и размер диска)
#увеличивать xfs м.сразу без отмонтирования
#проверим созданный размер раздела: lvdisplay /dev/vg01/lv01
#посмотрим инф. о ф/с xfs в точке монтирования /mnt/: xfs_info /mnt/ 
gdisk - работает с большими дисками GPT (GUID Partition Table)
создадим диск с gpt (или переделаем старый)
gdisk /dev/sdb
выбираем комманду - o
y - записать изменения
n - создать новый раздел
+5GB - выбираем конец первого раздела, через 5 Гб
w - записать изменения

parted - программа работающая со всеми дисками
посмотреть разделы:
parted -l
начинаем работу с диском sdb:
parted /dev/sdb
help - открываем help
q - выход
gparted - таже ПО с граф. оболочкой
pvs phisical volume
vgs volume group  
lvs logical volume
fstab - смотрим точки монтирования

утилита резервного копирования ф/системы XFS:xfsdump
для инкрементальных копий xfsdump использует уровни дампа (dump levels):
опция -l указывает уровень дампа (0-9)
полная резервная копия - уровень 0
инкрементальная резерв.копия - уровни 1-9
примонтируем раздел
mount /dev/vg01/lv01 /mnt/
#проверим: mount | tail -n 1
создадим папку в кот-й б.лежать резервная копия:
mkdir /bkp
создадим 1-ю полную резервную копию(-f ф-л точки назначения):
xfsdump -l 0 -f /bkp/dump0 /mnt
#указываем путь до каталога к кот-му примонтирована ф-ловая система /mnt
попросит ввести лейбл, кот-й мы будем вдальнейшем использовать:
вводим "l0"
этот же лейбл еще раз вводим для записи в историю: l0
что-то поменялось, добавили ф-л, теперь сделаем инкрементную копию:
xfsdump -l 1 -f /bkp/dump1 /mnt #копируется только тот ф-л который поменялся
ткже попросит ввести название лейбла 2 раза: вводим l1
удалим измененный ф-л, сделаем еще одну инкрементальную копию:
xfsdump -l 2 -f /bkp/dump2 /mnt
ткже попросит ввести название лейбла 2 раза: вводим l2
утилита восстановления ф-ловой системы XFS:xfsrestore
простой режим xfsrestore:
	восстановление дампа требует идентификатора дампа или метки
	опция -s используется для указания идентификатора сессии
	опция -L используется для указания метки сесии 
	опция -I отображает метки и идентификаторы всех дампов
кумулятивный режим xfsrestore:
	опция -r исп. для восстановления ф-ловой системы из инкрементальной резервной копии
	для восст-я ф-ловой системы из инкрементальной резерв. копии, необходимо добавить опцию -r
интерактивное выполнение:
	опция -i необходима для запуска xfsrestore в интерактивном режиме
	в диалоге доступны команды: help, cd, ls, add, delete, extract
чтобы ознакомиться с историей резервирования (передадим через less для удобства просмотра):
xfsrestore -I | less
восстановимся из резервной копии с лейблом "l0" (/mnt - путь куда хотим восстановиться):
xfsrestore -f /bkp/dump0 -L l0 /mnt
в кумулятивном режиме при восстановлении в этой папке создастся директория xfsrestorehousekeepingdir
в данном каталоге хранится инф-ия о данной резервной копии, к ней может клеится инкрементальная резерв. копия:
xfsrestore -f /bkp/dump0 -L l0 -r /mnt
для восстановления последующих инкрементных копий лейбл указывать не надо, т.к. он будет браться из этой папки:
xfsrestore -f /bkp/dump1 -r /mnt #после этого ф-лы будут добавляться или затираться, в зависимости от резервной копии
если мы удалим каталог xfsrestorehousekeepingdir, то можно б. восстановиться из любой копии, 
как из полной без указания лейбла, иначе выдаст ошибку "/mnt/xfsrestorehousekeepingdir prior to noncumulative restore":
xfsrestore -f /bkp/dump10 /mnt
чтобы просмотреть содержание резервной копии:
xfsrestore -f dump0 -i /mnt/
прочитает дамп и выведет список команд, для работы в интерактивном режиме, исп. команды pwd, help, cd, ls, add, delete, extract
xfsrestore -f /bkp/dump0 -L l0 -r /mnt
командой ls выведем список ф-лов, ком. extract м. запустить извлечение ф-лов из резерв. копии
доп. утилиты:
	xfs_copy - полностью копирует содержимое отмонтированного устройства ф-ловой системы XFS в одно или неск. расположений одновременно
	xfs_metadump - копирует метаданные файловой системы XFS в файл-образ
	xfs_mdrestore - восстанавливает метаданные из образа
	xfs_db - производит отладку ф-ловой системы XFS
	xfs_freeze - приостановка ф-ловой системы XFS
	xfs_repair - починка ф-ловой системы XFS
перед копированием у-ва с ф-ловой сист. XFS вначале нужно его отмонтировать
umount /dev/vg01/lv01
копирование на 2 тома одновременно, с записью лога:
xfs_copy -L /bkp/xfs.log /dev/mapper/vg01-lv01 /dev/mapper/vg01-lv02 /dev/vg01/lv03
проверка и исправление:
xfs_repair /dev/vg01/lv01
для снятия снепшотов исп. заморозка системы:
xfs_freeze -f /mnt/
#считать получиться, но записать - нет, будет висеть и ждать разморозки
разморозить:
xfs_freeze -u /mnt/
----------------------------------------------------------
типы событий: https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/6/html/security_guide/sec-Audit_Record_Types

перенос диска с корневой директорией с большего на меньший
подключаем меньший диск
находим его
fdisk -l
покажет:
Disk /dev/sdb: 10.7 GB
создадим разделы (скажем fdisk-у работать с /dev/sdb):
fdisk /dev/sdb
n #создать новый раздел
p #выбираем primary
#соглашаемся с номером раздела (1-4, default 1)
#соглашаемся начать с первого сектора (First sector, default 2048)
какой размер б. у раздела (просит указать последний сектор или размер раздела(K,M.G))
указываем размер:
+1G
создадим еще один раздел:
n
p
#соглашаемся с номером по порядку
#делаем весь оставшийся размер до конца
создадим lvm
#изменим метку раздела
t
#выбираем номер раздела, для кот-го хотим изменить тип
1
#спрашивает какой hex code(16-ричный код) будет у раздела, нажимаем L для просмотра списка кодов
#для 1-го загрузочного раздела будет метка 83 Linux
83
#продолжаем работу с изменением типа разделов
t
#выбираем номер раздела (default 2), соглашаемся
#для 2-го загрузочного раздела будет метка 8e Linux LVM 
8e
#посмотрим, что получилось, нажимаем p (print)  
p
покажет:
/dev/sdb1 ...
/dev/sdb2 ...
#если все устраивает, нажимаем w-записать изменения
w
после чего форматируем разделы
1-й в ф.систему xfs:
mkfs.xfs /dev/sdb1
т.к. 2-му разделу мы указали метку LVM, необходимо его превратить в LVM
#создай phisical volume
pvcreate /dev/sdb2
#после чего проверим создание через pvs, покажет
#или pvdisplay
PV	VG	Fmt	Attr	PSize	PFree
/dev		lvm2	---	<9.00g	<9.00g
#далее на созданном pisical volume необходимо создать volume group с допустим названием "centos"
vgcreate centos /dev/sdb2
#после чего проверим создание через vgs, покажет
#или vgdisplay
VG	#PV	#LV	#SN	Attr	VSize	VFree
centos	1	0	0	wz--n-	<9.00g	<9.00g
#далее создадим logical volume на всём свободном месте с именем "root" на volume group "centos"
lvcreate -l 100%FREE -n root centos
#м. создать размером 100МБ: -n <lv_name> -L 100Mg <vg_name>
#после чего проверим создание через lvs, покажет
#или проверим командой lvdisplay | less
LV	VG	Attr	LSize	Pool	Origin	Data%	Meta%	Move	Log	Cpy%Sync	Convert
root	centos	-wi-a--	<9.00g
отформатируем созданный раздел (LVM-разделы всегда монтируются к /dev/mapper):
mkfs.xfs /dev/mapper/centos-root
теперь будем копировать данные со старого места в новое место
для этого создадим в корне директорию монтирования для старого диска - old и для нового диска -new
mkdir /old
mkdir /new
#почему мы просто не скопируем корень в новый раздел?
#потому-что новый раздел нам нужно подключить куда-то в ф-ловую систему и м. случится что мы будем копировать этот раздел сам в себя
примонтируем старый загрузочный (/boot) раздел в папку old:
mount /dev/sda1 /old
примонтируем первый раздел диска sdb в папку new:
mount /dev/sdb1 /new
#копирование через cp не всегда корректно передает права, поэтому лучше это делать через rsync
rsync -av /old/* /new/
после этого отмонтируем разделы:
umount /old
umount /new
теперь подключим вторые разделы:
mount /dev/mapper/cl-root /old
#проверить рез-т работы команды м.: mount | tail -n1 
mount /dev/mapper/centos-root /new
теперь также копируем всю инф-ю со старого раздела в новый:
rsync -av /old/* /new/
после отмонтируем старый раздел:
umount /old
теперь будем править новый fstab
смотрим инф-ю о текущих подключенных разделах в fstab:
cat /etc/fstab
покажет:
/dev/mapper/cl-root				/	xfs	defaults	0	0
UUID=c9bfe5df-9915-4af2-ad47-e068d71db2d7	/boot	xfs	defaults	0	0
/dev/mapper/cl-swap				swap	swap	defaults	0	0
он у нас теперь полностью скопирован в новый раздел
узнаем id нового раздела с помощью blkid
покажет:
/dev/sda1: UUID="c9bfe5df-9915-4af2-ad47-e068d71db2d7" TYPE="xfs"
/dev/sda2: UUID="L6R0Eb-4D5U-kTBN-22Fk-UIeZ-c8EF-1RODXK" TYPE="LVM2_member"
/dev/sdb1: UUID="2258ad27-58fc-496f-b514-89a5827dlb9e" TYPE="xfs"
/dev/sdb2: UUID="SejlGi-euy9-Y42P-ro4u-X5SK-a7of-W5Yk6P" TYPE="LVM2_member"
/dev/mapper/cl-root: UUID="d73763b5-cfcl-46al-a711-2460a715a2cb" TYPE="xfs"
/dev/mapper/cl-swap: UUID="8c21a905-la2b-4835-abbf-00453320a9a9" TYPE="swap"
/dev/mapper/centos-root: UUID="42f22b73-4c58-4b46-a76e-2b12ee5790b3" TYPE="xfs"
отредактируем новый fstab:
vi /new/etc/fstab
приводим его к виду:
/dev/mapper/centos-root				/	xfs	defaults	0	0
UUID=2258ad27-58fc-496f-b514-89a5827dlb9e	/boot	xfs	defaults	0	0
сохр,вых
смотрим все точки монтирования в текущей файловой системе командой mount, покажет кучу мусора, но в последних строках б. запись вида:
sysfs on /sys type sysfs (rw,nosuid,nodev,noexec,relatime,seclabel)
proc on /proc type proc (rw,nosuid,nodev,noexec,relatime)
devtmpfs on /dev type devtmpfs (rw,nosuid,seclabel,size=1930096k,nr_inodes=482524,mode755)
.....
/dev/sda1 on /boot type xfs (rw,relatime,seclabel,attr2,inode64,noquota)
#нам нужно, чтобы вся эта инф-я была доступна в новой ф-ловой системе
#видим, что /dev/sda1 в текущей ф-ловой системе смонтирован в /boot
тоже самое нам нужно сделатьь в новой ф-ловой системе, для этого сделаем монтирование:
mount /dev/sdb1 /new/boot
#сейчас у нас lvm centos-root в текущую ф-ловую систему в директорию new, а диск /dev/sdb1 в этой директории /new в директорию /boot (/new/boot)
#опция --bind у mount позволяет подключить часть ф-ловой структуры в другой каталог, при этом не удаляя исходную точку монтирования
подключим /dev в новую ф-ловую систему /new:
mount --bind /dev /new/dev
подключим /sys в новую ф-ловую систему /new:
mount --bind /sys /new/sys
подключим /proc в новую ф-ловую систему /new:
mount --bind /proc /new/proc
теперь изменим текущий корень файловой системы:
chroot /new
теперь если посмотрим корень ф-ловой системы ls /, нам б. отображаться корень /new/
теперь нам нужно сделать grub update, но т.к. в новом загрузчике CentOS grub2 такой ф-ии нет делаем следующее:
старая информация загрузчика находится в ф-ле /etc/default/grub
откроем его, он содержит:
GRUB_TIMEOUT=5
GRUB_DISTRIBUTOR="$(sed 's, release .*$,,g' /etc/system-release)"
GRUB_DEFAULT=saved
GRUB_DISABLE_SUBMENU=true
GRUB_TERMINAL_OUTPUT="console"
GRUB_CMDLINE_LINUX="crashkernel=auto rd.lvm.lv=cl/root rd.lvm.lv=cl/swap rhgb quiet" #отредактируем данную строку со старой инф-ей
GRUB_DISABLE_RECOVERY="true"
исправим данную строчку на новую инф-ию:
GRUB_CMDLINE_LINUX="crashkernel=auto rd.lvm.lv=centos/root rhgb quiet" #также уберем инф-ю о swap-разделе, т.к. его у нас нету
сохр, вых
в директории нового загрузчика grub2 есть свой конфиг:
vim /boot/grub2/grub.cfg
#конфиг grub предыдущ. версии находился в /boot/grub/
найдем утилиту в установщике, кот-я раньше называлась grub-mkconfig:
yum search grub
видим, что есть пакеты grub2-tools.x86_64 : Support tools for GRUB
устанавливаем данный пакет:
yum install grub2-tools
командой grub смотрим все установленные модули и видим, что теперь команда называется grub2-mkconfig
заменяем существующий конфиг командой:
grub2-mkconfig -o /boot/grub2/grub.cfg
теперь нужно установить сам загрузчик:
grub2-install /dev/sdb
выходим из новой ф-ловой системы (мы в нее перемещались командой chroot /new):
exit
выключаем комп и вытаскиваем старый hdd:
poweroff
#после загрузки нас почему-то не пускает залогиниться под пол-лем root
#тогда мы при старте системы, во время выбора варианта системы загрузки нажимаем клавишу "е"
#и выбираем строчку с загрузкой ядра linux
linux16 /vmlinuz-3.10.0-693.5.2.e17.x86_64 root=/dev/mapper/centos-root ro crashkernel=auto rd.lvm.lv=centos/root rhgb quiet
#где rhgb - redhat graphical boot, к-рый показывает заставки и иконки вместо реальной инф-ии загрузки
#quiet - подавляет большинство выводимых сообщений. Поэтому удаляем их из пункта загрузки и нажимаем ctrl+x
#опять загрузиться не получилось, опять при старте выбираем эту строчку и меняем режим ro (read only) на rw (read write) и
#укажем, что б. процессом init, добавляем init=/sysroot/bin/bash_crashkernel=auto нажимаем ctrl+x
linux16 /vmlinuz-3.10.0-693.5.2.e17.x86_64 root=/dev/mapper/centos-root rw init=/sysroot/bin/bash_crashkernel=auto rd.lvm.lv=centos/root rhgb quiet
#грубо говоря мы просто запустили оболочку /bin/bash
сделаем chroot для удобства, чтобы перейти в тот root, который у нас есть в ф-ловой системе:
chroot /sysroot/
смотрим лог аудита:
less /var/log/audit/audit.log #клавишей "G" переходим в конец ф-ла и делаем поиск слова "root" нажав "/" наберем "root"
видим строчку:
type=USER_AUTH ....acct="root"....res=success #значит аутентификация была выполнена успешно
type=USER_ACCT ....acct="root"....res=success
....
type=AVC ....avc: denied {transaction} for pid... #AVC - access vector cache относится к SELinux, был отказ
потом
type=SYSCALL.....success=no.....
после чего происходит запись к-то события
type=USER_END......acct="root"....res=success #успешное завершение сессии пол-ля
type=SERVICE_STOP....res=success #остановка системы после того как пол-ля root не пустило в систему
выходим из режима chroot и возвращаемся в обычный корень командой exit
делаем reboot
т.к. мы определили проблему запуска на уровне SELinux
теперь нам нужно запуститься с выключенным SELinux-ом
для этого в варианте загрузки выбираем вариант с запуском ядра и добавляем к нему выключение Selinux:
linux16 /vmlinuz-3.10.0-693.5.2.e17.x86_64 root=/dev/mapper/centos-root ro crashkernel=auto rd.lvm.lv=centos/root rhgb quiet selinux=0
после того, как у нас теперь получилось войти в систему, после перезагрузке он нас начинает пускать уже в стандартном режиме загрузки

---------------------------------------

FDISK
=====
Для просмотра имеющихся дисков, на sata контролере:
ls /dev | grep sd
lsblk - покажет список дисков и разделов
Если у нас есть созданные разделы, информацию о них можем посмотреть такой командой (sda, sdb,sdc...):
/sbin/fdisk -l /dev/sda
Далее, мы можем переходить к работе с fdisk, для этого вводим команду и в аргументе указываем нужный нам диск, в данном случае «/dev/sda».
fdisk /dev/sda
После чего, попадаем в меню fdisk.
Список доступных командам можно получить введя «m»
Команды:
a   установить/снять флаг загрузочного раздела
b   редактировать метки bsd диска
c   переключить флаг совместности с dos
d   удалить раздел
l   вывести список известных типов разделов
m   показать это меню
n   добавить новый раздел
o   создать новую пустую таблицу разделов в стиле DOS
p   показать существующею таблицу разделов
q   выйти без сохранения изменений
s   создать новый раздел с меткой Sun
t   изменить метку типа раздела
u   изменить отображения/записи блоков
v   проверить таблицу разделов
w   сохранить изменения и выйти
x   дополнительные возможности (только для экспертов)

* Создание разделов fdisk-ом см. файл "linux каталоги"

UUID (это уникальное число тоесть номер раздела жесткого диска)
===============================================================
узнать UUID раздела жесткого диска или какого либо другого блочного устройства:
Листингом в дире с ссылками на устройства:
ls -l /dev/disk/by-uuid/
При помощи специальной утилиты blkid:	
blkid /dev/sda2

Вывод сообщения ядра:
dmesg
Посмотреть лог этих сообщений (соджержит только инф. о загрузке):
cat /var/log/dmesg
Посмотреть дерево процессов:
pstree
-----------------------------------------------------------------

ПРОВЕРКА ФАЙЛОВОЙ СИСТЕМЫ
=========================

inod (номер inod) - идентификатор (местонахождение/метка) ф-ла 
DF (disk free) показывает размер разделов:
df -h
покажет точки монтирования разделов и тип ф-ловой системы:
df -Th
Индексные дискрипторы inods в них хранится информация о владельце, размере, правах доступа ф-лов.
Для каждого файла создается свой inod.
Обычно для их размещение отдается 1% от жесткого диска
показывает кол-во inods, кол-во использованных, кол-во свободных inods для дисков:
df -i

DU (disk usage) показывает что и сколько занимает места
размер папок в текущей директории:
du -h
можно явно указать папку для поиска со вложенными папками:
du -h /home/semaev/*
показывает только один уровень вложения (ключ --summarize):
du -h --summarize /home/semaev/*

показывает размер файлов:
ls -l
показывает номера индексных дискриптеров (inods):
(если восстановить индексный дескриптор после удаления файла - можно восстановить и сам ф-л)
ls -i

FSCK (file system check) проверяет целостность ф-ловой системы
fsck /dev/sdb1
автоматом определяет файл. систему и запускает соотв. программу проверки для этой системы
если не смог определить, то указываем явно:
fsck -t ext4 /dev/sdb1
пишет, что диск смонтирован, вначале нужно отмонтировать:
umount /mnt/hard
папка куда смонтированы диски
повторяем:
fsck -t ext4 /dev/sdb1
монтируем диск обратно:
mount /dev/sdb1 /mnt/hard/

DEBUGFS отладчик файловой системы
с внесением изменений (ключ -w):
debagfs -w /dev/sdb1
вывести содержимое тома (с inods):
debagfs: ls
покажет в формате inod (размер) имя ф-ла
2(12).	2(12).. 11(44)lost+found	12(4028)test.txt
удалить ф-л:
debagfs: rm 1.txt
показать удаленные ф-лы:
debagfs: lsdel
показывает, что есть один удаленный inod под ном. 12
Inode	Owner	Mode	Size	Blocks	Time deleted
12	0	100544	15	1/	1 Mon Jan 19 18:44:12 2015
ideleted inodes found.
восстановить дескриптор удаленного ф-ла и написать желаемое имя восстанавливаемого ф-ла:
undel <12> test.txt

DAMPE2FS делает дамп информации файловых систем ext2/ext3/ext4
вывести на экран дамп диска:
dumpe2fs /dev/sdb1
тоже записать в ф-л:
dumpe2fs /dev/sdb1 > dump.txt
создадим другую ф-ловую систему (можно mkfs, а можно mke2fs):
вначале размонтируем этот диск:
umount /dev/sdb1
создаем:
mke2fs -t ext2 /dev/sdb1
отфильтруем вывод созданного дампа по строке содержащей features:
dumpe2fs /dev/sdb1 | grep features
видим отсутствует информация о журнале

TUNE2FS настроивает настраиваемые параметры файловых систем ext2/ext3/ext4
настроить опцию (ключ-O) иметь журнал (has_journal):
tune2fs -O has_journal /dev/sdb1
превратила fs ext2 в журналируемую
покажет
tune2fs 1.42.9 (4-Feb-2014)
Создание inod'a журнала: done
проверяем
dumpe2fs /dev/sdb1 | grep features
показывает
Filesystem features: has_journal ext_attr resize_inode dir_index и т.д.
Journal features: (done)
т.е. журнал в опциях есть и он пустой
удалить опцию (ключ-O) иметь журнал (has_journal):
tune2fs -O ^has_journal /dev/sdb1
----------------------------------------------------------------------- 
 
МОНТИРОВАНИЕ ФАЙЛОВЫХ СИСТЕМ
============================

посмотрим св-ва диска sdb1:
ls -l /dev/sdb1
посмотрим корень диска:
ls /
монтируем (WINDOWS переводим в онлайн) диск в созданную папку
mount /dev/sdb1 /mnt/hard
команда mount без ключей покажет что смонтировано в системе
отмонтируем диск из системы:
umount /dev/sdb1
перед отмонтированием все программы работающие с ним, открытые ф-лы, должны буть закрыты.
можно отмонтировать все, что примонтировано в папку:
umount /mnt/hard/
файл автоматического монтирования ф-ловых систем: 
cat /etc/fstab
лучше прописывать id устройчтва, но можно и по именам
все параметры прописываются через <tab>
<file system> <mount point> <type> <options> <dump> <pass>
dump - сохранять ли нам файлы автоматом при отключении ОС (внезап.отключение питания) (1-сохранять,0 -не сохранять)
pass - порядок проверки ф-ловых систем (1-у корневой ф-ловой сист."проверка в первую очередь", у всех 
остальных -2, у съемных -0)
запишем:
/dev/sdb1	/mnt/hard	auto	rw,user,auto,noexec	0	2
<type> тип файловой системы можно указать auto
<options> опции можно указать defaults (ф.сист. доступна на чтение/запись, м. находиться исполняемые ф-лы, автоматически монтируется, не может считать пользователь), а можно указать вручную, через запятую
rw (чтение запись),user (любой пользователь м. монтировать и демонтировать),auto (будет автоматически подключать при старте)(noauto - не будет),noexec (никто не сможет запускать исполняемые ф-лы)
<dump> сбрасывать ли при отключении питания информацию указать 0 (не надо)
<pass> тип проверки 2 (указывается для всех файл.систем, кроме корневой)
сохраняем выходим
после можем смонтировать от пользователя указав точку монтирования, а система посмотрит в ф-ле устройство и смонтирует его
mount /mnt/hard/
В десктоповых линуксах монтирование подключаемых устройств происходит автоматом

lsblk - покажет список дисков и разделов
BLKID показать блочное устройство, можно посмотреть id устройства
blkid - покажет все болчные у-ва в системе
blkid /dev/sdb1
покажет:
/dev/sdb1: UUID="ae86eca-f5cc-4564-a142-187652fb08af" TYPE="ext2"
можем в fstab вместо /dev/sdb1 прописать UUID=ae86eca-f5cc-4564-a142-187652fb08af

Чтобы автомат. монтировался cdrom вначале через blkid смотрим имя устройства, потом прописываем в fstab (ключ ro-read only):
/dev/sr0	/media/cdrom	udf,cdfs,iso9660	user,noauto,exec,ro	0	0
сохраняем, потом монтируем
mount /dev/sr0   

после монтирования флешки, чтобы корректно ее вытащить необходимо вначале ее отмонтировать.
umount имя_устр
потом написать комманду, которая выдергивает флешку eject
--------------------------------------------------------------------------------------------

КВОТЫ
=====

Вначале необходимо установить пакет quota:
apt-get install quota
монтируем диск со спец. параметрами (ключи usrquota - пользовательская квота, grpquota - групповая квота),
для этого прописываем параметры монтирования в fstab:
/dev/sdb1	/mnt/hard	auto	rw,user,auto,usrquota,grpquota	0	0
после этого делаем монтирование:
mount /dev/sdb1
чистим квоты, если таковые были:
quotaoff /mnt/hard

создадим квоты (ключ -cug создаст квоты для пользователей и групп):
quotacheck -cug /mnt/hard
файл. система ext4 поддерживает только квотирование дисков (мы не можем установить квоты на папки)
после этого в папке /mnt/hard появляются ф-лы aquota.group и aquota.user
Чтобы отредактировать эти ф-лы исп. команда edquota (ключ -u для юзера -g для группы пользователей):
edquota -u semaev
soft (Кбайт)- мягкая квота, юзер может превысить, но не > 1 недели, потом блокирует, hard (КБайт)- жесткая квота блокирует сразу;
blocks - сколько пользователь занимает 1-КБайтных блоков (сколько Килобайт)
inodes - сколько можно создать ф-лов и папок (тоже указ-ся soft и hard-квоты)
edquota - м. отредактировать значения квот
edquota -t
потом необходимо включить квотирование:
quotaon - чтобы включить квотирование
quotaon /mnt/hard
создадим пустой ф-л:
touch /mnt/hard/file.txt
посмотрим как изменились квоты
edquota -u semaev
стало blocks - 4, inodes - 2
редактируем ф-л, к-во блоков увеличилось до 8, потом когда значение превысит лимит hard-квоты не разрешит работать на этом разделе.
посмотреть отчет по квотам:
repquota /mnt/hard/
столбец grace показывает период блокировки
warnquota - посылает email пользователям превысившим квоту
----------------------------------------------------------

ПРАВА ДОСТУПА К ФАЙЛАМ И ПАПКАМ
===============================
chown	- установка владельца
chgrp	- установка группы владельцев
chmod	- установка прав доступа

сменить владельца ф-ла 1.txt на andrey:
chown andrey 1.txt
сменить группу владельцев ф-ла 1.txt на гр. testers:
chgrp testers 1.txt
или та же операция
chown :testers 1.txt
поменять одновременно владельца и группу владельцев:
chown andrey:testers 1.txt
рекурсивное изменение владельца папки с вложениями:
chown -R andrey Folder

первая буква хар-зует тип оюъекта (d-directory, l-link):
drwxr-xr-x 2 semaev testers 4096 нояб. 11 13:40 Folder
-
запретим всем запускать ф-л (ключи ugo 'user group other'):
chmod ugo-x 1.txt
существующему юзеру (владельцу) добавить права на выполнение:
chmod u+x 1.txt
поменять права на файл (юзеру-чтение,запись;группе-чтение;остальные-нет прав):
chmod 640 1.txt
дать всем полные права:
chmod 777 1.txt
разрешить всем (юзеру,группе,остальным) выполнение:
chmod +x 1.txt
чтобы попасть внутрь папки должно стоять execute (выполнение) 

umask			- маска создания файлов и папок (user file creation file)
suid (sid user id)	- бит запуска от имени владельца
sgid			- бит запуска от имени группы владельцев
sticky			- бит защиты содержимого

Параметр маски безопасности с которой создаются файлы и папки по умалчанию м. посмотреть в ф-ле
/etc/login.defs:
grep UMASK /etc/login.defs
покажет 
UMASK	022

установка битов для запуска от имени обычного пользователя (опасно):
Позволяет всем пользователям запускать от имени владельца файла
chmod u+s 1.txt
ls покажет права (x заменяется на s)
-rwsrwx---
также статистика по ф-лу:
stat 1.txt
покажет:
Доступ: (4770/-rwsrwx---)

убрать бит:
chmod u-s 1.txt

добавить бит для группы пользователя:
chmod g+s 1.txt
статистика покажет
Доступ: (2770/-rwxrws---)
добавить и юзеру и группе stiky-бит:
chmod ug+s 1.txt
статистика покажет
Доступ: (6770/-rwsrws---)
можно убрать все sticky-биты:
chmod 0755 1.txt
--------------------------------------------------------------------------------------------------
поиск ф-лов с завышенными правами доступа
найти в корне системы ф-лы на которых установлено разрешение (ключ -perm) на пол-ля установлен suid (ключ -u+s)
find / -perm -u+s
первый раз м. найти не все файлы, если б.д. была не проиндексирована - н.запустить второй раз
увидим ф-лы:
find: '/run/user/1000/gvfs': Отказанов доступе
/usr/sbin/pppd
/usr/sbin/X
/usr/sbin/sudo
/usr/sbin/mtr
/usr/sbin/pkexec
/usr/sbin/newgrp
/usr/sbin/passwd
/usr/sbin/chsh
/usr/sbin/chfn
/usr/sbin/gpasswd
/usr/lib/eject/dmcrypt-get-device
/usr/lib/dbus-1.0/dbus-daemon-launch-helper
/usr/lib/policykit-1/polkit-agent-helper-1
/usr/lib/openssh/ssh-keysign
/usr/lib/pt_chown
/usr/lib/x86_64-linux-gnu/oxide-qt/chrome-sandbox
/bin/fusermount
/bin/su
/bin/ping
/bin/umount
/bin/ntfs-3g
/bin/mount
/bin/ping6
если кроме этих ф-лов появились файлы, которуе мы не знаем и не устанавливали - нужно срочно разобраться с ними
для проверки посмотрим св-ва одного из найденных ф-лов ping:
ls -l /bin/ping
покажет:
-rwsr-xr-x 1 root root  44168 мая 7 2014 /bin/ping
suid не такой страшный, важно понять какого юзера мы будем замещать.
Если обыч. юзер явл. владельцем ф-ла и он ставит на него suid, это не страшно, потому что он не явл. супер пол-лем su
поэтому наиболее важно найти те ф-лы у которых владелец root у которых установлен suid:
find / -user root -perm -u+s
аналогичная команда:
find / -user root -perm +4000
аналогичная команда для sgid:
find / -perm -g+s
или с группой root и стоит бит на замену группы:
find / -group root -perm -g+s
найди в корневой ф-ловой системе ф-лы, разрешения на которые установлены ("/" выбор условий "или") suid или guid:
find / -perm /u+s,g+s
найди в корневой ф-ловой системе ф-лы, разрешения на которые установлены suid и guid:
find / -perm -u+s,g+s
покажет 1 ф-л:
/usr/bin/X
-----------------------------------------------------------------------------------------------------------------------
мягкие и жесткие ссылки:
inod (номер inod) - идентификатор (местонахождение/метка) ф-ла (индексный дескриптор)
мягкие ссылки опираются на полное имя ф-ла (занимают определенное место на диске, м. создавать ссылки на папки)
в правах доступа указывается первая буква l
например
lrwxrwxrwx
жесткая ссылка указывает на тот же самый inod (изменение имени исходного ф-ла не затрагивает данную ссылку, не занимают места на диске
нельзя создать ссылку на другой ф-ловой системе, нельзя создавать ссылки на папки)
LN - создает ссылки
без аргументов создает жесткую ссылку на файл, мягкую с ключем -s
жесткая ссылка на файл file.txt:
ln file.txt hard.txt (м.б без расширения)
мягкая (символическая) ссылка на файл file.txt:
ln -s file.txt soft.txt
создать мягкую ссылку на файл file.txt в папке folder:
неправильная запись (создаст битую ссылку, т.к. б. искать ф-л в папке Folder):
ln -s file.txt Folder/
правильно писать полный путь до файла:
ln -s /home/semaev/file.txt Folder/
ls -l вторым столбцом покажет сколько есть ссыло на данный inod
например показывает что есть 2 ссылки (т.е. файл и 1 линк):
-rw-rw-r--	1	semaev	semaev	0 февр. 11 13:14	copy.txt
-rw-rw-r--	2	semaev	semaev	0 февр. 11 13:14	file.txt
-rw-rw-r--	2	semaev	semaev	0 февр. 11 13:14	hard.txt
ls -li (покажет 3-им столбцом)
inod	security	links	user	group	size	data/time		name
408502	-rw-rw-r--	1	semaev	semaev	0	февр. 11 13:14		copy.txt
408507	-rw-rw-r--	2	semaev	semaev	0	февр. 11 13:14		file.txt
408507	-rw-rw-r--	2	semaev	semaev	0	февр. 11 13:14		hard.txt

Структура FHS (File Hierarchy Structure)
/bin	- базовые бинарники команд;
/boot	- файлы загрузчика;
/dev	- устройства;
/etc	- конфигурация ПК;
/home	- домашние папки;
/lib	- библиотеки и модули ядра;
/proc	- информация о работающей системе;
/media	- монтирование носителей;
/mnt	- монтирование носителей;
/opt	- дополнительное ПО;
/root	- домашняя папка админа;
/sbin	- основные программы настройки системы;
/srv	- данные для системных служб;
/tmp	- временные ф-лы;
/usr	- бинарные файлы пользователей;
/var	- переменные

grep	- утилита поиска по содержимому;
find	- утилита поиска фалов по св-вам;
locate	- быстрый поиск файлов;
which	- поиск команды;
type	- вывод точной команды;
whereis	- поиск команды, исходников и мануала

поиск файлов в корне, всего, что имеет отношение к mail (точное совпадение, работает с символами/ключами):
find / -name mail

LOCATE - тоже самое, только быстрее (все, что содержит слово mail)
ищет только в определенных местах, работает только с индексной локацией
Раз в день запускает программу find и индексирует ф-лы создавая БД нахождения файлов
locate mail
покажет настройки поиска locate:
cat /etc/updatedb.conf
не ищет в ф-лах .git .bzr .hg .svn
не ищет в папках /tmp /var/spool /media /home/.ecryptfs
не ищет в файловых системах nfs,smbfs,iso9660...
вручную запустить обновление базы поиска locate:
updatedb

покажет где находится команда ls:
which ls
покажет
/bin/ls

покажет с какими ключами по умолчанию запускается команда ls:
type ls
покажет
ls является алиасом для 'ls --color=auto'

показывает подробную инф. по программе:
whereis ls
покажет где находится и в какой пакет входит:
ls: /bin/ls usr/share/man/man1/ls.1.gz
-------------------------------------------------------------

Управление SYSTEMD
==================
Unit - модули которыми оперирует systemd
.service - службы;
.mount - точки монтирования;
.device - устройства;
.socket - сокеты
.target - группировка последовательно запускаемых юнитов

Директория с юнитами по умолчанию:
/usr/lib/systemd
Директория с управляемыми юнитами:
/etc/systemd

Runlevel	target			описание
-------------------------------------------------

0		poweroff.target		Выключение
1		rescue.target		Однопользовательский режим
2,4		multi-user.target	Настраиваемый режим
3		multi-user.target	Многопользовательский режим
5		graphical.target	Графика
6		reboot.target		Перезагрузка


Управление системы (контроль системы) осущ. командой SYSTEMCTL
==============================================================
Просмотр запущеных юнитов (устройства, точки монтирования, службы, сокеты):
systemctl list-units
Просмотр юнитов, которые не запустились:
systemctl --failed
Просмотр юнитов, которые отвечают за запущенные службы:
systemctl list-units --type=service
Просмотр юнитов, которые отвечают за запущенные таргеты:
systemctl list-units --type=target

Просмотр статуса/запуск/стоп службы crond:
systemctl status crond
systemctl stop crond
systemctl start crond

Перейти в однопользовательский режим:
systemctl isolate rescue.target
или (как в sysv)
telinit 1

Сделать "Однопользовательский режим" таргетом по умолчанию:
systemctl set-default -f multi-user.target
где f-форсировать

Управление службой журналирования journald
==========================================
Просмотр событий по мере их возникновения:
journalctl -f

Вывод последних 10 событий:
journalctl -n 10

Вывод событий по UID пользователя:
journalctl _UID=0
-----------------------------------------

MY SQL
======
устанавливаем пакет сервера с клиентом:
apt-get install mysql-server
подключаемся к БД под юзером root (если у root задан пароль ставим ключ -p и вводим пароль ):
mysql -u root
появится ком. строка mysql
mysql>
создадим БД:
CREATE DATABASE cars;
подключаемя к БД:
USE cars;
создадим таблицу с полями:
CREATE TABLE new (brand VARCHAR(10), madel VARCHAR(10), year YEAR, coast INT);
показать таблицы БД:
SHOW TABLES;
показать структуру таблицы new:
DESCRIBE new;
выйти из mysql:
exit
создадим текст. ф-л со значениями БД с разделителем полей <tab>
для импорта текст. файла сначала необходимо включить эту возможность в mysql:
mysql --local-infile=1 -u root
для импорта входим в режим mysql и открываем таблицу cars:
USE cars;
загрузить данные из локального input-ф-ла:
LOAD DATA LOCAL INFILE "new.txt" INTO TABLE new;
посмотрим что импортировалось:
SELECT * FROM new;
сделать вставку данных в поля (brand, model, year) таблицы:
INSERT INTO new (brand, model, year) VALUES ('Daewoo','Nexia','2015');
удалить из таблицы информацию о Matiz:
DELETE FROM new WHERE model='Matiz';
подключаемся сразу к таблице БД:
mysql cars -u root
показать таблицы:
SHOW TABLES;
показать KIA 215 года:
SELECT * FROM new WHERE brand="KIA" AND year="2015";
изменить информацию в таблице:
UPDATE new SET model='KUGA' WHERE model='FOCUS';
вывести все из таб-цы new где поле brand= полю brand из таб. used:
SELECT * FROM new JOIN used ON new.brand = used.brand;
выбрать все из таб. new отсортировав по полю brand:
SELECT * FROM new ORDER BY brand;
группировать по полю brand:
SELECT * FROM new GROUP BY brand;
------------------------------------------------------------------

ФАЙЛОВЫЙ СЕРВЕР SAMBA
ПРОГРАМНЫЙ RAID
=====================

Смотрим какие диски установлены:
fdisk -l
Создадим разделы на диске /dev/sdb:
fdisk /dev/sdb
создадим новый раздел: n
выберем primary: p
соглашаемся создать раздел на весь диск
для выбора файловой системы нажимаем: t
создадим linux raid autodetect: fd
посмотрим результат: p
запись изменений: w
На втором диске создадим такой же раздел (/dev/sdc)
Для создания программного рейда используем программу mdadm
Установим ее:
apt-get install mdadm
Запустим ее с ключами (--create создать, --verbose показать, визуально,
диск рейда md0 --level=1 (1 уровень "зеркало"), --reid-devices=2,
указываем тома которые будут использоваться sdb1 sdc1 ):
mdadm --create --verbose /dev/md0 --level=1 --raid-devices=2 /dev/sdb1 /dev/sdc1
покажет:
mdadm: array /dev/md0 started
посмотреть процесс создания:
cat /proc/mdstat
чтобы смотреть процесс в реальном времени (обновление каждые 2 сек):
watch cat /proc/mdstat
посмотрим конф. файл mdadm:
cat /etc/mdadm/mdadm.conf
покажет из каких устр-в собирается массив (--detail детально,--scan просканировать,--verbose показать):
mdadm --detail --scan --verbose
Чтобы после перезапуска сказать системе, что нужно собирать диск из дисков...
в ф-л конфига нужно будет дописать:
echo "Device partitions" >> /etc/mdadm/mdadm.conf
допишем в файл предыдущую команду (используя команду awk):
mdadm --detail --scan --verbose / awk '/ARRAY/ {print}' >> /etc/mdadm/mdadm.conf
в конфиг также м. дописать адрес почты на которую будут отправляться сообщения о критич. состоянии рейда:
(если настроен почтовый сервер)
echo "MAILADDR mberdyugin@gmail.com" >> /etc/mdadm/mdadm.conf
после создания рейда диск md0 будет показан отдельным устройством в системе (fdisk -l)
после создания этого диска, на нем тоже нужно будет создать ф-ловую систему:
fdisk /dev/md0
n
p
t (тип ф-ловая система линукс "83")
покажет, что создался раздел (/dev/md0p1 "партиция 1"), запишем изменения: w
форматируем раздел:
mkfs.ext4 /dev/md0p1
чтобы диск с raid-массивом не менял свое имя "md0" после перезагрузки системы напишем:
обновить диск initram, который создается при старте системы в оперативной памяти
update-initramfs -u

проверим впорядке-ли raid-массив:
cat proc/mdstat
покажет:
md0: active (auto-read-only) raid1 sdc[1] sdb[0]
смонтируем диск с raid в папку /data:
mount /dev/md0p1 /data
посмотрим разрешения на диск смонтированный в папку:
stat /data
сделаем группу semaev группой владельцев ф-ла:
chown root:semaev data
поставим полные права для владельца и группы владельца ф-ла:
chmod 775 data
чтобы после перезагрузки системы автомат. монтировался в эту папку:
узнаем id раздела raid:
blkid
установим пакет для работы с мышью:
apt-get install gpm
(скопировать - enter, втавить - нажать scroll мыши)
допишем в файл /etc/fstab:
UUID=35gf3ec8-e5ff-4828-hgh...	data	ext4	defaults	0	0

при сбое одного из дисков raid-массива м. выйти сообщение закрытое квадратиками.
Говорится, что устр-во смонтированное в папку /data не может б. смонтировано из-за отсутствия одного из дисков
Предоставляется выбор нажать S (skipe- пропустить и продолжить работать дальше не собирая этот диск) или М
(перейти в режим manual recovery).
В режиме manual - запускается run level 1 (не работают никакие ПО и сервисы)
Нажимаем S и смотрим:
cat /proc/mdstat
покажет:
md0: inactive sdb1[0] (S)
sdb0 - inactive (не работает), есть только диск sdb1
чтобы запустить raide-массив для начала нужно его остановить:
mdadm --stop /dev/md0
теперь raid-массив нужно пересобрать:
mdadm --assemble --scan
стартует его с одним диском из 2-х
теперь смонтируем этот диск пока вручную:
mount /dev/md0p1 /data
посмотрим raid:
cat /proc/mdstat
покажет:
md0: active raid1 sdb1[0]
посмотреть детальную информацию по raid-диску:
mdadm --detail /dev/md0
покажет, что один диск degraded
подключим новый диск
посмотрим какие есть диски:
fdisk -l
(можно на него скопировать mbr или gpt, но мы поступим по старому):
в системе он обозначен под именем /dev/sdc
подготовим диск для raid-массива:
fdisk /dev/sdc
n
p
t
fd
укажем этот диск, как 2-й диск для raid-массива (--add добавить том диска /dev/sdc1):
mdadm /dev/md0 --add /dev/sdc1
запустит процесс синхронизации
покажет что передобавил том /dev/sdc1:
mdadm: re-added /dev/sdc1
проверяем:
cat /proc/mdstat
покажет:
md0: active raid1 sdc[2] sdb1[0]
-------------------------------------------------------------------------------------

SAMBA
=====
http://smb-conf.ru/

создадим папку /data/shared
mkdir /data/shared
посмотрим разрешения:
stat shared/
установим пакет samba:
apt-get install samba
настройки файл. сервера в конфигурационном файле:
/etc/samba/smb.conf
скопируем оригинал на всяк случ.:
cp smb.conf smb_orig.conf
в нем:
где хранятся пароли (встроенная БД tdsam):
passdb backend = tdbsam
программа исп. для проверки паролей:
passwd program = /usr/passwd
диалог паролей:
passwd chat = *Enter\snew\s*\spassword:*....
PAM -подключаемый модуль аутентификации
Допишем в файл отдельную секцию для работы с нешей папкой:
[Shared folder]
как будет называться папка по сети:
comment = NewName
путь к папке:
path = /data/shared
наследование icls (access control list):
наследование безопасности (маска безоп. вышестоящей папки)
inherit acls = yes
чтобы наследовался владелец папки:
inherit owner = yes
наследовать разрешения:
inherit permissions = yes
сделать доступной для записи в нее:
writable = yes
если только для чтения - значение no
пользователи которые имеют право работать (могут подключаться):
valid users = semaev
пользователи которые имеют доступ "только на чтение":
read list = semaev
пользователи у которых есть доступ только на запись:
write list = semaev
принудительно, чтобы пользователь был buh1:
force user = buh1
принудительно, чтобы группой пользователей была Buhs:
force group = Buhs
заменить маску создания файлов и папок:
create mask = 0777
можно не вводить логин и пароль:
guest ok = yes
в конце ф-ла оставляем пустую строку (иначе последние значения не увидит)

запустим утилиту проверки конфигурации samba (сама или подсказывает или меняет):
testparm
надо добавить локального пользователя semaev в базу данных пользователей samba:
ключ -а добавить
smbpasswd -a semaev
спросит пароль для входа пользователя в samba
после вноса изменений в samba неободимо ее перезапускать (демон smbd):
service smbd restart

создадим группу пользователей Buhs в samba:
groupadd Buhs
создадим пользователей в этой группе (ключ -G):
useradd -G Buhs buh1
зададим для юзера buh1 пароль:
passwd buh1
создадим папку /data/shared2 и поменяем владельца и разрешения на buh1:
mkdir shared2
chown buh1:semaev shared2
chmod 770 shared2 
открываем конфиг samba и создаем для каждой общедоступной папки свою секцию с настройками доступа

aptitude - установщик
обновляет информацию о своих репозиториях (линки серверов) установщика пакетов aptitude:
aptitude update
посмотреть информацию о пакете winbind (используется для привязки к домену):
aptitude search winbind
статус р - показывает, что пакет не установлен
также для работы samba с доменом нужны пакеты:
winbind - осуществляет привязку к домену
krb5-user - клиент протокола kerberos
ntp (network time protokol) - используется для синхронизации времени в домене
aptitude install winbind krb5-user ntp
при установке kerberos5 попросит ввести имя домена (kemont.kz), имена контроллеров домена через пробел (srvdc01.kemont.kz)
и кто является первичным контроллером
еще необходимо доустановить еще след. пакеты (хотя возможно они уже установились):
libpam-krb5 - библиотека модуля pam (plugin authentication module) для kerberos5
libpam-winbind - библиотека модуля pam для winbind
libnss-winbind - библиотека nss для winbind
aptitude install libpam-krb5 libpam-winbind libnss-winbind

в ubuntu параметры dns лежат в ф-ле:  /etc/resolv.conf
если у нас статическая адресация, то нужно править ф-л: /etc/resolvconf/resolv.conf.d/head
все что напишем сюда, будет автоматически добавляться в ф-л /etc/resolv.conf
для того, чтобы по dhcp получить корректную адресацию можно отредактировать ф-л: /etc/dhcp/dhclient.conf
в нем нужно откомментировать 2 строки:
1. перезаписать имя домена (supersede domain-name "kemont.kz";)
2. переуказать имя dns-сервера (prepend domain-name-servers 192.168.114.15;)
тогда он будет игнорировать настройки dhcp-сервера и брать, что мы укажем.
Чтобы переименовать имя компа, правим ф-л: /etc/hostname
при статич. адресации явно указываем соответствие имен (c dns-суфиксом) адресам в ф-ле: /etc/hosts
192.168.114.15	srvdc01.kemont.kz
проверим правильность получения информации о хостах командой nslookup
nslookup srvdc01
настроим демон времени:
/etc/ntp.conf
указываем сервером времени вместо списка серверов server ntp.ubuntu.com.... имя нашего контроллера домена:
server srvdc01.kemont.kz
чтобы применились изменения рестартуем демон ntp:
/etc/init.d/ntp restart
проверяем настройки kerberos:
/etc/krb5.conf
д.б. правельно заполнены строчки:
default_realm = KEMONT.KZ
kdc = srvdc01.kemont.kz
admin_server = srvdc01.kemont.kz
в секции [domain_realm] дописываем:
.kemont.kz = KEMONT.KZ
kemont.kz = KEMONT.KZ
проверяем вход в домен (под администратором домена adadmin) для этого мы должны запросить билет kerberos у контроллера домена (kinit - kerberos initialisation):
kinit adadmin@kemont.kz
после ввода пароля пускает
чтобы это проверить вводим команду klist (kerberos list) - покажет информацию о полученном билете kerberos

отредактируем файл конфигурации samba /etc/samba/smb.conf
в рабочей группе указываем короткое имя (без суфикса):
workgroup = KEMONT
после него дописываем параметр:
realm = KEMONT.KZ
после строки server string след. строки (кто у нас будет отвечать за безопасность active directory service):
security = ADS
методы аутентификации (winbind (windows binding)- набор/пакет ПО отвеч. за привязку к Windows, ищет инф. о пользователях и паролях во всех местах):
auth methods = winbind
чтобы winbind умел пробрасывать пользователей домена на нашу локальную машину:
winbind enum users = yes
тоже самое по группам:
winbind enum groups = yes
winbind использовать домен по-умолчанию (чтобы исп. в написании пользователя короткое имя, а не semaev@kemont.kz):
winbind use default domain = yes
разделитель в написании объектов домена (например \ - kemont\mberdyugin):
winbind separator = /
чтобы правильно выдавались id доменным учеткам (м.было шарить для доменных учеток) следует добавить диапазоны id:
idmap config * : range = 10000-20000
можно закоментировать строку (роль сервера - автономный сервер):
#server role = standalone server
БД паролей:
#passdb backend = tdbsam
настройки pam:
#obey pam restrictions = yes
синхронизация паролей UNIX:
#unix password sync = yes
программы для паролей:
#passwd program = /usr/bin/passwd %u
#passwd chat = ...
#pam password change = yes
#map to guest = bad user
запретим гостей:
#usershare allow guests = yes
секцию print$,printers
после выхода проверяем конфиг через testparm
утилита сама увеличивает лимит подключений к самбе, роль сервера на "член домена", соглашаемся нажимаем ENTER
на десктоповых версиях linux нужно проверить, что службы samba и winbind находятся в режиме автозапуска:
service winbind status
теперь добавим сервер samba в домен (с правами доменного юзера adadmin):
net ads join -U adadmin@kemont.kz
нужно указать ns (name service) switch, что всю информацию нужно брать в winbind:
для этого правим /etc/nsswitch.conf
там указано где ищется информация о пользователях, группах и т.д.
меняем строки:
passwd:	compat
group: compat
shadow: compat
на
passwd: files winbind
group: files winbind
shadow: files winbind
закрываем
перезагружаем сервер:
shutdown -r now
проверяем что linux понимает юзеров (-u) и группы (-g) windows:
wbinfo -u
wbinfo -g
должен их показать
команда id д.показать id пользователя
локального:
id semaev
доменного (должны пробрасываться в linux им д.присваиваться id в локальной системе):
id adadmin
проверим все ли пользователи получили id-шники (смотрит на конф. /etc/nsswitch.conf):
getent passwd
тоже для групп:
getent group
сменим владельца на доменную учетку для папки Shared (с ключем -v (verbose) визуально покажет рез-т команды):
chown -v adadmin:semaev Shared/
можно с группой владельцев "Пользователи домена":
chown adadmin:"Пользователи домена" Shared/
при работе в домене в конф. ф-ле samba не нужно для шар прописывать эти параметры (станет разрешено всем всё), тогда
доступ к ресурсам будет организовываться на уровне ф-ловой системы:
valid users,read list,write list,force user,force group
--------------------------------------------------------------------------------------------------------------------

ГРАФИЧЕСКАЯ СИСТЕМА X11
=======================

ищем пакет содержащий xorg:
apt-get update
apt-cache search xorg
для удобства чтения вначале сохраняем вывод в ф-л xorg.txt, затем его постранично посмотрим (стрелками вверх вниз):
apt-cache search xorg > xorg.txt
less xorg.txt
нашли
xorg - X.Org X Window System 
запускаем установку xorg:
apt-get install xorg
сконфигурировать установленный оконный сервер:
X -configure
конф. ф-л будет находиться:
/home/semaev/xorg.conf.new
все логи находятся:
/var/log/xorg.0.log
(WW) - строки сообщений warning
(II) - строки информационных сообщений
(EE) - строки сообщений error
запустим графическую подсистему (в ubuntu):
startx
после этого можно запустить любое приложение которое использует для вывода граф. подсистему (например firefox)
но лучше сразу установить граф. среду (gnome и т.д.), она корректно будет работать с оконной подсистемой.
команда xwinfo показывает информацию об активном окне:
xwinfo
и выбираем окно приложения
В ubuntu desktop при нажатии ctrl+alt+F1 из адаптированной консоли переключается в системную консоль терминала tty (teletype)
ctrl+c закроет текущий терминал
ctrl+alt+F2 откроет еще 2-ю консоль tty2 и т.д.
в граф. среде переключение м/у терминалами осущ. компбинацией Ctrl+Alt+F1 — Ctrl+Alt+F6
в текстовом режиме переключение м/у терминалами осущ. компбинацией Alt+F1 — Alt+F6
покажет в каком терминале находимся в текущий момент: tty
завершить сеанс работы с системой в одном из терминалов м. комбинацией Ctrl+d
Можно завершить сеанс работы и введя одну из команд logout или exit
ctrl+alt+F7 вернемся в наш терминал с граф. оболочкой (display 0)
покажет какой сейчас активный дисплей:
echo $DISPLAY
покажет:
:0
запустим еще одну оконную подсистему:
startx
горячая клавиша вызова терминала: ctrl+alt+t
если в нем напишу echo $DISPLAY
покажет:
:1.0 (теперь используется 1-й монитор)
можно указать на каком дисплее я хочу запустить графику:
startx -- :5
команда xhost разрешает удаленным приложениям использовать мой монитор (добавит этот хост в acl для x11):
xhost +192.168.0.55
на удаленной машине, чтобы захватить мой монитор нужно написать (ip моей машины:мой активный монитор):
для этого x-сервер (моя машина) д.б. спец.настроен
DISPLAY=192.168.0.10:0.0

менеджер терминалов TMUX:
позволяет открывать неск. терминалов в одном окне

---------------------------------------------------------------------------------------------------------

МЕНЕДЖЕРЫ ДИСПЛЕЯ GDM,KDM,XDM
=============================

для ubuntu:
установим дисплей-менеджеры (только окно входа в систему):
apt-get install gdm kdm xdm
настройки дисплей менеджера:
/etc/X11/default-display-manager
покажет какой менеджер используется, например "/usr/sbin/gdm"
можно поменять используемый dm командой или изменить конфигурационный ф-л:
dpkg-reconfigure kdm
появится окнос выбором дисплей-менеджера
в конф.ф-л запишется какой менеджер используется "/usr/sbin/kdm"
после выполнения reboot, окно входа поменяется
чтобы отключить gdm, зайдем в его конф.ф-л:
/etc/init/gdm.conf
правим значения runlevel, на которых он может стартовать и останавливаться (ставим не запускать на логоне runlevel 2)
чтобы отключить xdm нужно выполнить (-f force):
update-rc.d -f xdm remove
настройки gdm хранятся:
/etc/dconf/db/gdm.d/
--------------------
добавим приветствие, для этого в папке нужно создать ф-л:
/etc/dconf/db/gdm.d/01-banner-message
(для ubuntu)
заполним его:
[org/gnome/login-screen]
banner-message-enable=true
banner-message-text='Greetings, earthlings!'
после создания ф-ла обновляем БД менеджера дисплея gnome:
dconf update
перегрузим систему: reboot
в этом ф-ле так-же редактируется фон рабочего стола, выпадающий список, расположение иконок и т.д.

чтобы тоже самое проделать с менеджером дисплея xdm
поменяемменеджер на xdm
dpkg-reconfigure xdm
переходим в папку:
/etc/x11/xdm
откроем ф-л /etc/x11/xdm/Xresources
ищем параметр xlogin*greeting и вводим любое значение
xlogin*greeting: Welcome, dear friends!
делаем reboot
также здесь можно определить ниспадающий список пользователей, можно спрятать пользователей списка и т.д.

чтобы тоже самое проделать с менеджером дисплея kdm
поменяемменеджер на kdm
dpkg-reconfigure kdm
переходим в папку:
/etc/kde4/kdm
открываем инициализационный скрипт
vi /etc/kde4/kdm/kdmrc 
ищем слово welcome:
/welcome
находим строку:
Default is "Welcome to Kubuntu at %n"
можно раскоментировать переменные указанные выше после строчки:
The headline in the greeter. The following character pairs are replaced:
%h - выводит имя машины
но все это не будет работать, т.к. идет привязка к теме раб. стола
можно поменять настройки темы (установлена oxygen), строка:
Theme=/usr/share/kde4/apps/kdm/themes/oxygen
идем в папку с темами:
cd /usr/share/kde4/apps/kdm/themes/
открываем ф-л oxygen
vi /usr/share/kde4/apps/kdm/themes/oxygen
видим ссылку наф-л oxygen.xml
открываем его
oxygen.xml
в нем ищем строчку:
<stock type="welcome-label"/>
она говорит о типе приветствия
меняем на свою фразу и перегружаем систему

lightdm - облегченный дисплей-менеджер
по умолчанию на ubuntu desktop уже установлен
для его установки на ubuntu server пишем:
apt-get install lightdm
потом нужно будет ставить еще доп. пакеты
заходим в его конф. файл
/etc/lightdm/lightdm.conf
здесь можно поставить автологин для юзера:
autologin-user=semaev
мануал по работе с lightdm находится в /usr/share/doc/lightdm/lightdm.conf.gz
распакуем его:
gunzip lightdm.conf.gz
смотрим:
less lightdm.conf
по умолчанию этот дисплей-менеджер управляется темой /usr/share/xgreeters/unity-greeter.desktop
установим тему lightdm-gtk-greeter:
apt-get install lightdm-gtk-greeter
после чего она появится в папке /usr/share/xgreeters/
добавим строчку с этой темой в конф. файл:
greeter-session=lightdm-gtk-greeter
перегружаем и видим новую тему входа в систему

дисплей менеджер для CENTOS (red hat systems)
установим несколько пакетов д.м.GNOME с пом. yum
yum groupinstall "GNOME Desktop" "Graphical Administration Tools"
в CENTOS возможно только использование дисплей-менеджера GNOME
можно его также выбрать при установке
-----------------------------------------------------------------------------------------------

УПРАВЛЕНИЕ ПОЛЬЗОВАТЕЛЯМИ И ПАРОЛЯМИ
====================================

файл БД в котором хранятся сведения пользователей, есть доступ для всех пол-лей:
/etc/passwd
содержит например:
имя пол-ля:х-говорит, что пароль хран-ся в теневой папке:id user:id group:прочая информация о группе:домашняя папка пол-ля:оболочка, которая используется при входе (в д.сл. пол-ль games не может войти в систему используя стандартный экран входа(дисплей-менеджер))
games:x:5:60:games:/usr/games:/usr/sbin/nologin
например у обыч пол-ля последнее значение: /bin/bash - используется для входа в систему
файл БД в котором хранятся сведения о группах, есть доступ для всех пол-лей:
содержит например:
группа пол-лей:пароль хранится в теневой папке:id group:члены группы cdrom:
cdrom:x:24:semaev
ф-л в котором хранятся теневые пароли, доступ только для пол-ля root:
/etc/shadow
содержит например:
имя пользователя:*-пароль закрыт, т.е. отсутствует (нельзя залогинится стандартным диалогом входа) !-говорит о том, что пароль существует и заблокирован, но мы можем стандарт. командами его разблокировать
games:*:16547:0:99999:7:::
или
имя пол-ля:зашифр. пароль:срок к-рый прошел с последнего изменения пароля в днях (по умол. с 1970г.):0-минимальный срок действия пароля (г.о том что можно сменить пароль сразу:99999-максимальный срок действия пароля в днях:7- кол-во дней до истечения предыдущего срока 99999 у нас начнет появляться предупреждение)
semaev:$hfjhjhjsh..:16500:0:99999:7:::
ф-л теневых паролей групп, доступ только для пол-ля root:
/etc/gshadow
в этих ф-лах ничего не меняем, для изменения значений используются команды кот. рассмотрим далее
наличие этого ф-ла не дает никому, кроме пол-ля root входить в систему (не следует делать на ubuntu desktop, т.к. вход под root-ом там отключен):
создадим ф-л touch /etc/nologin

useradd - создание пользователей;
passwd - установка пароля для пол-лей;
usermod - изменять св-ва польз-лей;
userdel - удалять пол-лей;
интересные ключи:
-d указание домашней папки по умолчанию;
-g id группы к которой мы хотим добавить этого пользователя (по умолч. создается одноименная группа пол-ля);
-G перечислить группы по названиям если мы хотим добавить пол-ля в к-то спецфическую группу;
--create-home создастся домашняя папка сразу, до входа в систему;
-p или --password можно сразу указать пароль п-ля;
-s указать оболочку пол-ля, кот-я б. использоваться по умолчанию;
-u м. указать id пол-ля который хотим чтобы был (по умолчанию присваивается по-порядку от 1000);
создадим пол-ля buh (ключ -m создать папку сразу, -G включить в группу sambashare):
useradd -m -G sambashare buh
сразу проверяем, как завелся пол-ль в ф-лах БД паролей
установим пароль для польз-ля buh:
passwd buh
просто набрав команду м. сменить пароль текущего пол-ля:
passwd
заблокировать учет. запись пол-ля buh (ключ -L):
usermod -L buh
посмотрим как отразилось на записи теневого пароля в ф-ле:
/etc/shadow
где перед хэшем паролья будет стоять знак !
разблокируем пол-ля buh (ключ -u):
usermod -U buh
смотрим ф-л /etc/shadow, знак ! перед паролем убран
поменяем пол-лю buh оболочку для работы по умолчанию (ключ -s) и поставим комментарий (ключ -c):
usermod -s /bin/bash -c "My favorite" buh
проверяем, открываем БД п-лей:
/etc/passwd
удалим пол-ля buh и удалим его домашнюю папку (ключ -r):
userdel -r buh

настройка срока действия учетных записей:
создадим пол-ля petr сразу с домашним каталогом:
useradd petr -m
зададим ему пароль:
passwd petr
проверим, что пол-ль создался, просмотрим ф-л теневых паролей:
cat /etc/shadow
отключим пол-ля (-L lock):
usermod -L petr
проверим ф-л теневых паролей
перед паролем пол-ля д. стоять знак !
разблокируем пол-ля (-U unlock):
usermod -U petr
создадим домашнюю папку пол-ля вручную (утилита mkhomedir_helper помогает создавать домашние папки с нужными параметрами):
mkhomedir_helper petr
команда chage (change age) - изменить срок (ключ -l list):
посмотрим инф-ю по срокам действия пароля пол-ля:
chage -l petr
покажет:
Последний раз пароль был изменен:				мая 13, 2016
Срок действия пароля истекает:					никогда		#еще не деактивируется но начнут сыпаться сообщения в кол-ве дней указ. в п.7, после чего учетка деактивируется
Пароль будет деактивирован через:				никогда		#через сколько б.деактивирована учетная запись
Срок действия учетной записи истекает:				никогда		#срок на который выцдается учет. запись вне зависимости от параметров указанных выше
Минимальное кол-во дней м/у сменой пароля:			0
Максимальное кол-во дней м/у сменой пароля:			99999
Количество дней с предупреждением переддеактивацией пароля:	7		#за сколько дней до момента п.3 будут выдаваться сообщения о смене
чтобы задать все эти параметры пишем:
chage petr #запустится мастер ввода данных значений
чтобы изменить глобальные параметры по пол-лям, можно править ф-л /etc/login.defs
в частности м. указать мин/макс. длину паролей и т.д
---------------------------------------------------------------------------------
активные и прошлые сессии пол-лей

команда w - показывает кто вошел в систему и что делает
покажет:
13:04:55 (когда сист. была загружена) up 1 min (сколько работает) 2 users (сколько сейчас п-лей) load aversge 0.27, 0.14, 0.05 (3 пок-ля загрузки системы)
т.к. пол-ль semaev подключен через GUI и запущена консоль показывает его 2 раза:
USER	TTY	FROM	LOGIN@	IDLE	JCPU	PCPU	WHAT
semaev	:0	:0	13:03	?xdm?	6.28s	0.08s	/sbin/upstart --user
semaev	pts/17	:0	13:04	3.00s	0.02s	0.00s	w

TTY - куда подключен
FROM - откуда подключен
@LOGIN - когда подключен
IDLE - сколько времени простаивает
JCPU - время кот-е исп-ся всеми процессами закрепленными за данной консолью и включая фоновые задания, которые выполняются в данный момент
PCPU - время которое исп-ся текущим процессом в данный момент
WHAT - что выполняется
можно передать команде конкретного пол-ля, которого хотим посмотреть:
w semaev

команда who - показывает кто вошел в систему
когда была последняя загрузка системы:
who -b
покажет:
загрузка системы 2016-05-19 13:03
показать все логины кто вошел в систему (ключ -q) с именами каждого столбца (ключ -H headers заголовки):
who -qH
покажет:
semaev	semaev
количество пол-лей=2
who -uH
покажет:
ИМЯ	ЛИНИЯ	ВРЕМЯ			PID	КОММЕНТАРИЙ
semaev	:0	2016-05-19 13:03 ?	820	(:0)
semaev	pts/17	2016-05-19 13:04 .	1684	(:0)
показать все:
who -aH

команда users покажет тех, кто вошел в систему в виде одной строчки (показывает лог из бинарного ф-ла /var/run/utmp)
команда last показывает последние логины (показывает лог из бинарного ф-ла /var/log/wtmp)
в логах также показывает регистрацию виртуального пол-ля reboot, т.о. мы можем посмотреть информацию о всех перезагрузках системы:
last reboot
покажет неудачные попытки входа (показывает лог из бинарного ф-ла /var/log/btmp):
lastb
т.о. можем увидеть всех пол-лей которые неудачно зарегистрировались в системе (подбирали пароль)
------------------------------------------------------------------------------------------------
groupadd - добавить группу пол-лей;
groupmod - изменить группу;
groupdel - удалить группу;
chage - меняет настройки учет. записи;
getent (get entries - получить записи) - ищет сведения в БД уч. записей, умеет работать с службами AD,LDAP;

groupadd
ключи:
- g устанавливаем id группы вручную;
- p или --password установить пароль на группу (используется для смены группы владельца)
добавим группу groupadd:
groupadd clowns
проверяем ее создание в БД:
/etc/group
изменим для пол-ля buh группу пол-лей clowns (ключ -ag перезаписывает группу пол-лей по id группы, -G по имени группы):
usermod -aG clowns buh
проверяем ее изменение в БД групп /etc/group
изменим id группы clowns на 25000:
groupmod -g 25000 clowns
удалим группу clowns:
groupdel clowns
посмотреть св-ва пользователя (ключ -l):
chage -l semaev
изменить срок истечения учетной записи 9 янв. 2016 (ключ -E в формате YYYY-MM-DD)
chage -E 2016-01-09 semaev
сбросить все настройки к исходным (ключ -1):
chage -E -1 semaev
посмотрим теневые пароли:
getent passwd
посмотрим теневые пароли п-ля semaev:
getent passwd semaev
посмотреть ф-л кот. отвечает за группы:
getent group
---------------------------------------------------------------------------------

ВЫПОЛНЕНИЕ АДМИНИСТРАТИВНЫХ ЗАДАЧ
=================================

Страшное описание sudoers: https://opennet.ru/man.shtml?topic=sudoers&category=5&russian=0
Хорошее описание sudo: https://wiki.archlinux.org/index.php/Sudo_(Русский)
покажет какие пользователи сейчас находятся в системе и какие процессы запущены от их имени:
w username #например w max

если обычный пол-ль не может отредактировать системный ф-л, такие права есть только у суперпользователя
1. для этого нужно войти в режим суперпользователя su
запросит пароль пол-ля root
(домашним каталогом б. каталог пол-ля root)
чтобы вернуться к пол-лю под которым зашел в систему - exit
2. чтобы постоянно не находиться в режиме su (ключ -С комманда), т.к. не безопасно 
su -c 'комманда'
например
su -c 'vi /etc/resolv.conf'
вводим пароль root
закрыв файл режим su закроется
3. чтобы открыть ф-л от имени пол-ля пишем sudo vi /etc/resolv.conf и вводим пароль
также мы можем ограничивать доступ к исп-льзованию прав суперпользователя для этого есть ф-л:
/etc/sudoers
через редактор vim его редактировать не рекоммендуется
для его редактирования используют утилиту visudo, кот-я при сохранении изменений проверяет ошибки синтаксиса:
sudo visudo
в ней можно назначить псевдонимы для хостов, пол-лей, комманд
в нем видим правило вида:
root ALL=(ALL) ALL #пол-ль root м. выполнять с любой машины'ALL=' от имени любого пол-ля'(ALL)' или любой группы ':ALL' любую команду ' ALL'
%admin ALL=(ALL) ALL #группа admin те-же права
%sudo ALL=(ALL) ALL #группа sudo те-же права
т.о. если добавить пол-ля в любую из этих групп у него б. права вызывать суперпользователя
откроем ф-л /etc/group и отсортируем по слову sudo:
видим:
sudo:x:27:semaev #пол-ль semaev входит в группу sudo и поэтому м. выполнять действия sudo
sudo спрашивает пароль пол-ля 1 раз, а потом запоминает его в консоли
чтобы сбросить этот сеанс:
sudo -K #очищается запомненый пароль
если хотим выполнить неск. команд подряд, мы пишем:
sudo -s #сразу начинаем работать от пол-ля root (но домаш. каталогом б. каталог текущего пол-ля semaev), аналогично комманде su
sudo su #запрашивается пароль пол-ля с правами администратора и запускается сеанс аналогично su
в redhat системах:
sudo visudo
%wheel #аналог группы sudo
sudo - substitute user and do?
посмотреть кол-во неудачных попыток входа:
lastb | wc -l
-------------------------------------------------------------------------------------------------------------------------------

АВТОМАТИЗАЦИЯ ЗАДАЧ (ПОВТОРЯЮЩИХСЯ), ПЛАНИРОВЩИК CRON
=====================================================

как работать с системными задачами планировщика:
конфигурация планировщика cron находится в ф-ле /etc/crontab
там записываются задания планировщика
crontab должен заканчиваться переводом строки
есть еще планировщик anacron, его конфиг лежит в ф-ле:
/etc/cron.d/anacron
в эту папку (cron directory) устанавливаются скрипты для всех устанавливаемых программ, если у них есть к-то запланированные действия 
посмотрим какие есть ф-лы с фразой cron в папке /etc:
ls /etc -l | grep cron
покажет папки, где лежат скрипты выполняемые по соотв. расписанию:
cron.d,cron.daily,cron.hourly,cron.mounthly,cron.weekly и ф-лы anacrontab,crontab
можем закинуть в эти папки уже готовые скрипты, и в зависимости в какую папку мы их положим, они б. выполняться или ежедневно, ежечасно, еженедельно, ежемесячно
если в crontab есть строка 01 * * * * root run-parts /etc/cron.hourly, то скрипты лежащие в директории cron.hourly б. запускаться в 01 минуту каждого часа?
----------------------------------------------------------------------------------------------------------------------------------------------------------------

как работать с пользовательскими задачами планировщика, управлять доступом к планировщику:
посмотреть (ключ -l)какие есть задачи у текущего польз-ля:
crontab -l
чтобы создать задачу (ключ -e edit)
crontab -e
предложит выбрать редактор с пом. которого создать задание
добавим строку в 8часов по будням будет запускаться сканер drweb с ключами проверки системы:
00 08 * * 1-5 /usr/bindrweb/scanner -scan -all
смотрим какие появились задания, смотрим папку ls /var/spool/cron
покажет папку crontabs, в ней создаются ф-лы по имени польз-ля (в ubuntu)
--------------------------------------------------------------------------------------------

приоритет разрешения allow доступа к cron выше чем запрета deny
создадим ф-л с запретом доступа /etc/cron.deny, он в себе д. содержать имена п-лей к-рым запрещен доступ к планировщику, добавим в него строку semaev
проверим под пол-ем semaev попробуем создать задание в crontab:
crontab -e
напишет:
You (semaev) are not allowed to use this program (crontab)
теперь создадим ф-л /etc/cron.allow и запишем туда semaev
теперь получиться запустить планировщик
если мы удалим ф-л cron.deny (лист запретов) и удалим строку semaev из ф-ла cron.allow, то мы опять не сможем запустить планировщик, т.к. есть созданный ф-л (лист с разрешениями), но в нем нет разрешения для пол-ля semaev
если еще удалим лист разрешений rm /etc/cron.allow, то опять будет разрешать запускать планировщик всем пол-ям.
-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

АСИХРОННЫЙ ПЛАНИРОВЩИК (ПОВТОРЯЮЩИХСЯ) ЗАДАЧ ANACRON И ПЛАНИРОВЩИК ЗАДАЧ AT
===========================================================================

anacron - не поддерживает запуск задач по расписанию, но может запускать задания в интервале времени (исп. как дополнение к cron)
минимальный интервал выполнения - день
допустим частота выполнения задания в днях
файл конфигурации anacron:
/etc/anacrontab
содержит одну из строк:
день	задержка(мин)	метка (id)		задание
1	5		cron.daily		run-parts --report /etc/cron.daily
7	10		cron.weekly		run-parts --report /etc/cron.weekly
@monthly	15	cron.monthly		run-parts --report /etc/cron.monthly
(каждый день проверяет выполнялись ли задачи cron.daily и если не выполнялись, то выполняет задание каждый день с задержкой в 5 минут)
(раз в 7 дней проверяет выполнялись ли задачи cron.weekly и если не выполнялись, то выполняет задание каждый день с задержкой в 10 минут)
(раз в месяц нужно запускать задачу cron.monthly с задержкой в 15 минут)
выполнив задачу anacron записывает дату выполнения задачи в соотв. ф-лы наход. в папке /var/spool/anacron:
cron.daily,cron.weekly,cron.monthly
в папке /etc/cron.daily находится скрипт 0anacron, что говорит о том что первым будет запускаться скрипт anacron
в ubuntu и в др. debian-системах стандартный планировщик cron проверяет если в системе помимо cron установлен anacron, то он отдает управление ему, что позволяет избежать 2-хкратного запуска задач
----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

установим планировщик at:
apt-get install at
покажет что у нас запланировано:
atq
создадим пустой ф-л script
touch script
сделаем его исполняемым
chmod +x script
скажем at исполнять этот скрипт в 17-00:
at 17:00
переходим в режим написания скрипта
и пишем выполнить наш скрипт:
/home/semaev/script
выход из режимма написания ctrl+d
проверяем наличие задачи:
atq
покажет:
job1	Sun Jul 12 17:00:00 2015 a semaev
есть 1 задача выполнить ее в 17:00
можно создать задачу в формате сейчас + 15 минут:
at now + 15 minute
опять запустит режим написания задания
м. сказать запустить задачу 9 янв. 2015г. в 15:00:
at 15:00 01/09/2015
удалим 1-е задание:
atrm 1
также можно создавать списки доступа и запрета:
/etc/at.deny, etc/at.allow
--------------------------------------------------

SSH
===

публичный ключ сервера хранится в скрытой папке в профиле:
~/.ssh
cat known_hosts
можно записать ключ находящийся в данном ф-ле для всех пользователей системы,
для этого создадим ф-л:
vi /etc/ssh/ssh_known_hosts

RSA (фамилии Rivest,Shamir,Adleman)
криптографический алгоритм с открытым ключом - для подписи и шифрования;
DSA (Digital Signature Algorithm)
криптографический алгоритм с открытым ключом - только для подписи;

если на сервере другой пользователь, чем на локале, то подключение к серверу через ssh выглядит:
ssh admin@10.0.1.6
если такой же то:
ssh 10.0.1.6
создадим (сгенерируем) цифровой ключ с типом RSA на своей машине:
ssh-keygen -t rsa
создастся пара открытого и закрытого ключа в папке:
/home/semaev/.ssh/id_rsa
предложит ввести парольную фразу (некое предложение из слов)
после чего в папке появятся 2 ф-ла:
id_rsa, id_rsa.pub
теперь в кач-ве примера создадим пару ключей dsa:
ssh-keygen -t dsa
в папке появятся 2 ф-ла:
id_dsa, id_dsa.pub
скопируем сгенерированные публичные ключи через ssh на сервер (он б.знать что Я это я)
(-i ключ)
ssh copy-id -i .ssh/id_rsa.pub admin@10.0.1.6
сверим скопированный сертификат
смотрим у себя на ммашине:
cat .ssh/id_rsa.pub
смотрим кго насервере:
ssh admin@10.0.1.6
попросит один раз ввести парольную фразу на время сеанса (если подключение через графическую среду)
подключившись к серверу смотрим ф-л:
cat .ssh/authorized_keys
сверяем его
тоже самое можно проделать с ключом dsa
если подключение будет не через графику, для запоминания парольной фразы используем
запуск bash от имени (родителя) ssh-agent:
ssh-agent bash
ssh-add .ssh/id_rsa
просит ввести парольную фразу
тоже запомнит на время работы сеанса консоли
также если хотим сгенерить ключи для всех пользователей системы (на уровне хоста) (ключ -f где создать)
ssh-keygen -t rsa -f /etc/ssh/ssh_host_rsa_key
создадутся открытый и закрытый ключи в папке:
/etc/ssh
ключи ssh_host_rsa_key, ssh_host_rsa_key.pub
можно проверить данные ключи на сервере подключившись через ssh:
ssh admin@10.0.1.6
ls /etc/ssh
---------------------------------------------------------------------

ssh туннели
проброс портов и сессий х11
рассмотрим запуск графических окон с удаленной машины у себя на компе:
подключимся к серверу через ssh с ключом -X:
ssh -X admin@10.0.1.16
после подключения запустим к-либо ПО, например nautilus удаленного сервера
nautilus
закрыть сессию ctrl+c
м. запустить firefox удаленного сервера
скопируем через ssh файл 1.txt на машину 10.0.1.16 в папку /home/semaev
scp 1.txt semaev@10.0.1.16:/home/semaev
пробросим 80 порт через сервер ssh-сервер (10.0.1.16) с ключем -N (none ничего не делать)
с ключем -L (локальный порт 12345) на какой пробрасывать 80-й порт,
адрес веб-сервера (ya.ru 213.180.204.3) до которого пробросить порт 
ssh 10.0.1.16 -N -L 12345:213.180.204.3:80
если нужно пробросить неск. портов, то указываем их через пробел.
после этого открываем браузер и в адресной строке набираем
localhost:12345
открывается сайт ya.ru
закрываем сессию ssh: ctrl+c

ШИФРОВАНИЕ Ф-ЛОВ С ПОМОЩЬЮ GPG
==============================

сгенерируем ключ
gpg --gen-key
предлагает выбрать ключи для подписи и для шифрования
выбираем ключ по умолчанию (1) RSA и для подписи и для шифрования
для идентификации ключа нужен User ID
программа создаст его из вашего имени, комментария и адреса почты
вводим данные
для защиты секретного ключа вводим секрет. фразу
потом нам нужно минут 5 чем-то заниматься на компе, т.к. для создания ключа нужно 247 случайных байт
ключ создастся в скрытой папке ~/.gnupg
публичный ключ pubring.gpg
частный ключ secreting.gpg
посмотрим существующие ключи:
gpg --list-key
покажет:
pub	2048R/71168532 2016-05-31
uid		Kirill Semaev (semaevkey) <it.prepod@gmail.com>
sub	2048R/3C39B2A4 2016-05-31
где
uid - id кто регистрировал  ключ
pub - публичный (открытый) ключ используется для подписи
sub - подключ используется для шифрования
экспортируем sub-ключ и обозначим его допустим по комментарию semaevkey в ф-л gpg.public:
gpg --export semaevkey > gpg.public
отправим его тому кто хочет нам отправлять зашифрованную информацию с помощью этого ключа
допустим отправим его на удаленный ssh-сервер 10.0.1.6, там создадим файл, зашифруем его и перешлем обратно.
перешлем gpg.public:
scp gpg.public admin@10.0.1.6:/home/admin
для подключения к серверу попросит ввести секретную фразу
теперь подключимся к серверу через ssh:
ssh admin@10.0.1.6
~/ls
смотрим в папке ~/ появился ф-л gpg.public
смотрим есть ли к-либо ключи на удаленном сервере:
gpg --list-key
первый раз выполняя программа создает свою среду для работы
выполняем ее 2-й раз , показывает что никаких ключей нет
нам нужно его импортировать на удаленной машине
gpg --import gpg.public
теперь gpg --list-key покажет импортированный ключ
теперь создадим ф-л 1.txt и зашифруем его с помощью этого ключа
gpg --out secret.file --recipient 'Kirill Semaev' --encrypt 1.txt 
где secret.file (зашифрованный файл на выходе), recipient (получатель, указываем к-либо реквизиты ключа), encrypt (зашифровать какой файл)  
выходим с удаленного сервера
exit
скачаем зашифрованный ф-л к себе на машину:
scp admin@10.0.1.6:/home/admin/secret.file /home/semaev
расшифруем ф-л в ф-л с названием some.file:
gpg --out  some.file --decrypt secret.file
спрашивает ключевую фразу при создании ключа
------------------------------------------------------------------------------------------------------------------------------------------

ЛОКАЛИЗАЦИЯ И КОДИРОВКА
=======================
https://wiki.archlinux.org/index.php/Locale_(Русский)
переменная $LANG - основная настройка языка;
переменная LC_ALL - позволяет разом перезаписать все языковые настройки
команда LOCALE - показывает текущие языковые настройки
LANG=C - установка кодировки по умолчанию (исп-ся в начале скриптов)
посмотрим переменные среды командой env:
покажет языковые переменные
для языковых настроек программ использующих графическую оболочку:
LANGUAGE=en_US
для всего, что не установлено переменными LC_...(в locale):
LANG=en_US.UTF-8
команда locale покажет все языковые настройки
допустим если захотим поменять переменную LC_TIME:
задаем переменную:
LC_TIME=en_US.UTF-8
загружаем переменную:
export LC_TIME
проверяем вводим команду locale
если хотим все перезаписать и сделать русским:
LC_ALL=ru_RU.utf8
export LC_ALL
проверяем
locale
чтобы вернуть все в прежние значения (отменить настройку команды LC_ALL):
unset LC_ALL
посмотреть все доступные кодировки:
iconv --list
можем поменять кодировку напр-р в ф-ле /etc/fstab (по ум. в нем UTF-8) на ASCII и вывестина экран (ключ -o имя_файла_вывода):
iconv -f UTF-8 -t ASCII /etc/fstab
-----------------------------------------------------------------------------------------------------------------------------

УПРАВЛЕНИЕ ВРЕМЕНЕМ
===================

показывает текущую дату (системное время):
date
установим дату (в формате ЧЧММччммГГГГ)
date 010918001985
запустим мастер установки временной зоны:
tzselect
после чего
можно назначить вручную и выгрузить в перем. среды, например:
TZ='Europe/Moscow'
export TZ 
посмотреть таймзону в данный момент м. в ф-ле /etc/timezone
cat /etc/timezone
Значение 'Europe/Moscow' показывает папку с которой б. работать система:
/usr/share/zoneinfo/Europe/Moscow (бинарный ф-л Moscow)
на текущую врем.зону также указывает линк /etc/localtime (бинарник, в нем хранится информация текущей врем. зоны, св-ва: lrwxrwxrwx говорят что это линк)
Можем создать линк на временную зону Киева (создадим символическую ссылку):
ln -sf /usr/share/zoneinfo/Europe/Kiev /etc/localtime
проверяем какая временная зона стала текущей:
zdump /etc/localtime
В /usr/share/zoneinfo/ лежат бинарники часовых поясов формируемые спец. утилитой (сервисом), кот. считывает настройки временных зон
и создает эти ф-лы. Их можно просмотреть спец. утилитой zdump
допустим:
zdump Poland
в ubuntu, если мы посмотрим на св-ва ф-ла localtime (ls -l /etc), он не является символической ссылкой
в ubuntu ссылка localtime находится в /usr/share/zoneinfo
localtime -> /etc/localtime
Поэтому в ubuntu мы не можем поменять врем. зону просто перелинковав ф-л, в ubuntu для этого используется пакет dpkg:
dpkg-reconfigure tzdata
он запускает окно с мастером конфигурации временной зоны
---------------------------------------------------------------------------------------------------------------------

при старте системы берется значение аппаратных часов (real time clock) (хранится в схеме на мат. плате и поддерживается батарейкой)
чтобы посмотреть аппаратное время:
hwclock (hardware clock)
при запуске компа аппаратные часы передают время операционной системе
в ф-ле /etc/adjtime хранится информация о том, насколько время отличается от аппаратных часов (по умолчанию отсутствует)
создается после нескольких синхронизаций времени
чтобы подвести аппаратные часы исп. команда:
hwclock --adjust
м. указать аппаратным часам другое время:
hwclock --set --date="01/01/2020 12:00"
чтобы синхронизировать аппаратные часы с системным временем:
hwclock -w
формат UTC (universal time coordinated) универсальное время
чтобы хранить время в аппаратных часах в формате текущего часового пояса (формат LOCAL):
hwclock --localtime -w
проверим файл корректировки времени:
cat /etc/adjtime
там поменяется формат времени с UTC на LOCAL
чтобы вернуть к прежнему формату (ключ -u UTC):
hwclock -u -w
-----------------------------------------------------------------------------------------

список серверов NTP в РФ:
www.pool.ntp.org/zone/ru
для разовой настройки времени по протоколу ntp (допустим взять время с пула серверов 0.ru.pool.ntp.org):
ntpdate 0.ru.pool.ntp.org
установим демон синхронизации времени:
apt-get install ntp
его настройки лежат в /etc/ntp.conf
укажем какие сервера будем использовать, или примем сервера по умолчанию:
server 0.ru.pool.ntp.org
server 1.ru.pool.ntp.org
server 2.ru.pool.ntp.org
server 3.ru.pool.ntp.org
перезапускаем службу:
service ntp restart
(или перезагрузить конф. файл командой reload)
проверить синхронизацию с серверами точного времени м. командой (ntp query):
ntpq -pn
----------------------------------------------------------------------------

ЖУРНАЛИРОВАНИЕ СОБЫТИЙ SYSLOG
=============================

syslog сейчас уже не используется
событие в журнале записывается в формате:
источник.приоритет	куда отправлять данное событие 
его ф-л конфигурации /etc/syslog.conf
в нем например:
по умолчанию события ядра закомментированы (никуда не записываются):
#kernel.*	/dev/console
если разкомментировать будут выводиться в консоль пол-ля (на экран)
все информационные события и важнее отовсюду (*), не из почты (none), не аутентификации, не планировщика б. записываться в журнал /var/log/messages:
*.info;mail.none;authpriv.none;cron.none	/var/log/messages
все события из источника событий authpriv б. записываться в защищенный журнал /var/log/secure, просматривать его м. только пол-ль root:
authpriv.*	/var/log/secure
все события от почты б. записываться в журнал /var/log/maillog (знак - говорит о том, что этот жур-л после использования не нужно выгружать из оперативной памяти, т.е. всегда иметь его кэш в ОЗУ, система б. быстрее работать, но в сл. сбоя м. не сохраниться журнал)
mail.*		-/var/log/maillog
все события планировщика сохр. в журнал /var/log/cron:
cron.*		/var/log/cron
все источники событий emergency (черезвычайная ситуация) получит каждый пользователь (знак *):
*.emerg		*
все новости critical и выше отправлять в журнал /var/log/spooler:
uucp,news.crit		/var/log/spooler
если мы хотим чтобы только это событие записывалось ставим знак "=" после точки:
uucp,news.=crit		/var/log/spooler
локали (тэги). Это метки 0-7. можно эти метки присваивать к-либо событиям (например события загрузчика метятся local7):
local7.*		/var/log/boot.log
м. дописать все источники событий user отправлять на машину 192.168.115.118 (сервер логов):
user.*		@192.168.115.118
после этого перезапустим службу:
service syslog restart
на друго машине куда мы отправили лог., надо научить его принимать, для этого меняем его ф-л конфигурации:
/etc/sysconfig/syslog
допишем в строчку ключ -r
SYSLOGD OPTIONS="-m -r 0"
программой LOGGER м. управлять модулем системных событий
создать событие warning (предупреждение) от пол-ля написав его (Please help), отправив его т.о. на др. комп:
logger -p user.warn Please help! 
------------------------------------------------------------------------------------------------------------

РОТАЦИЯ ЛОГОВ LOGROTATE
=======================

klogd (kernel log demon) демон записи логов ядра
он м. перхватывать и регестрировать все сообщения идущие к ядру Linux
logrotate умеет сжимать логи, отправлять по почте, но основная задача брать текущий лог, сохранять его в др.место и создавать пустой ф-л
обычно это задание записывается в планировщик:
cat /etc/cron.daily/logrotate
там записано что запускается эта утилиита исп. конф. файл /etc/logrotate.conf
в нем указано:
работать с логами еженедельно (раз в неделю б. выполнять свои действия), здесь м. указать по размеру логф-ла (либо то, либо это, взаимоисключ. параметр):
раз в неделю б. сохранять текущий файл и создавать новый пустой
weekly
от какого имени будем работать с логфайлом
su root syslog
хранит 4 backlogs, т.е. 4 файла логов
rotate 4
создавать новые пустые ф-лы
create
м. раскомментировать строчку compress (сжимает, архивирует логи)
отдельное расписание ротации м. хранится в ф-ле /etc/logrotate.d
include /etc/logrotate.d
отдельные настройки ротации для отдельных лог ф-лов
/var/log/wtmp...бинарники о прошлых входах-выходах
/var/log/btmp...бинарники о ошибках входа
это ф-лы входа и выхода из системы (utmp-ф-лы текущего состояния пол-лей)
missingok если нет ф-ла -все нормально
monthly делать бэкап лога ежемесячно
создавать ф-л с такими параметрами:
create 0664 root utmp(группа владельца)
хранить 1 бэкап ф-ла
rotate 1
чтобы просмотреть ф-лы /var/log/wtmp
utmpdump /var/log/wtmp
в папке настройки для ротации отдельных служб (ф-лы с названиями служб):
/etc/logrotate.d
например cat ufw (стандартный фаервол ubuntu)
в нем:
notifempty не обрабатывать пустые ф-лы
delaycompress сжимает предыдущий ф-л при следующей ротации
sharedscripts скрипты б. выполняться один раз вне зависимости от того сколько лог ф-лов б. обработано
postrotate скрипты к. б. выполняться после rotate
смотрим какие логи создаются в папке /var/log
-----------------------------------------------------------------------------------------------------

ЖУРНАЛИРОВАНИЕ СОБЫТИЙ: JOURNALD
================================

https://www.altlinux.org/Journald
м. работать с другими системами журналирования по умолчанию (rlog,syslog,..)
файловые системы необходимые для запуска служб на ранних стадиях загрузки, выделяется место в ОЗУ и монтируются в папку /run
файловая система исп-ся как централизированное хранилище временных ф-лов в ОЗУ
/run/log/journal
в ней лежит папка e308367..., в ней хранится бинарный ф-л system.journal
по умолчанию информация держится в оперативке, чтобы она записывалась в ф-лы журналов сделаем:
настройки демона находятся в ф-ле:
/etc/systemd/journald.conf
в нем закоментированы используемые по умолчанию параметры:
#Storage=auto говорит о том, где мы будем хранить логи (в оперативке или на диске), auto - говорит о том, что он м. хранить логи на диске, если создана эта папка,
если хотим, чтобы б. создана эта папка автоматически ставим значение persistent
#Compress=yes сжимать ф-лы журнала
#Seal=yes криптография для событий journald
#SplitMode=uid разбивать ли журналы по к-либу признаку (стоит по id пол-лей)
#SyncIntervalSec=5m интервал синхронизации м/у журналами в памяти и на жестком диске (время кот-е он побыл в ОЗУи потом скидывается на диск)
#RateLimitInterval=30s и #RateLimitBurst=1000 сколько сообщений принимать, т.е. принимается max 1000 сообщений за 30 сек, остальные б. отбрасываться
ограничения для журналов на жест.диске:
#SystemMaxUse= макс. объем кот. м. занимать логи на диске
#SystemKeepFree= макс. свободного места
#SystemMaxFileSize= объем ф-ла лога, после кот. он д.б. удален с диска
тоже самое по журналу, кот. хранится в ф-ловой системе (в ОЗУ) подключенной к каталогу /run:
#RuntimeMaxUse=
#RuntimeKeepFree=
#RuntimeFileSize=
хранение по времени записи в журнале (редко исп-ся):
#MaxRetentionSec=
#MaxFileSec=imonth
отправлять ли сообщения в к-либо сторонние службы:
#ForwardToSyslog=yes
#ForwardToKMsg=no в систему отслеживания событий ядра kernel message - не отправлять
#ForwardToConsole=no
#ForwardToWall=yes команда кот. отправляет сообщение всем пол-лям
максимальные уровни сообщений, кот. будут отправляться:
#MaxLevelStore=debug
#MaxLevelSyslog=debug отладочные и выше
#MaxLevelKMsg=notice уведомления и выше
#MaxLevelConsole=info информ. и выше
#MaxLevelWall=emerg всем п-лям будет отправлять сообщения об ошибке черезвычайной ситуации и выше
поменяли значение #Storage=persistent
перезапускаем службу
service systemd-journald restart  или reload
проверяем появилась ли папка с журналом ls /var/log/journal/
e3083.... все ок
теперь инф. будет храниться не только в ОЗУ, но и на жест.диске
основные команды, которыми м. управлять journald:
journalctl (journal controller)
пишем journalctl
выводит на экран огромное к-во сообщений
чтобы просматривал сообщения от момента загрузки (boot) системы:
journalctl -b
покажи все события с 15:30:
journalctl --since 15:30
покажи все события с 15:30 до 15:38:17:
journalctl --since 15:30 --until 15:38:17
показать все сообщения со вчера до сейчас:
journalctl --since yesterday --until now
можем посмотреть отфильтровав по службе (ключ -u unit):
journalctl -u networking.service служба сети
journalctl -u apache2 #журнал работы сервиса apache2
посмотреть события ядра:
journalctl -k
посмотреть события с определенным кодом(типом) ошибки (ключ -p):
journalctl -p err
код уровня ошибок:
0: emerg (система неработоспособна);
1: alert (требуется немедленное вмешательство);
2: crit (критическое состояние);
3: err (ошибка);
4: warning (предупреждение);
5: notice (всё нормально, но следует обратить внимание);
6: info (информационное сообщение);
7: debug (отложенная печать).
просмотреть журнал сообщений обо всех ошибках, имевших место в системе во время предыдущей загрузки, можно при помощи команды:
journalctl -p err -b -1
тоже с момента загрузки:
journalctl -p err -b
показать новые сообщения (последние 10):
journalctl -n
показать новые сообщения (последние 20):
journalctl -n 20
смотреть логи в режиме онлайн:
journalctl -f #выйти ctrl+z или ctrl+c
по умолчанию, journalctl не переносит строки по ширине экрана. Чтобы сократить вывод по ширине экрана - выполните:
journalctl --no-full
по умолчанию journalctl использует для вывода сообщений логов внешнюю утилиту less.
В этом случае к ним невозможно применять стандартные утилиты для обработки текстовых данных (например, grep).
Эта проблема легко решается: достаточно воспользоваться опцией --no-pager, и все сообщения будут записываться в стандартный вывод:
journalctl --no-pager
посмотреть сколько места занимает журнал journalctl:
journalctl --disk-usage
установить сколько места будет занимать журнал journalctl (максимально допустимый размер хранимых на диске логов, ключ --vacuum-size, лишние ф-лы б. удаляться):
journalctl --vacuum-size=1G	1гигабайт
удаление по времени (ключ --vacuum-time)
journalctl --vacuum-time=1years  1год
если хотим, чтобы журнал journalctl отправлял логи на др. машину, то на другом компе запускаем и настраиваем службу systemd-journal-remote
для приема логов с удаленного хоста пишем например:
systemd-journal-remote --url https://ssjsj:34424
можно загружать логи с локальнной машины на удаленный хост:
systemd-journal-upload --url https://ssjsj:34424
------------------------------------------------------------------------------------------------------------------------------------------

ЖУРНАЛИРОВАНИЕ СОБЫТИЙ RSYSLOG
==============================

http://www.k-max.name/linux/rsyslog-na-debian-nastrojka-servera/

rsyslog очень производительный (обрабатывает 1млн. операций в сек.)
позволяет фильтровать по целому ряду признаков, исп. возможности протокола TCP
ubuntu использует rsyslog по умолчанию параллельно с journald:
проверим работу данной службы:
service syslog status
покажет что:
rsyslog.service -System Logging Service
Loaded: loaded (/lib/systemd/system/rsyslog.service:enabled)
Active: active(running)
опции, которые передаются демону при старте (по умолчанию пусто):
/etc/default/rsyslog
основной конфиг syslog находится:
/etc/rsyslog.conf
он разбит на 4 секции: модули, глоб. директивы (параметры)
$FileOwner syslog #права по умолчанию, кто будет владельцем
$FileGroup adm #кто будет группой владельца
$FileCreateMode 0640 #права для создания ф-лов
$DirCreateMode 0755 #права для создания папки 
$Umask 0622 #маска
$PrivDropToUser syslog #от кого будет запускаться демон
$PrivDropToGroup syslog #от какой группы владельцев запускается
$WorkDirectory /var/spool/rsyslog #очередь сообщений для обработки из ф-лов которые он будет передавать куда-то
$IncludeConfig /etc/rsyslog.d/*.conf #нужно включить конфиг из этой папки
еще бывает 2 отдельных модуля:
1. это шаблоны, где мы можем задавать формат выводимой информации
используя динамические имена ф-лов на основе к-то правила
2. правила сортировки похожи на syslogd (источник приоритет куда_выводить)
есть дополнительная фильтрация на основе скриптового языка, также фильтрация на основе св-в полученных от шаблонов
открываем папку /etc/rsyslog.d и видим 2 ф-ла конфигурации
смотрим cat /etc/rsyslog.d/50-default.conf
в нем такой же формат записи как у syslog:
auth,authpriv.*		/var/log/auth.log #источник_сообщений.тип_сообщений	куда выводить
mail.err		/var/log/mail.err #все ошибки от почты б.записываться в журнал /var/log/mail.err
смотрим ф-л для фаервола cat /etc/rsyslog.d/20-ufw.conf
в нем:
:msg,contains,"[UFW " /var/log/ufw.log #если у нас любое сообщение (:msg), содержит (contains), "[UFW " записать в журнал /var/log/ufw.log
ротация ф-лов логов прописана в файле:
/etc/logrotate.d/rsyslog
------------------------------------------------------------------------------------------------------------------------------------------

ЖУРНАЛИРОВАНИЕ СОБЫТИЙ SYSLOG-NG
================================

м.б. как единый централизованный сервер логов в сети (м. соберать логи с большого кол-ва источников и обрабатывать 600тыс/сек)
ubuntu по умолчанию исп. систему инициализации в стиле systemd и журнал ctrl (journalctl)
удалить мы этот журнал не можем
поэтому если будем ставить на ubuntu нужно сказать journalctl, чтобы он пересылал все сообщения в syslog-ng
ставим пакет:
apt-get install syslog-ng
открываем ф-л конфигурации:
vim /etc/syslog-ng/syslog-ng.conf
разбит на неск. секций
опции
источники sources, откуда он забирает сообщения (по умолч. с локальной машины) все системные (system) и внутренние (internal) сообщения
если хотим принимать сообщения по сети, то нужно разкомментировать строчки
source s_net { tcp(ip(127.0.0.1) port(1000)); }; #по какому порту и сетевой карте он будет слушать
можем указать:
source s_net { udp } #будет собирать все посылаемые ему логи по udp
далее определяем назначение destinations, в каких логах у нас будет что храниться
по умолчанию записано
destination d_auth { file("/var/log/auth.log"); }
и т.д.
есть настройки для сервера новостей INN
внизу в секции filters указано как мы будем фильтровать сообщения
filter f_dbg { level(debug); }; #будет отслеживать сообщения "отладка"  
filter f_err { level(err); };
есть сообщения
filter f_error { level(err .. emerg) ; }; #будет отслеживать ошибки и выше
можно указать фильтры по совпадению с к-либо регулярным выражением, например фильтр по хосту
Log path - пути логов
источник (s_src), заданный в первой части файла, все что попадает в этот источник и отностится к фильтру (f_auth), тоже заданный выше
будет сохраняться в назначение (d_auth):
log { source(s_src); filter(f_auth); destination(d_auth); };
в конце есть строка включить все ф-лы конфигурации из папки:
@include "/etc/syslog-ng/conf.d/*.conf*"
-----------------------------------------------------------------------------------------------------------------------------------------

DNS+DHCP
========

Мануал по настройки сетевых карт:
http://help.ubuntu.ru/wiki/настройка_сети_вручную
https://habr.com/post/137587/

сеть в ubuntu настраивается в ф-ле /etc/network/interfaces
1-й интерф. смотрит в локальную сеть:
в нем указан петлевой интерфейс loopback
и автоматический eth0 получ. адрес по dhcp:
auto eth0
iface eth0 inet dhcp
изменим на статический адрес:
auto eth0
iface eth0 inet static
address 192.168.0.1
netmask 255.255.255.0
#шлюз не указываем, он б. на 2-й сетевой карте
#укажем адрес днс-сервера
dns-nameservers 192.168.0.1
#укажем поисковый домен (имя нашей сети)
dns-search LAB.LOCAL
dns-domain LAB.LOCAL

2-й интерф. смотрит в интернет:
auto eth1
iface eth1 inet dhcp

сохраняем и перезапускаем сеть:
service networking restart

установим putty:
apt-get install openssh-server
отключим "ubuntu firewall" ufw 
ufw disable
раньше настраивался dns в папке:
/etc/resolvconf
в ней есть подпапка /etc/resolvconf/resolv.conf.d/
в ней есть ф-лы: base,head (м.б. еще tail(хвост))
в base хранится основная инф. о настройках dns
в head хранится заголовок, который вставляется перед основной инф-ией
в tail хранится инф., кот-я вставляется после этой динамически создаваемой конфигурации
сейчас ф-л head генерируется автоматически
сейчас инф-я основного ф-ла dns хранится:
/etc/resolv.conf
если не все прописалось, обновим конфигурацию dns (с ключем -u update):
resolvconf -u
если неправильно отображается инф. о dns, м. отредактировать ф-л(если его нет-создать самому):
/etc/resolvconf/resolv.conf.d/tail
если dns сервера у провайдера указаны статически, а не получаем по dhcp, запишем в файл их адреса:
nameserver 192.168.97.1
nameserver 8.8.8.8
перезапустим службу сети: service networking restart

установим пакет для dns:
apt-get install bind9
настроим основую конфигурацию сервера dns bind9
все настройки сервера лежат в папке /etc/bind
там есть ф-л с настройками 'сервер имен dns' named.conf.options
там записано
forvarders #куда переадресовывать запросы, если наш сервер не может его разрешить
по умолчанию переадресовывает в сеть интернет (0.0.0.0)
forvarders {
	0.0.0.0:
};
поменяем это значение на адрес нашего рутера (или dns-сервер провайдера)
forvarders {
	192.168.97.1:
};
dnssec - протокол к. позволяет защищать зоны dns, шифровать запросы, оставляем по умолчанию:
dnssec-validation auto;
укажем серверу через какие интерфесы слушать (listen):
listen-on {
127.0.0.1;	#слушал себя и
192.168.0.1;	#слушал интерфейс в локальную сеть
};	
#если dns сервер смотрит сразу в 2 сети (в локальную сеть и интернет) , то не нужно, чтобы он разрешал запросы, 
которые ему будут приходить из интернета, т.к. это плохо с т.зрения безопасности
стартуем сервер:
srvice bind9 start
теперь сервер б. пробрасывать запросы в рутер, даже если никаких dns серверов в настройках сети прописано не будет
шаблон зоны прямого просмотра (premier zone) хранится в БД /etc/bind/db.local
скопируем его:
cp db.local /var/lib/bind/forward.bind
отредактируем ф-л /var/lib/bind/forward.bind
в нем:
$TTL (TimeToLive) 604800 	#время которое информация записи в этой зоне будет храниться в кэше клиента, 
				#через это время удалится из кэша как неактуальная (в секундах)7дней
IN (зона интернет) - тип узлов
SOA (service of authority) - говорит о том, кто у нас явл. ответственным за эту зону и параметры этой зоны
след. значение вместо localhost указываем название нашего сервера - srv.LAB.LOCAL. root.srv.LAB.LOCAL.(
NS (name server) - тот dns-сервер, кот. отвечает за эту зону
A (тип) - запись задает соответствие имени хоста его IP-адресу (имя:IP)
AAAA - тоже самое для IP протокола версии 6
получиться:
$TTL	604800
@	IN	SOA	srv.LAB.LOCAL.	root.srv.LAB.LOCAL. (
			2		; Serial #серийный номер зоны, он б. изменяться каждый раз, когда зона б. обновляться
#это нужно если у нас за эту зону отвечает неск. серверов (на к-то сервере эта зона будет указана как дополнительная), тогда
#тот сервер у которого этот номер будет выше - будет считаться приоритетным и он будет обновлять сервера-партнеры на которых тоже есть эта зона
			604800		; Refresh #интервал обновления (как часто соседний сервер б. пытаться обновлять информацию)
			86400		; Retry #через какое время нужно повторить попытку, если пред. обновление было неудачным
			2419200		; Expire #срок годности зоны (ч/з какое время инф-я содерж. в этой зоне б.считаться недействительной на партнере, если этот партнер не связывался с основным dns-сервером)
			604800 )	; Negative Cache TTl #это время жизни несуществующих записей
;
@	IN	NS	srv.LAB.LOCAL.
@	IN	A	192.168.0.1
@	IN	AAAA	::1
srv	IN	A	192.168.0.1
добавим сюдя еще одну запись узла для проверки
test	IN	A	192.168.0.111

теперь создадим зону обратного просмотра (т.к. DNS не может в обратном порядке читать свою базу)
скопируем этот же ф-л:
cp /var/lib/bind/forward.bind /var/lib/bind/reverse.bind
в этом ф-ле нам нужно поменять указатели A на PTR (pointer указатель)
изменим файл с этой строчки:
@	IN	NS	srv.LAB.LOCAL.
1	IN	PTR	srv.LAB.LOCAL.
111	IN	PTR	test.LAB.LOCAL.

теперь серверу нужно сказать, что эти зоны у него есть
для этого меняем ф-л /etc/bind/named.conf.local
добавим в файл:
#инф. о зоне прямого просмотра
zone "LAB.LOCAL" {
	type master;				#тип зоны master (главный сервер)
	file "var/lib/bind/forward.bind";	#файл где лежит инф. о зоне
	};
#инф. о зоне обратного просмотра
zone "0.168.192.in-addr.arpa" {
	type master;
	file "var/lib/bind/reverse.bind";
	};
перестартуем службу:
service bind9 restart
проверяем статус:
service bind9 status
проверим зону прямого просмотра командой host:
host test
покажет:
test.LAB.LOCAL has address 192.168.0.111
проверим зону обратного просмотра:
host 192.168.0.111
покажет:
111.0.168..192.in-addr.arpa domain name pointer test.LAB.LOCAL.
----------------------------------------------------------------
установим dhcp-сервер:
apt-get install isc-dhcp-server
настраиваем ф-л конфигурации (если в конфиге б.хоть одна опечатка dhcp-сервер не запустится):
/etc/dhcp/dhcpd.conf
в нем:
#режим взаимодействия с dns-серверами:
ddns-update-style none;
#ложные пакеты dhcp-nack - сервер посылает эти пакеты клиенту, если клиент использует неподходящий ip-адрес
#или адрес занятый др. компом. Если в сети б. конфликтующие dhcp-сервера, то не авторитетный (authotitative)
#сервер не будет приниматься во внимание (по умолчанию эта опция отключена) 
#скажем, что этот сервер является авторитетным для этой зоны (по умолч. эта запись отсутствует)
#он м. сам вручную обрывать аренду и выдавать заново аренду IP-адресов:
authotitative;
#нам нужно настроить сеть
#по умолчанию настроена зона для всех сетей "example.org"
#option domain-name "example.org";(комментируем ее)
#option domain-name-servers ns1.example.org, ns2.example.org;(комментируем ее)
создадим отдельную зону:
subnet 192.168.0.0 netmask 255.255.255.0 {
#укажем диапазон выдаваемых адресов (нет параметра исключаемых адресов, поэтому можно разбить
#выдаваемые адреса на два пула)
range 192.168.0.101 192.168.0.199;
range 192.168.0.200 192.168.0.230;
#указываем опции (м.указать имя домена, маршрутизатор, сервер времени, днс-сервер, tftp-сервер)
option domain-name "LAB.LOCAL";
#указываем имя dns-сервера
option domain-name-servers 192.168.0.1;
#указываем маршрутизатор. адрес шлюза в интернет
option routers 192.168.0.10;
#укажем широковещательный адрес сети (не обязательно)
option broadcast-address 192.168.0.255;
}
#можем зарезервировать ip-адрес за хостом (kem118-имя хоста, 08:02:27:1c:f5:df-mac-адрес хоста)
Host kem118 {
hardware ethernet 08:02:27:1c:f5:df;
fixed-address 192.168.0.134;
}
#существует неск. локалей 0-8 (это класс системных сообщений или раздел журнала syslog)
#укажем куда будет записываться лог, по умолчанию б.записываться в систем журнал syslog и помечены, как local7
#потом мы сможем их найти по этому классу:
log-facility local7;
#параметры по умолчанию для всех зон
#сколько время аренды (сек):
default-lease-time 600;
#сколько максим. время аренды (сек):
max-lease-time 7200;
закрываем, сохраняем.
чтобы избежать получение запросов из сети интернет отредактируем ф-л:
/etc/default/isc-dhcp-server
в нем по умолчанию пусто, добавим в него по какой сетевой карте прослушивать запросы:
INTERFACES="eth0"
выходим, сохраняем
логи у нас б. вестись в syslog
для того, чтобы логи dhcp-сервера мы смотрели в отдельном ф-ле, добавим строчку в конфиг демона журналов:
vi /etc/rsyslog.conf
в конце ф-ла добавим строчку:
local7.*	/var/log/dhcpd.log
в конце ф-ла оставляем пустую строчку (т.к. некоторые конфиг. ф-лы этого требуют)
выходим, сохраняем.
теперь создадим этот файл:
touch /var/log/dhcpd.log
можно проверить посмотреть права на этот ф-л и м. ли демон туда писать
stat /var/log/dhcpd.log
покажет:
Access: (0644/-rw-r--r--) Uid:(0/root) Gid:(0/root)
нужно поменять владельца на syslog и группу владельцев на adm
(подсмотрели права на другие логи из папки /var/log/)
chown syslog:adm /var/log/dhcpd.log
перегружаем сервис rsyslog:
service rsyslog restart
перегружаем сервис dhcp:
service isc-dhcp-server restart
проверяем его статус:
service isc-dhcp-server status
м. показать ошибку (она может не мешать):
Can't create PID file /run/dhcp-server/dhcpd.pid: Permiss..ied
посмотрим адреса аренды:
cat /var/lib/dhcp/dhcp.leases
должны появиться записи после получения адресов
проверим файл логов dhcp:
cat /var/log/dhcpd.log

чтобы копировать куски текста в буфер обмена установим putty на комп с Windows и подключимся ч/з него
запустим команду для генерации ключа:
dnssec-keygen -a HMAC-MD5 -b 128 -r /dev/urandom -n USER DHCP_UPDATER
где
dnssec-keygen работает с dnssec (технология защиты dns, позволяет нам подтверждать информ-ю о подлинности записи на сервере dns)
-a алгоритм (HMAC-MD5)
-b размер ключа (128 бит)
-r устройство отвечающее за генерацию чисел (в ubuntu это /dev/urandom)
-n тип владельца ключа (м.б. ключ для подписи зоны, подписи хоста, мы создаем ключ DHCP_UPDATER для пол-лей)
покажет:
Kdhcp_updater.+157+38479
появятся ключи в папке пол-ля:
Kdhcp_updater.+157+38479.key и Kdhcp_updater.+157+38479.private
откроем ф-л Kdhcp_updater.+157+38479.private
покажет:
Private-key-format: v1.3
Algoritm: 157 (HMAC_MD5)
Key: xR+zsn0k0i+va9IwoSCnzg==
Bits: AAA=
Created: 20150921095641
Publish: 20150921095641
Activate: 20150921095641
пропишем данный ключ в конфигурации dns-сервера  и dhcp-сервера
зайдем в ф-л конф. сервера dns:
vi /etc/bind/named.conf.local
добавим в начало ф-ла информ-ию о ключе, кот-й б.использоваться для обновления инф-ии в зонах прямого и обратного просмотра

key DHCP_UPDATER {
	algoritm HMAC-MD5.SIG-ALG.REG.INT; #алгоритм с пом. которого гинерировали ключ
	secret "xR+zsn0k0i+va9IwoSCnzg=="; #вставили сам ключ
	};
#теперь допишем в каждую зону конф. ф-ла данный ключ
#инф. о зоне прямого просмотра
zone "LAB.LOCAL" {
	type master;				#тип зоны master (главный сервер)
	file "var/lib/bind/forward.bind";	#файл где лежит инф. о зоне
	allow-update { key DHCP_UPDATER; };
	};
#инф. о зоне обратного просмотра
zone "0.168.192.in-addr.arpa" {
	type master;
	file "var/lib/bind/reverse.bind";
	allow-update { key DHCP_UPDATER; };
	};
выходим,сохраняем
рестартуем службу:
service bind9 restart
теперь скажем dhcp-серверу, что сам dhcp может обновлять dns
для этого зайдем в ф-л конфигурации сервера dhcp:
vi /etc/dhcp/dhcpd.conf
допишем в начале ф-ла:
ddns-updates on; #разрешаем обновлять зоны dns
ddns-update-style interim; #изменим стиль обновления на interim
update-static-leases on; #разрешать обновлять статические адреса аренды
authoritative; #оставим

key DHCP_UPDATER {
	algoritm HMAC-MD5; #алгоритм шифрования без дополнений
	secret "xR+zsn0k0i+va9IwoSCnzg==";
	} #в конфигураторе dhcp ; не ставим
#а также добавим информацию о зонах
zone LAB.LOCAL {
	primary 192.168.0.1;
	key DHCP_UPDATER;
	}
zone 0.168.192.in-addr.arpa. {
	primary 192.168.0.1;
	key DHCP_UPDATER;
	}
сохраняем,выходим
перестартуем службу dhcp:
service isc-dhcp-server restart
проверим наличие журналов
ls /var/lib/bind
видим журналов нет
бывает так, что они появляются не сразу и нужно перезапускать сервер.
бывает так, что службы стартуют и некоторое время им нужно поработать, чтобы журналы появились
service isc-dhcp-server status
показал, что служба не работает 'active=failed'
просмотрим лог журнала 
tail -n 30 /var/log/syslog
видим запись, ошибка в 13 строке:
Sep 21 13:02:29 srv sh[12054]: /etc/dhcp/dhcpd.conf line 13: semicolon expected.
исправили рестартуем сервер:
service isc-dhcp-server restart
опять проверим наличие журналов (появляются после первого запроса аренды ip адреса)
ls /var/lib/bind
появились ф-лы forward.bind.jnl и reverse.bind.jnl
проверяем ф-л аренды ip-адресов dhcp-сервера:
cat /var/lib/dhcp/dhcpd.leases
проверим ф-л лога dhcp-сервера:
cat /var/log/dhcpd.log
проверяем получение новой информации в зонах (появится после рестарта службы dns: bind9):
cat forward.bind
-----------------------------------------------------------------------------------------------

СОЗДАЕМ ТРЕКЕР ЗАЯВОК
=====================
Крупные системы:
Системы ITSM (IT Servece Managment)
Системы попроще:
Системы ServiceDesk (автоматизация работы службы тех.поддержки)
Системы еще проще:
Системы HelpDesk (автоматизация обработки запросов) #трекер заявок

АГЕНТ ПЕРЕДАЧИ ПОЧТЫ (MTA) POSTFIX
==================================

по сертификатам: https://habr.com/company/tuthost/blog/150433/
варианты релеев  на разных хостерах: http://sys-adm.org.ua/mail/postfix-sender-dependent-relayhost

Если уже установлен sendmail - его нужно отключить.
устанавливаем пакет postfix:
#На debian потребовалось также установить пакет: apt-get install libsasl2-modules чтобы всё заработало
apt-get install postfix
при установке выбираем конфигурацию Satellite system (просто для отправки почты через к-то узел)
также есть возможность выбрать конфигурации:
Internet Site (полноценный почтовый сервер) 
Internet with smarthost (получает почту сам, а отправляет черз к-то узел)
(все почта отправляется внутри узла, без выхода в сеть)
потом в случае чего в любой момент сможем запустить программу dpkg-reconfigure для запуска мастера настройки
или отредактировать конф. файл
в мастере установки указываем:
1.имя хоста
укажем ubsrv
2.сервер используемый для редиректа
как наз-ся сервер для отправки писем стороннего почтового сервера (mail.ru, gmail) и порт
укажем smtp.gmail.com:587

установим утилиты при пом. которых будем проверять работу почтового сервера (для отправки письма):
apt-get install mailutils
откроем файл конфигурации postfix:
vi /etc/postfix/main.cf
в нем
нужно убедиться, что указан relayhost:
relayhost = smtp.gmail.com:587
можно убрать ipv6 адреса из конфигурации
добавим опцию использования протокола SASL (simple authentication security layer):
smtp_sasl_auth_enable = yes
#укажем откуда брать пароль почты (храним в отдельном ф-ле для безоп-ти)
smtp_sasl_password_maps = hash:/etc/postfix/sasl_passwd
#не пускать никого анонимно на этот сервер
smtp_sasl_security_options = noanonymous
#файл в котором будут лежать доверенные центры сертификации
smtp_tls_CAfile = /etc/postfix/cacert.pem
#указываем, что smtp будет отправляться с использованием tls
smtp_use_tls = yes
сохраняем, выходим
теперь нужно создать ф-л с логином и паролем:
vi /etc/postfix/sasl_passwd
запишем в нем:
smtp.gmail.com:587	mberdyugin@gmail.com:наш_пароль
сохраняем, выходим
теперь сменим права на файл (доступ только у su и только на чтение):
cmod 400 /etc/postfix/sasl_passwd
загружаем этот файл в postfix с пом. команды postmap (исп. для создания и изменения ф-лов конфигураций):
postmap /etc/postfix/sasl_passwd
в папке /etc/ssl/serts лежит куча сертиф-ов, среди них лежит сертификат, 
который явл. центром сертификации для серт-ов вида X.509 (если мы говорим, что доверяем ему - мы автомат. доверяем большинству защищенных серверов в интернете)
/etc/ssl/certs/Thawte_Premium_Server_CA.pem
скопируем его в наш ф-л указанный в конфигурации postfix:
cat /etc/ssl/certs/Thawte_Premium_Server_CA.pem | sudo tee -a /etc/postfix/cacert.pem
рестартуем сервис:
service postfix restart
отправим проверочное письмо:
echo "Test Letter Number 1" | mail -s "Test 1" 1c@mail.ru
посмотрим логи:
tail /var/log/mail.log
на gmaile нужно разрешить доступ к почт. ящику из непроверенных приложений (разрешаем):
https://myaccount.google.com/lesssecureapps
смотрим последние 4 сообщения лога:
tail -n 4 /var/log/mail.log

посмотреть очередь:
mailq
принудительно запустить отправку из очереди:
mailq -q
или
postqueue -f
Очистить очередь
удалить все сообщения:
postsuper -d ALL
postsuper -d <идентификатор письма>
где идентификатор письма можно увидеть командой mailq
также, очередь можно посмотреть командами:
find /var/spool/postfix/deferred -type f | wc -l
find /var/spool/postfix/active -type f | wc -l
find /var/spool/postfix/incoming -type f | wc -l
find /var/spool/postfix/defer -type f | wc -l
перезапустить очередь:
postsuper -r ALL
если не помогло, поочередно:
postfix stop
postsuper -r ALL
postfix start
задать периодичность повторной отправки сообщений:
postconf -e "queue_run_delay = 5m"
задать время, на которое будет отложена отправка сообщений, которые не были отправлены по причине временных неисправностей (например, принимающий сервер не отвечает или просит повторить запрос позже):
postconf -e "minimal_backoff_time = 10m"
задать максимальное время для отправки сообщений, которые не были отправлены по причине временных неисправностей:
postconf -e "maximal_backoff_time = 15m"
Выставить время жизни для сообщения в очереди:
postconf -e "maximal_queue_lifetime = 1d"

---------------------------------------------------------------------------------------------------------------------------------------------------------------
выбор системы: https://toster.ru/q/44724
внедрение каяко: https://habr.com/company/plarium/blog/220585/

отключаем фаервол ubuntu, чтобы не мешал:
ufw disable
чтобы удаленно подключаться через Putty устанавливаем ssh-сервер:
apt-get install openssh-server
обновляем список репозитория:
apt-get update
ставим обновления на ubuntu:
apt-get upgrade
установим mysql-сервер, mysql-клиент, необходимые для этого библиотеки:
apt-get install mysql-server mysql-client libmysqlclient-dev
в мастере установки указываем пароль для юзера "root" MySQL (достаточно 4 символа)
отредактируем ф-л конфигурации mysql:
vi /etc/mysql/mysql.conf.d/mysqld.cnf
добавим параметр увеличенный размер кэша:
#рекомендуется выставлять в размере половины ОЗУ сервера
innodb_buffer_pool_size = 2048M
запустим мастер, который обезопасит установку:
mysql_secure_installation
попросит ввести пароль от п-ля root MySQL-сервера
спрашивает хотим ли мы изменить пароль, ставим "n"
спрашивает удалить анонимных пол-лей: "y"
запретить удаленно подключаться: "y"
удалять ли тестовую БД: "y"
перезагрузить таблицу привелегий: "y"
рестартуем сервис mysql:
service mysql restart
теперь разберемся с сервером WEB
установим следующие пакеты:
apt-get install make apache2 libapache2-mod-fcgid libssl-dev libyaml-perl libgd2-xpm-dev libgd-gd2-perl libgraphviz-perl
make - утилита для преобразования ф-лов из одной формы в другую (компилировать исходный код)
добавим пол-ля rt, создадим одноименную группу, добавим пол-ля в эту группу:
adduser --system --group rt
добавим юзера rt в группу www-data (apache):
usermod -aG rt www-data
--------------------------------------------------------------------------------------------------
для установки трекера заявок скачаем установочный пакет с офиц. сайта https://www.bestpractical.com
Мануал по конфигуратору: https://docs.bestpractical.com/rt/4.2.15/configure.html
Русскоязычная статья неплохая: https://habr.com/sandbox/96505/
Лучший мануал (англ): http://binarynature.blogspot.ru/2013/10/install-request-tracker-4-on-ubuntu-server.html
для начала обновим информацию о репозиториях:
apt-get update
проверяем установлен ли perl и make:
apt-get install perl
apt-get install make
мы сейчас будем компилировать свой request tracker используя его конфигурационные ф-лы.
для этого есть спец. make-фйлы, которые запускают последовательности команд, подкачивают зависимости
приступаем к скачке с сайта пакета трекера с пом. команды wget:
wget https://download.bestpractical.com/pub/rt/release/rt-4.2.12.tar.gz
по умолчанию ф-л скачивается в домашнюю папку пол-ля, распакуем во временную директорию:
tar xzvf rt-4.2.12.tar.gz -C /tmp
где:
-x extract (распаковать)
-z использовать gzip
-v (verbose) показывать что происходит
-f (file) куда выводить
-C распакует в папку
после перезагрузки системы из папки /tmp все сотрется
в этой папке появилась папка /tmp/rt-4.2.12
переходим в эту папку и запускаем конф. ф-л с параметрами:
./configure --with-web-user=www-data --with-web-group=www-data --enable-graphviz --enable-gd
где:
--with-web-user от кого запускаем (пол-ль от которого работает web-сервер apache "www-data")
--with-web-group от группы пол-лей
--enable-graphviz пакет graphviz (в нем много утилит ком. строки и GUI программ, нужен чтобы создавать графы и строить разл. зависимости)
--enable-gd пакет связанный с графикой и диаграммами
теперь сконфигурируем библотеку модулей span:
cpan
разрешить конфигурирование автоматически: "y"
пускает в оболочку конфигурации
зададим изначально установку зависимостей (зададим "ставить по умолчанию"), в оболочке пишем:
o conf prerequisites policy follow
модули, которые нужны для установки, но потом не нужны в системе
зададим политику по умолчанию, ставить все модули  которые нам нужны для build-a текущих пакетов и пусть они у нас остаются в системе:
o conf build_requires_install_policy yes
для того, чтобы эта конфигурация применилась напишем:
o conf commit
выходим из оболочки буквой "q"
проверим текущую конф-ю для настройки rt:
make testdeps
для доустановки недостающего, запускаем утилиту фиксирования найденных проблем:
make fixdeps
#процесс м. затянуться на 30мин
в ходе установки возник вопрос, установить модуль XS Stash "Do you want to build the XS Stash module?", отвечаем "y"
Do you want to use the XS Stash by default? ставим тоже "y"
(возможно этот  пакет придется скачивать и устонавливать вручную через wget)
(д.б. доступ к интернету)предлагает провести доп. тесты "Do you want to run the live tests (y/N)?" ставим тоже "y"
еще раз проверим, все ли у нас установилось:
make testdeps
если опять чего-нибудь не найдет (missing) - опять запустим make fixdeps
если все found, то м. выполнять действие установки:
make install
необходимо инициализировать БД:
make initialize-database
запрашивает пароль от п-ля root от mysql
теперь нужно настроить apache (в данный м. при переходе на наш ip-адрес отображается страница по умолчанию apache)
переходим в папку доступных ф-лов apache:
cd /etc/apache2/sites-available/
ls
видим 2 ф-ла:
000-default.conf - конфигурация по умолчанию для стартовой страницы
default-ssl.conf - конфигурация по умолчанию для доступа через ssl
отредактируем ф-л 000-default.conf8 для доступа через http :
#допишем имя сервера
ServerName rt.ubsrv:80
#добавим блок для работы трекера
AddDefaultCharset UTF-8
DocumentRoot /opt/rt4/share/html #директория куда по умолчанию установился трекер - /opt/rt4/
Alias /NoAuth/images/ /opt/rt4/share/html/NoAuth/images/
ScriptAlias / /opt/rt4/sbin/rt-server.fcgi/
<Location />
Require all granted
</Location>
закомментируем строчки:
#ServerAdmin webmaster@localhost
#DocumentRoot /var/www/html
сохраняем,выходим
перезапускаем apache:
service apache2 restart
если стартанул без ошибок
заходим на нашу страницу через браузер, видим что все заработало
по умолч. логин root, пароль: который_мы_задавали (password)
---------------------------------------------------------------------------------------------
Полный мануал по всем возможностям: https://docs.bestpractical.com/rt/4.4.3/index.html
Опции для файла RT_SiteConfig.pm: https://docs.bestpractical.com/rt/4.4.3/RT_Config.html

откроем ф-л конфигурации:
/opt/rt4/etc/RT_SiteConfig.pm
добавим здесь базовые настройки:
Set($rtname,'rt.it-semaev.ru'); #имя rt, желательно, чтобы совпадало с внешним именем
Set($Organisation, 'rt.it-semaev.ru');
Set(@ReferrerWhitelist, qw(10.0.1.8:80); #лист с которого б.разрешено обращаться к нашему rt
Set ($Timezone, 'Europe/Moscow');
Set($LogoLinkURL, 'http://it-semaev.ru'); #ссылка на логотип
сохраняем и перегружаем apache:
service apache2 restart
остальные настройки уже делаем через браузер
---------------------------------------------------------------------------------------------
Мануал по модулю: https://metacpan.org/pod/RT::Authen::ExternalAuth
Пример внедрения: http://trevthorpe.blogspot.ru/2015/01/request-tracker-424-ldap-authentication.html
установим модули для внешней аутентификации:
cpan -i RT::Authen::ExternalAuth
модуль для импорта из службы каталогов:
cpan -i RT::Extension::LDAPImport
отредактируем ф-л конфигурации /opt/rt4/etc/RT_SiteConfig.pm
добавим записи:
Set(@Plugins, qw(RT::Extension::LDAPImport)); #подключим плагин
#добавим опции к плагину
Set ($LDAPHost,'dc.mti.local'); #имя контроллера домена
Set ($LDAPUser,'mti\rt'); #пол-ля от имени кот-го будем просматривать наш домен
Set ($LDAPPassword, '1000'); #пароль пол-ля
Set ($LDAPBase, 'dc=mti,dc=local'); #каталог в АД из которого б.импортировать пол-лей
Set ($LDAPFilter, '(&(objectClass=person))'); #фильтр импорта только людей
Set ($LDAPMapping, {	Name	=> 'sAMAccountName'), #имя импортируемого пол-ля
			RealName	=>'cn', #реальное имя пол-ля
			EmailAddress	=> 'mail'}); #брать email адрес пол-ля
Set ($LDAPCreatePrivileged, 1); #привелегированные права пол-ля
Set ($LDAPUpdateUsers, 1); #обновлять инф-ю о пол-лях при запуске импорта
сохраняем,выходим
запустим тестовый импорт:
/opt/rt4/local/plugins/RT-Extension-LDAPImport/bin/rtldapimport \
> --debug > ldapimport.debug 2>&1
#создаст в папке, в кот-й мы находимся ф-л ldapimport.debug
теперь запустим импорт:
/opt/rt4/local/plugins/RT-Extension-LDAPImport/bin/rtldapimport \
> --import
добавим в ф-л конфигурации еще плагин аутентификации:
Set (@Plugins, qw(RT::Authen::ExternalAuth RT::Extension::LDAPImport)); #добавим в эту строчку
#а также настройки плагина, в принципе поль-ли м.создаться только с этим плагином, без импорта 
Set ($ExternalAuthPriority, [ 'My_AD' ]); #куда он будет передавать запросы аутентификации ('My_AD' псевдоним источника)
Set ($ExternalAuthPriority, [ 'My_AD' ]); #если есть альтернатива от куда еще качать
Set ($UserAutocreateDefaultsOnLogin, { Priveleged => 1 }); #привелегированные права пол-ля
Set ($ExternalSettings, {
	'My_AD'		=> {
	'type'		=> 'ldap',
	'server'	=> 'dc.mti.local',
	'user'		=> 'mti\rt',
	'pass'		=> '1000',
	'base'		=> 'dc=mti,dc=local', #от куда берем пол-лей
	'filter'	=> '(objectClass=person)',
	'attr_match_list'	=> ['Name'], #аттрибут как пол-ль м.аутентифицироваться (по имени 'login')
	'attr_map'	=> {			#указываем, что за параметр 'Name'
	'Name'		=> 'sAMAccountName',
	'EmailAddress'	=> 'mail',
	'RealName'	=> 'cn',
	},
	},
} );
сохраняем,выходим
рестартуем apache:
service apache2 restart
для проверки в АД создадим пол-ля, которого не было при импорте
проверяем вход в трекере
---------------------------------------------------------------------------------------------------------------------------
ou - organisation unit
cn - canonical name
Настроим аутентификацию через apache
Мод базовой аутентификации: https://httpd.apache.org/docs/2.4/mod/mod_auth_basic.html
Мод ldap аутентификаци: http://httpd.apache.org/docs/current/mod/mod_authnz_ldap.html
Разные опции RT: https://docs.bestpractical.com/rt/4.4.1/RT_Config.html
зайдем в конфиг зайта по умолчанию apache:
/etc/apache2/sites/available/000-default.conf
для того, чтобы apache м.авторизовывать пол-лей нужно изменить строчку Require all granted на:
Require valid-user #пол-ли д.б. настоящие, т.е. могли авторизоваться
AuthType Basic #тип аутентифик. базовый
AuthName "Request Tracker" #какая строчка б. показана браузером
AuthBasicProvider ldap
AuthLDAPURL "ldap://192.168.0.1/dc=mti,dc=lan?sAMAccountName?sub?(objectClass=*)"
# IP dc(м. имя)/basedn(откуда искать пол-лей)?что ищем у по-лей(sAMAccountName)?sub(пробираемся в глубь дерева)?класс объекта поиска=*(м.поставить person)
#след.строка от имени кого б. проверять, т.к. АД не умеет пускать анонимных п-лей поэтому создадим пол-ля connect в корне домена
AuthLDAPBindDN "cn=connect,dc=mti,dc=lan" 
AuthLDAPBindPassword "1000" #пароль п-ля connect
сохраняем,выходим
включаем еще модуль:
a2enmod authnz_ldap
рестартуем apache:
service apache2 restart
чтобы после авторизации apache еще не было авторизации web, нужно открыть ф-л конфигурации rt:
/opt/rt4/etc/RT_SiteConfig.pm
в конец добавим опцию, кот-я позволит пол-лю авторизоваться:
Set ($WebRemoteUserAuth, 1); #позволит передавать apache инф. об успешном логировании rt
#теперь при входе на rt не б. пускать п-ля root, чтобы это исправить нужно покопаться в apache
----------------------------------------------------------------------------------------------

ПОЧТОВЫЕ АГЕНТЫ МТА
===================

Управление командой mail: https://www.lifewire.com/mail-linux-command-unix-command-4097057
Хороший пример по очистке очереди сообщений: http://val-khmyrov.blogspot.ru/2012/10/postfix.html

MTA - Mail Transfer Agent
установим почтовый агент postfix
apt-get install postfix
в мастере конфигурации выбираем "Только локальное исполнение"
(предназначена только для локальных пользователей) без сети
для тогочтобы управлять почтой нам нужны б. утилиты
apt-get install mailutils
создались псевдонимы в файле:
/etc/aliases
содержит:
postmaster: root #те кто будут писать postmaster-у сообщения приходят root-у
добавим:
Kirill: semaev #кто пишет Kirill-у получать б. semaev
сохр.,выходим
чтобы псевдоним закрепился в системе надо ввести команду:
newaliases
после этого новые псевдонимы загружаются в конфиг. системы и почтовый сервис видит эти псевдонимы
чтобы создался ящик у пол-ля необходимо написать письмо
mail semaev@ubuntudesktop (имя_пол-ля@имя_хоста)
или через псевдонимы
mail kirill
откроется диалог создания письма:
Cc: (кому отправлять копию) нажимаем enter
Subject: Test #1 нажимаем enter
Test message (вводим текст сообщения)
для того, чтобы закончить письмо - переходим на новую строчку и нажимаем ctrl+d
после этого сообщение ставится в очередь на отправку
теперь, если введем команду mail, то увидим (есть 1 сообщение из них 1 новое):
"/var/mail/semaev": 1 message 1 new
>N	1 semaev	Пн.янв.11 15/463 Test #1
?
Для того, чтобы прочитать это сообщение нужно выбрать его номер, нажимаем 1 enter
после откроется сообщение
Return-Path: <semaev@ubuntudesktop> #пришло получателю
X-Original-To: kirill@ubuntudesktop #отправлено получателю
если выбрать d - сообщение б.удалено
?d
чтобы выйти из агента нажать q
если опять напишем команду mail - напишет:
Нет почты для semaev
чтобы пересылать почту, создадим в папке пол-ля скрытый ф-л forward:
cd ~
vi .forward
в нем укажем кому хотим переадресовывать почту (другого пол-ля), напишем root
теперь при отправке письма kirill оно отправится root
mail kirill
чтобы проверить почту у пол-ля root
sudo mail
сообщит о получении сообщения
команды sendmail б. работать во всех агентах
man sendmail
#откроет мануал по установленному почтовому агенту (postfix)
команда mailq - просмотр очереди сообщений
-----------------------------------------------------------------------------

СЕРВЕР ПЕЧАТИ CUPS
==================

URI - Uniform Resource Identifier — унифицированный (единообразный) идентификатор ресурса
установим cups (в десктоповой ubuntu он есть по умолчанию)
apt-get install cups
пакет, который создаст pdf-принтер:
apt-get install cups-pdf
в аплете принтер, в настройках. добавим новый принтер
введем URI локального usb-принтера:usb://Samsung/ML-2850
в cups можно зайти через браузер, в адресной строке вводим:
http://localhost:631
в нем также можно добавить принтер, через меню Administration
конфигурация сервера печати и настроек доступа к нему наход. в ф-ле:
/etc/cups/cupsd.conf
настройки каждого принтера:
/etc/cups/printers.conf
откроем ф-л cupsd.conf:
в нем:
LogLevel warn #cups б. записывать события от предупреждений warning и выше
MaxLogSize 0 #максим. размер лога
Listen localhost:631 #по каким портам прослушивает соединения (м.указать IP-адрес сет.карты)
а также указаны настройки доступа
есть мануал по этому конф.файлу (man cupsd.conf)
есмли хотим дать права оператора печати к-либо пол-лю, его нужно добавить в группу lpadmin:
usermod -aG lpadmin [имя_пол-ля]
#он сможет управлять демоном cups через web-интерфейс или через инструменты настройки
посмотрим ф-л printers.conf:
в нем есть адрес URI принтеров (через к-кой протокол к нему подключаться), описание, модель
команды управления очередью печати:
lpq (lpquery)
lpq -a #покажет очередь печати по всем принтерам
lpq #покажет информацию по принтеру "по умолчанию"
информация по принтеру (очередь печати):
lpq -P[имя_принтера]
например
lpq -PSamsung
покажет:
Samsung готов
нет записей
отправим на печать на принтер файл pushkin.txt:
lpr -PSamsung pushkin.txt
задания очереди печати сохраняются (до момента отправки на печать) в папке /var/spool/cups
удалим задание из очереди печати (предварительно узнав его номер командой lpq -a):
lprm 24
удалить все задания из очереди принтера "Samsung":
lprm -PSamsung -
посмотреть состояние всех принтеров:
lpc status all
перестать принимать задание на принтер PDF:
cupsreject PDF
разрешить принимать задание на принтер PDF:
cupsaccept PDF
приостановить печать (очередь б. копиться)(ключ -r reason причина):
cupsdisable -r "Out of paper" Samsung
включить очередь печати:
cupsenable Samsung
чтобы перекинуть задания очереди печати с принтера Samsung на принтер PDF
перенести задание №29 на принтер PDF:
lpmove 29 PDF
перекинуть все задания с принтера Samsung на принтер PDF:
lpmove Samsung PDF
чтобы отследить физический статус принтера через командную строку помогут скрипты:
https://unix.stackexchange.com/questions/216223/how-to-make-cups-show-a-usb-printer-as-disabled-when-it-is-disconnected
----------------------------------------------------------------------------------

КОНФИГУРАЦИОННЫЕ Ф-ЛЫ СЕТИ
==========================
для настроек сети важно узнать имя адаптера:
lshw -C network
имя хоста находится в ф-ле:
/etc/hostname
ф-л текстовой БД соответствия ip-адресов и имен:
/etc/hosts
ф-л настройки DNS (прописываются адреса серверов dns):
/etc/resolv.conf
содержит:
nameserver 127.0.0.1 #адрес сервера dns
search alter-ego.local #список доменов для поиска (взаимоисключающие адреса, считается правильным последний)
domain #домен в котором находится комп.
в папке /etc/resolvconf/resolv.conf.d находится 2 ф-ла:
base и head, в некоторых дистрибутивах ф-л tail
base - содержит то, что мы хотим чтобы было в теле resolv.conf
head - то, что б. появляться в ф-ле resolv.conf над основной конфигурацией
tail - то, что будет в конце ф-ла конфигурации
перезаписать информацию в dns (в конфиг. ф-л /etc/resolv.conf), если мы вводили изменения в эти 3 ф-ла:
resolvconf -u
ф-л отвечающий за настройки диспетчера службы имен:
/etc/nsswitch.conf
в нем первая колонка - БД, 2-я колонка - то, где мы будем искать инф-ю
например содержит строку:
hosts:	files mdns4_minimal [NOTFOUND=return] dns
где:
files - сначала искать в локальных ф-лах
dns - в конце искать на серверах dns
mdns4(multicast dns) - каждый компьютер сам хранит запись о своей зоне. Обращается в сеть по широковещ. адресу, а запрашиваемый хост отвечает
mdns4_minimal - говорит о том, что искать узлы в лок. сети в mdns нужно, только если они находятся в зоне .local,
если ни какого ответа не будет, то срабатывает параметр [NOTFOUND=return] - мы возвращаемся и не делаем поиск по серверам dns (поэтому зоны .local нельзя делать, т.к. запрос не пойдет на сервера dns)
значения параметра бывают:
return - вернуться
comtinue - продолжить
условия:
success - успех
notfound - не найден
not available - не доступен
try agent - попробовать еще
-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
в redhat ф-лы конфигурации сети находятся:
/etc/sysconfig/network-scripts/
настройка интерфесов происходит в ф-лах ifcfg-[if_name] 
enp0s3 (имя сет. интерфейса) - ethernet network periphery[номер_шины]s[номер_слота]
смотрим ф-л ifcfg-enp0s3
содержит:
TYPE=Ethernet
BOOTPROTO=dhcp #в момент загрузки получай ip по DHCP
DEFROUTE=yes #этот интерфейс будет маршрутом по умолчанию
PEERDNS=yes #файл resolv.conf будет перезаписываться и DNS-сервер в него будет списываться полученное от DHCP-сервера
PEERROUTES=yes #будем получать маршруты от сервера DHCP и записывать их в свои ф-лы конфигурации сети
IPV4_FAILURE_FATAL=no #является ли фатальным отказ стека IPv4 (если не работает стек - выключать карту или нет)
IPV6INIT=yes #инициализировать или нет
IPV6_AUTOCONF=yes
IPV6_DEFROUTE=yes
IPV6_PEERDNS=yes
IPV6_PEERROUTES=yes
IPV6_FAILURE_FATAL=no
NAME=enp0s3
UUID=501733e8-a3d0-48ee-b28c-345de265f786
DEVICE=enp0s3
ONBOOT=no #сетевой интерфейс по умолчанию да/нет
отредактируем его:
BOOTPROTO=static //или none
IPADDR=192.168.0.101
NETMASK=255.255.255.0
GATEWAY=192.168.0.9
DNS1=192.168.0.1
DNS2=192.168.0.2
сохр,выходим
перезапускаем службу сети
systemctl restart network
после этого проверяем ф-л /etc/resolv.conf
там должен поменяться DNS-сервер на который мы ввели

в ubuntu ф-л настроек сет-х интерфейсов находится в ф-ле:
/etc/network/interfaces
#desktop ubuntu не хранит в нем настройки реальных интерфейсов, а хранит их networkmanager
#в /etc/NetworkManager/NetworkManager.conf
содержит только
auto lo
#auto - говорит, что инт-фейс б. автоматически включаться вместе с загрузкой системы
iface lo inet loopback
добавим сюда значение физического инт-фейса:
auto lo enp0s3
iface lo inet loopback
#inet - говорит о том, что это маршрутизируемая сеть
iface enp0s3 inet static
address 192.168.0.102
netmask 255.255.255.0
gateway 192.168.0.9
dns-nameservers 192.168.0.1 192.168.0.2
если делалось в desktop ubuntu, то необходимо б. отключить network manager
для этого зайдем в ф-л конф. Network Manager в ф-л /etc/NetworkManager/NetworkManager.conf
содержит:
[main]
plugins=ifupdown,keyfile,ofono
#dns=dnsmasq #dnsmasq офиц. приложение объедин. DNS+DHCP, чтобы DNS-сервера приписывались из ф-ла /etc/network/interfaces нужно закоментировать
[ifupdown]
managed=false #исправим на true (сами б. управлять интерфейсами)
сохр.,выходим
перезапускаем network manager:
service network-manager restart
перезапускаем службу сети:
service networking restart
в десктоповых ubuntu не рекомендуется отключать network manager, иначе будет подвисать стек IP
-----------------------------------------------------------------------------------------------------------------------------------------------
чтобы вручную установить сетевую карту вначале выключаем старую:
ifconfig enp0s3 down
установим ip-адрес на оставшуюся сет. карту:
ifconfig enp0s8 192.168.0.50/24
проверим интерфейсы:
ifconfig -a #покажет, что инт. enp0s3 находится в down
удалим драйвера сет. карты, для этого смотрим какие у нас есть модули ядра (драйверы):
lsmod
и видим строчку:
e1000	131072	0 #драйвер модели сет. карты Intel PRO/1000 MT Desktop
pcnet32 45056	0 #драйвер второй сет. карты (работающей) модели PCnet-FAST III (Am79c973)
удаляем драйвер карты:
rmmod e1000
теперь кагда сделаем команду "ifconfig -a", то карты уже не увидим
после этого выключаем комп и выдергиваем сет. карту

В ubuntu desktop настройки сет. интерфейсов рекомендуется делать через Network Manager
В ubuntu server делать настройки в ф-ле /etc/network/interfaces (стираем инф-ю о карте)
	удаляем инф. из строчки "auto" о старом адаптере, добавляем инф. о 2-м сет. адаптере
	потом прописываем сетевые настройки 
--------------------------------------------------------------------------------------------
великолепная команда ip: http://ss64.com/bash/ip.html

отключим сет.карту:
ifdown enp0s3
включим сет.карту:
ifup enp0s3
назначим интерфейсу enp0s3 сетевой адрес, маску и т.д.:
ifconfig enp0s3 192.168.0.111
ifconfig enp0s3 netmask 255.255.255.0
IP-адрес изменится, но после перезагрузки службы сети вернется к исходному, т.к. он прописан в конфигурационном ф-ле
можно изменить MAC адрес:
ifconfig enp0s3 hw ether 08:00:27:1c:5a:dd
для просмотра маршрутов исп. команда route:
покажет:
Destination	Gateway		Genmask		Flags	Metric	Ref	Use	IFace
default		192.168.0.10	0.0.0.0		UG	0	0	0	enp0s3
link-local	*		255.255.0.0	U	1000	0	0	enp0s3
192.168.0.0	*		255.255.255.0	U	0	0	0	enp0s3
где:
default - маршрут по умолчанию, кот-й говориит, что по всем запросам не найденным в нашей сети 
нужно обращаться к машрутизатору 192.168.0.10
link-local - говорит, что все замкнуто на самого себя
строчка 192.168.0.0 говорит о том, в сети 192.168.0.0 мы можем работать без к-либо маршрутизатора
удалим маршрут по умолчанию:
route del default
добавим маршрут по умолчанию (опция gw - адрес шлюза (м-ра)):
route add default gw 192.168.0.110
показать ip-адреса интерфейсов:
#команда ip работает со стеком ip, тогда как ifconfig работает только с сетевыми интефейсами 
ip addr
отключить интерфейс enp0s3:
ip link set enp0s3 down
включить интерфейс enp0s3:
ip link set enp0s3 up
стереть ipv4 адрес на интерфейсе enp0s3:
ip -4 address flush enp0s3
добавить ipv4 адрес на интерфейсе enp0s3:
ip address add 192.168.115.118/255.255.255.0 dev enp0s3
--------------------------------------------------------------------------------------------
исправление маршрутов
посмотрим таблицу root:
покажет:
Destination	Gateway		Genmask		Flags	Metric	Ref	Use	IFace
default		192.168.0.10	0.0.0.0		UG	100	0	0	enp0s8
default		10.0.1.1	0.0.0.0		UG	101	0	0	enp0s3
10.0.1.0	*		255.255.255.0	U	100	0	0	enp0s3
link-local	*		255.255.0.0	U	1000	0	0	enp0s8
192.168.0.0	*		255.255.255.0	U	100	0	0	enp0s8
флаг UG говорит о том, что маршрут включен и используется шлюз (G) на этом маршруте
удалим маршрут с метрикой 101:
route del default gw 10.0.1.1
добавим маршрут с более низкой метрикой:
route add default gw 10.0.1.1 netmask 0.0.0.0 dev enp0s3 metric 99
чтобы эти маршруты не сбросились после перезагрузки
для ubuntu desktop:
отредактируем ф-л /etc/NetworkManager/NetworkManager.conf
меняем строчку
managed=true #будем вручную управлять сет. интерф-сами
заходим в конфиг. файл интерфейсов /etc/network/interfaces:
дописываем:
auto lo enp0s3 enp0s8 #интерфейсы стартующие при включении системы
iface lo inet loopback
iface enp0s3 inet dhcp
#также нужно внести информацию о метрике, иначе после перезагрузки маршруты будут отображаться неверно
metric 100
iface enp0s8 inet static
address 192.168.0.5
netmask 255.255.255.0
gateway 192.168.0.10
metric 101
------------------------------------------------------------------------------------------------------
пример использования nc: http://handynotes.ru/2010/01/unix-utility-netcat.html

инструменты диагностики сети
показ. имя хоста:
hostname
запрос у сервера DNS информации, минуя локальные конфиги (ф-л hosts)(аналог nslookup в wind.):
host ya.ru #покажет запись вида А
host 8.8.8.8 #покажет ответ зоны обратного просмотра
тоже самое, но в развернутом виде получим командой dig:
dig ya.ru
получи информацию с сервера 8.8.8.8 о узле yandex.ru:
dig @8.8.8.8 yandex.ru
где в выводе строка ;;SERVER: 8.8.8.8#53(8.8.8.8) показывает какой сервер ответил на запрос
пингу узла в 10 шагов:
ping ya.ru -С 10
посмотреть маршрут до узла:
traceroute ya.ru
#устанавливается дополнительно apt-get install traceroute
#если маршрутизатор узла показывает *, значит либо он игнорирует (отбрасывает) данные запросы, либо ставит низкий приоритет ответов
аналогичная утилита, но более простая, tracepath (использует готовый функционал системы API)
показать статистику сети netstat
показать все tcp,udp порты:
netstat -tu
покажет:
Proto(протокол), Recv-Q(очередь отправки), Send-Q(очередь получения), Local address(лок. адрес:порт), Foreign address(адрес куда пытаемся попасть), State(состояние)
State м.б. CLOSE_WAIT - сторона отключилась, но сокет еще открыт
#порт ipp - internet printing protocol
показать без имен хостови названий портов:
netstat -ntu
показать тоже самое, но со службами (демонами PID):
netstat -ntup
статистика соединений по портам:
netstat -s
посмотреть таб-цу маршрутизации (аналогично route):
netstat -r
полный вывод команды netstat показывает еще и локальные сокеты домена UNIX (конечная точка обмена данными)
сначала выводит сетевые потоки, потом байтовые (сокеты)
утилита netcat (установка соединений) в ком. строке используется с сокращением nc
ключ -v verbose (с выводом)
можем использовать в качестве сервера (-l list (слушать) -p port -v verbose -n без dns запросов -z прослушивать демоны -w таймаут по умолчанию)
начни с выводом в консоль принимать соединения по порту 12345:
nc -l -v -p 12345
создать подключение с уд.хостом www.it-semaev.ru по порту 80
nc -v www.it-semaev.ru 80
если создать т.о соединение с хостом с одной стороны, а на др. хосте слушать это соединение,
то соединение м/у 2-мя хостами б. установлено
компы могут передавать ф-лы, переговариваться  через программу nc
прослушаем порты на удаленном узле 10.0.1.1, порты с 50-100:
nc -v -n -z -w 1 10.0.1.1 50-100
--------------------------------------------------------------------------------------------

МОНИТОРИНГ СЕТИ
===============

ifconfig или ip addr
	mtu (maximum transmition unit) макс. размер блока информации, кот-й передается в рамках одного пакета 1500 байт
	txqueuelen (длина очереди передачи) - размер буфера передачи 1000 packets(пакетов). Как становится 1000 пакетов - они отправляются по сети
	scopeid как далеко наш ip известен за пределами данной системы
		global - глобальный публичный IP
		site - действителен для адресов ipv6
		link - наш адрес действителен в пределах локальной сети
		host - адрес разрешен только в пределах хоста 127. 0.0.1
	RX receive - получить. Сколько пакетов получено
		RX errors(ошибки) dropped(отброшенные) overruns(firstin/firstout errors)- если буфер переполняется, а ядро не успевает его очищать - здесь появятся ошибки
		frame - показывает нецелые кадры (не кратные 8, т.е. что-то недополучили, ошибки, проблемы со свичем)	
	TX transmit - передать. Сколько пакетов отправлено
		carrier (носитель, несущая волна) цифр. инф-я преобразуется в аналоговую (проблемы с кабелем)
		collisions (колизии). Ошибки связанные с настройкой оборудования (дуплекс/полудуплекс)
выводит инф-ю об интерфейсах:
netstat -ie
выводит статистику:
netstat -s
netstat -tuna #вывод портов tcp,udp,numeric (адреса ipv4,6),all (все соединения)
	Recv-Q очередь получения
	Send-Q очередь отправки
	Local Address 0.0.0.0:111 - для всех сет. инт-фейсов слушается(State Listen) порт 111 
netstat -ntulp #l-listen,p-program
установим пакеты:
yum install wget iftop nload
iftop - в реальном времени псевдографикой показывает куда/откуда отправляется инф-ия
	cum - сколько всего трафика б. получено с момента запуска программы
	peak - пиковое значение за посл. 40сек.
	rates - ср.скорость за посл. 2, 10, 40сек
iftop -nP #отключает имена хостов, включает номера портов
закрываем через q
nload - псевдографикой показ-ет загрузку сети
	Incoming - входящий
	Outgoing - исходящий
vnstat - показывает статистику приема/передачи трафика в месяц, неделю, день
vnstat -h #статистика по часам в течение дня
vnstat -d #статистика по дням
vnstat -t #top 10 дней в которые б. скачано больше всего трафика
vnstat -m #статистика по месяцам

для трассировки маршрута исп. traceroute
по умолчанию исп. протокол icmp, т.к. он чаще режится, м. переключится на исп. протокола tcp:
traceroute -T mail.ru
сделать не 30 шагов (по умолчанию), а - 100, и отправлял не 3 пакета за один шаг (по умолчанию), а - 1:
traceroute -m 100 -q 1 mail.ru
чтобы при трассирровке инф-я динамически обновлялась исп. утилиту mtr:
mtr mail.ru
где
Loss% - %потери пакетов
Snt - к-во отправленных пакетов
Last - время прохождения последнего пакета через всю цепочку
Avg - ср-ее время
Best - лучшее время
Wrst - худшее время (worst)
StDev - разброс значений (если разброс большой, то значит до этого узла сильно скачат значения и мы не м. доверять значению avg, 
	также это м. говорить о сильной загрузке данного маршрутизатора)
#в идеальной ситуации цифры д. расти сверху вниз
скажем, чтобы он работал по порту 80, с интервалом 0,2сек., с отчетом (-r) широким (-w), отправил 10 пакетов (-с 10):
mtr -P 80 -i 0.2 -rwc 10 mail.ru

для замера скорости канала исп. утилита iperf или iperf3
на одной стороне запускается сервер, на другой клиент (по умолч. идет отправка 1ГБ)
запустим сервер:
iperf3 -s #б. слушать порт 5201
запустим клиент на др. машине с адресом хоста сервера:
iperf3 -c <адр_хоста>
м. вручную задать размер передаваемых данных -n 500МБ:
iperf3 -c <адр_хоста> -n 500M
м. задать время теста -t 5 (5сек.):
iperf3 -c <адр_хоста> -t 5
м. запустить тест в обратном порядке (б. отправлять пакеты сервер, upload у сервера, downoad у клиента) для этого запустим на клиенте с ключом -R:
iperf3 -c <адр_хоста> -R
проверка канала в фоновом режиме с выводом рез-та через 10сек:
iperf3 -c <адр_хоста> -i 10
Interval - время за которое отправляются данные (по умолч. 1сек)
Transfer - отправлено байт
Bandwidth - пропускная способность
Retrive - к-во переотправки пакетов
В итоговых значениях покажет:
Sender - скорость upload (отправки до сервера)
Receiver - скорость download (загрузки с сервера)



НАСТРОЙКА КЛИЕНТА DNS
=====================

ссылка по dnsmasq: https://wiki.archlinux.org/index.php/Dnsmasq_%28Русский%29
информация о конфигурации БД находится в ф-ле:
/etc/nsswitch.conf
в нем о ДНС говорит строчка:
hosts:	files mdns4_minimal [NOTFOUND=return] dns #порядок поиска информации
посмотрим ф-л /etc/hosts
резолвер получаю инф-ю от демонов dns записывает в ф-л /etc/resolv.conf
локальный сервер dns называется dnsmask
утилита getent обращается к различным БД
получить информацию о хостах:
getent hosts
она просмотривает ф-л /etc/hosts и показывает записи из него
через нее м. посмотреть как корректно разрешаются имена в лок. системе
может посмотреть инф-ю на сервере dns:
getent hosts mti.edu.ru
-----------------------------------------------------------------------------

ИССЛЕДОВАНИЕ ОТКРЫТЫХ ПОРТОВ И СЛУЖБ
====================================

посмотреть работающие службы и порты м. в файле:
less /etc/services

утилита netstat покажет статистику сети (открытые порты, файлы, сокеты):
ключи:
-t tcp
-u udp
-n numeric (в числовом формате, не переводить в имена служб)
-a all (показывать все открытые используемые и не используемые порты)
netstat -tuna
например покажет:
Proto(протокол), Recv-Q(очередь отправки), Send-Q(очередь получения), Local address(лок. адрес:порт), Foreign address(адрес куда пытаемся попасть), State(состояние)
udp		0				0			0.0.0.0:44904			0.0.0.0:* 
#если локальный адрес 0.0.0.0 значит порт прослушивается по всем интерфейсам
#если локальный адрес 127.0.0.1(петлефой интерф-с), значит система прослушивает сама себя по этим портам
за что отвечают указанные порты м. узнать открыв ф-л /etc/services
установим nmap: apt-get install nmap
просканируем локальные порты через nmap:
nmap 127.0.0.1
или
nmap localhost
покажет:
PORT 	STATE	SERVICE
22/tcp	open	ssh #занят демоном ssh
631/tcp	open	ipp #занят internet printing protocol
или
sudo nmap -p1-65535 [локал_ip_адрес]
для управлением демоном ssh в старой системе инициализации sys.v (мы все равно еще м. к ней обращаться в ubuntu, потому-что современная система инициализации system.d обратно совместима со старой)
перейдем в папку /etc/init.d/ и посмотрим лежащие там скрипты
в частности там есть скрипт с названием ssh
в этой папке лежат все скрипты которые д.возможность управлять запущенными демонами
чтобы классическим способом остановить демон ssh напишем:
/etc/init.d/ssh stop
в современной системе инициализации system.d для этого нужно использовать systemctl:
например узнаем состояние демона:
systemctl status ssh
чтобы отключить службу ssh:
systemctl disable ssh #после чего данная служба при перезапуске системы не будет автоматически стартовать
#удаляет runlevel где ssh должен запускаться и останавливаться, после чего удаляет необходимые линки
поставить службу ntp (ntpd сервер) в автозапуск:
systemctl enable ntpd
в SystemD просмотреть список служб с их статусом:
systemctl list-unit-files

если мы хотим знать какие порты у нас открыты снаружи, узнаем свой внеш. ip-адрес (адрес сет. интерфейса)
nmap 10.0.2.15
покажет:
All 1000 scanned ports on 10.0.2.15 are closed #все порты закрыты
команда lsof (list open files) покажет все открытые ф-лы, а также сетевые соединения (ключ -i)
lsof -i
#покажет тоже, что и netstat но в более подробном виде
COMMAND(комманда)
PID
USER(пол-ль)
FD (file descriptor описание ф-ла и с каким уровнем доступа открыт)
TYPE (тип процесса 'vIP' 'DIR' 'REG')
DEVICE (устройство)
SIZE/OFF (размер)
NODE (TCP/UDP протокол)
NAME (приложение,порт)
часто используется для поиска ф-лов занятых к-то конкретным процессом (ключ -C):
lsof -C dnsmasq
показать службы исп. 53 порт:
lsof -i:53
утилита fuser исп. для поиска процесса, который занимает к-то файл или сокет (обратный порядок lsof)
покажи что происходит по текущему каталогу:
fuser -v .
покажет
каталог, пол-ль, PID, доступ, команда
/home    semaev  805  ..C..   upstart
#уровень доступа ..C.. говорит, что это текущий каталог
кто висит у нас на 53 порту:
fuser 53/tcp -v
покажет:
	ПОЛ-ЛЬ	PID	ДОСТУП	КОМАНДА
53/tcp:	nobody	628	F....	dnsmasq
#уровень доступа F.... говорит, что сокет открыт с доступом на запись
дальше посмотрим, что это за процесс с PID 628:
ps 628
покажет:
PID	TTY	STAT	TIME	COMMAND
628	?	S	0:00	/usr/sbin/dnsmasq --no resolv #т.е. видим что это процесс dnsmasq запущенный с параметрами
--------------------------------------------------------------------------------------------------------------------------

НАПИСАНИЕ ДЕМОНА ДЛЯ "СТАРОЙ" СИСТЕМЫ ИНИЦИАЛИЗАЦИИ SysV
========================================================

мануал по uptime: https://habr.com/post/216827/

данная система инициализации исп. в redhat&centos v.6 и ниже, debian v7 и ниже, ubuntu v.6.10 и ниже
пример на CentOS
напишем скрипт проверяющий загрузку cpu 1раз в 30 сек. и если эта зсгрузка более к-то значения - выдавать сообщение
посмотрим сколько у нас ядер cpu командой:
cat /proc/cpuinfo | grep cores
сделаем вывод последних 5 символов команды uptime:
uptime | tail -c 5
покажет:
0.05
т.к. bash не умеет работать с дробными числами, установим basic calculator
yum install bc
калькулятор принимает входящие параметры:
echo "5 > 3" | bc -l
покажет: 1 (истина)
выдает ответы истина - 1, ложь - 0
создадим скрипт:
vim /opt/checker.sh
отредактируем его:
#!/bin/bash
while true
do
LIMIT=0.02 #установим значение переменной LIMIT
LAST="$(uptime | tail -c 5)" #установим значение переменной LAST (последние сведения о загрузке системы)
if (($(echo "$LAST >= $LIMIT" | bc -l))); then #знак $-говорит о переменной, значение перем. передаем в калькулятор bc, если результат 1 то ...
echo "ALERT at $(date) >> /var/log/checker " #вывод сообщения с датой в лог-файл
fi #закрываем if
sleep 10 #б.выполнять задачу 1 раз в 10сек.
done
сохр,вых
создадим ф-л лога:
sudo tail /var/log/checker
добавляем бит исполнения скрипту:
chmod u+x /opt/cheker.sh
запускаем скрипт
sudo /opt/cheker.sh

создание демона для SysV
зайдем в директорию init directory:
cd /etc/init.d/
здесь создадим ф-л:
vim cheker
отредактируем его:
#!/bin/bash
# chkconfig: 235 20 80 #chkconfig-утилита управляющая демонами, где 235-уровни runlevel где скрипт будет запускаться (4 в redhat не используется), 20-приоритет запуска скрипта, 80-приоритет остановки скрипта 
# description: checking load #описание скрипта
# Source function library. #указываем стандартные библиотеки
. /etc/init.d/functions #путь к библиотекам
#. /lib/lsb/init-functions #путь к библиотекам в deb-системах
case "$1" in #case -позволяет выбирать информацию со стандартного ввода, $1 -первый аргумент, кот-й нам передается
start) #если 1-м аргументом передана ф-я start - тогда
echo "$(date) service checker started" >> /var/log/checker #запишем в лог, во сколько была запущена служба
/opt/checker.sh & #запускаем скрипт в фоновом режиме (знак &)
echo $!>/var/run/checker.pid #значение pid запущенного в фоновом режиме процесса содержится в переменной !, записываем его в ф-л
;; #закрываем 1-е условие, когда послали команду start
stop) #если 1-м аргументом передана ф-я stop - тогда
echo "$(date) service checker stopped" >> /var/log/checker #запишем в лог, во сколько была остановлена служба
kill `cat /var/run/checker.pid` #убиваем процесс pid которого считываем из ф-ла (для kill нужны обратные кавычки чтобы cat отработал и отдал киллу pid)
rm /var/run/checker.pid #удаляем ф-л
;; #закрываем 2-е условие, когда послали команду stop
restart) #если 1-м аргументом передана ф-я restart - тогда
$0 stop #$0 - по умолчанию это переменная с названием текущего скрипта checker.sh
$0 start
;;
#переменная ${0##*/} выдаёт только имя файла
#переменная ${0%/*} выдает путь откуда был запущен скрипт?
status) #если 1-м аргументом передана ф-я status - тогда
if [ -e /var/run/checker.pid ]; then #если существует (-е) ф-л /var/run/checker.pid то...
echo checker is running, pid=$(cat /var/run/checker.pid) #сообщение о запущенном процессе с id процесса
#echo checker is running, pid=`cat /var/run/checker.pid` #аналогичное выполнение команды
else
echo checker is NOT running #сообщение - не запущен
exit 1 #завершаем работу скрипта со статусом 1-ошибка 
fi #закрываем условие if
;; #закрываем условие для case
*) #во всех ост. случаях, если кто-то вводит команду с опечаткой и т.д.
echo "Usage: $0  {start|stop|status|restart}"
esac #закрываем условие case
exit 0 #выходим из скрипта со статусом 0-стандартный
вых,сохр
делаем ф-л исполняемым:
chmod u+x checker
теперь можно работать с ним как со службой
проверим статус:
service checker status
запустим:
service checker start
поставим созданную службу в автозапуск:
chkconfig checker on
посмотрим на каких уровнях runlevel запускается:
chkconfig --list
проверим лог службы:
tail /var/log/checker

УПРАВЛЕНИЕ СЕТЕВЫМИ ОБРАБОТЧИКАМИ (ДЕМОНАМИ)
============================================

Описание xinetd.conf: http://www.linuxrsp.ru/artic/xinetd_conf.html
Если нужно оправить один и тоже запрос на кучу серверов одновременно: http://michael.mindmix.ru/617-818-pssh-i-shmux.zhtml
суперсервер - это процесс (демон), который управляет всеми остальными процессами.
т.е. сам прослушивает все сетевые сокет после чего вызывает демоны, кот-е д. обрабатывать запросы по этим сокетам, если это необходимо
устаревшая версия inetd (inetdemon)
его файл конфигурации находится /etc/initd.conf
он содержит:
имя службы	тип сокета	протокол	опция	пол-ль	что запускать		исполн. ф-л с ключом
ftp 		stream		tcp		nowait	root	/usr/libexec/ftpd	ftpd -l		#б. запущен демон ftp
#с udp используется сокет dgram(datagram)
#с tcp используется сокет stream
#опция nowait чаще исп-ся для tcp
#имя службы д.б. корректным, т.к. согласно этому servicename происходит поиск информации в /etc/services и по этому имени он понимает какой порт прослушивать
в папке /etc/inetd.d б. находиться ф-лы конфигурации для отдельных служб
современная версия супердемона назыв-ся xinetd (extended)
его файл конфигурации находится /etc/xinitd.conf
#по умолчанию содержит одну строчку
includedir /etc/xinetd.d #включить данную директорию
в директории /etc/xinetd.d уже б. находится отдельные настройки для каждого демона
по умолчанию там б. находится настройки служб chargen, daytime, discard, echo, time
посмотрим настройки службы time
откроем ф-л cat /etc/xinetd.d/time
service time #по этому имени службы происходит поиск портов в ф-ле /etc/services
{
	disable		= yes #по умолчанию отключен inetd для этой службы
	type		= INTERNAL #говорит о том, что сервис у нас есть и мы о нем знаем (еще м.б. LISTED если сторонний сервис)
	id		= time-stream #если сервис использует разные протоколы
	socket_type	= stream
	protocol	= tcp
	user		= root
	wait		= no #не ждать
}
{
	disable		= yes
	type		= INTERNAL
	id		= time-dgram
	socket_type	= dgram
	protocol	= udp
	user		= root
	wait		= yes #ждать	

}

в ubuntu по умолчанию выполняется запуск служб через upstart и он сам контролирует весь этот процесс, поэтому демон xinetd уже не нужен
tcp wrapper (tcp обработчики, оборачивают tcp), дают возможность контроля над соединениями
через них даже работают локальные хосты (localhost)
с помощью них м. возвращать комментарии (ответ) хостам к. хотят подключиться, м. добавить запись в лог-ф-л, м. отправить письмо админ-ру
есть 2 ф-ла разрешений и запретов, как и для планировщика cron, это:
/etc/hosts.allow #у разрешений этого ф-ла всегда приоритет перед hosts.deny
#это перечень хостов, кот-м разрешен доступ к нашей системе
#в нем д. указать все разрешения, что в нем указано не будет - будет запрещено
по умолчанию он пустой
можно для примера добавить:
ALL: LOCAL @some_netgroup #всем демонам(ALL) разрешить локальные (LOCAL) соединения от сетевой группы some_netgroup
ALL: .foobar.edu EXCEPT terminalserver.foobar.edu #всем демонам(ALL) разрешить принимать соединения от поддомена .foobar.edu кроме сервера terminalserver.foobar.edu
tftpd: 192.168.0 #демон tftpd может принимать соединения из сети
ф-л /etc/hosts.deny
--------------------------------------------------------------------------------------------------------------------------------------------------------------------

IPTABLES+SQUID+BIND
===================
как блочить https ресурсы: https://imbicile.pp.ru/ubuntu-16-04-prozrachnyj-squid-https/
squid+active directory kerberos: https://interface31.ru/tech_it/2015/06/nastraivaem-squid-dlya-raboty-s-active-directory-chast-2-kerberos-autentifikaciya.html

установим пакеты утилитой apt
apt install bind9 squid3
проверим настройки сет. карт
enp0s3 inet addr: 10.0.1.5 Bcast: 10.0.1.255 Mask: 255.255.255.0 (сет. инт. смотрит в интернет)
настроим 2-ю сет.карту, которая смотрит в локальную сеть
vi /etc/network/interfaces
содержит:
source /etc/network/interfaces.d/*
auto lo
iface lo inet loopback
auto enp0s3
iface enp0s3 inet dhcp
как видим здесь 2-я сет.карта не указана
мы можем посмотреть название неопределившейся сет.карты командой:
ip link
покажет:
1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN mode DEFAULT group default qlen 1
	link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
2: enp0s3: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc pfifo_fast state UP mode DEFAULT group default qlen 1000
	link/ether 08:00:27:e9:4d:0b brd ff:ff:ff:ff:ff:ff
3: enp0s8: <BROADCAST,MULTICAST> mtu 1500 qdisc noop state DOWN mode DEFAULT group default qlen 1000
	link/ether 08:00:27:92:9d:09 brd ff:ff:ff:ff:ff:ff
видим, что сет.карта enp0s8 находится в состоянии DOWN
нам ее нужно вписать в ф-л /etc/network/interfaces
добавим в ф-л:
auto enp0s8
iface enp0s8 inet static
address 192.168.0.10
netmask 255.255.255.0
#шлюз не указываем, т.к. 1 шлюз мы будем получать по dhcp, если мы пропишем 2 шлюза нам нужно б. выставлять метрики
перегружаем сетевую службу:
service networking restart
проверяем командой ifconfig, видим вторая сет.карта появилась с ip-адресом
для того, чтобы ubuntu могла пробрасывать пакеты из одной сети в другую нам нужно разрешить forwarding vIP4 между сетевыми интерфейсами
для этого отредактируем ф-л конфигурации ubuntu:
vi /etc/sysctl.conf
в нем найти и раскомментировать строчку:
net.ipv4.ip_forward=1 # включить forwarding
для того, чтобы этот параметр применился выполним команду:
sysctl --system
теперь выключим встроенный firewall в ubuntu:
ufw disable
#фаервол остановлен и убран из автозапуска
#Firewall stopped and disabled on system startup
посмотрим текущие настройки iptables
iptables -L
добавим правило разрешающее подключение по ssh:
iptables -A INPUT -p tcp --dport ssh -j ACCEPT
потом включим политику DROP для цепочки INPUT (ключ -P policy):
iptables -P INPUT DROP
тоже делаем для цепочки FORWARD:
iptables -P FORWARD DROP
добавим входящее правило разрешающее пинг (ключ -A add добавить, -p для протокола,-j действие):
iptables -A INPUT -p icmp -j ACCEPT
после перезагрузки все правила сотрутся, поэтому сохраним сделанные настройки в ф-л:
iptables-save > /home/semaev/iptables.backup
теперь прокинем пинг от хоста внутри сети 192.168.0.101 до хоста в сети интернет 10.0.1.1
восстановим настройки iptables:
iptables-restore < iptables.backup
добавим правило в цепочку INPUT (ключ -m marker (явным образом) все пакеты с состоянием (state) --state перечисляем состояния)
iptables -A INPUT -m state --state RELATED,ESTABLISHED -j ACCEPT
#RELATED - уже относятся (связанный), ESTABLISHED - установленные соединения (механизм connection tracker -conntrack умеет отслеживать состояние соединения)
делаем такое-же правило для цепочки FORWARD:
iptables -A FORWARD -m state --state RELATED,ESTABLISHED -j ACCEPT
разрешим пинг в сеть интернет:
iptables -A FORWARD -p icmp -j ACCEPT
#когда мы не указываем с какой таблицей мы работаем, по умолчанию б. работать с таблицей FILTER
поэтому аналогично правило можно записать:
iptables -t filter -A FORWARD -p icmp -j ACCEPT
цепочки POSTROUTING нет в стандартной таблице filter, поэтому нам нужно указать таблицу nat в правиле
сделаем маршрутизацию прохождения пакета используя таб-цу nat используя действие masquerade (заменим адрес источника соединения на адрес внешней сет.карты машины линукс(с IPTABLES))
в цепочке POSTROUTING  (для пакетов -s source источником кот-х явл-ся сеть 192.168.0.0/24 или вместо IP сети указать -i interface имя интерфейса enp0s3 )
iptables -t nat -A POSTROUTING -s 192.168.0.0/24 -j MASQUERADE
#т.о. все пакеты  из этой локальной сети их ip-адреса б. заменяться на внешний ip-адрес машины линукс(с IPTABLES) 10.0.1.5
командой iptables -L это правило мы не увидим, т.к. по умолчанию мы работаем с таблицей filter, поэтому нужно написать:
iptables -t nat -L
чтобы посмотреть правила сразу для всех таблиц:
iptables-save
установим пакет iptables-persistent, чтобы каждый раз не восстанавливать настройки iptables после перезагрузки:
apt install iptables-persistent
после установки этого пакета, наши правила сохранились в /etc/iptables/rules.v4
дальше если будем менять правила iptables, нужно б. просто их сохранить в этот ф-л командой iptables-save
#в CentOS можно написать service iptables save и правила сохраняться тоже по этому пути 
чтобы м.б. пинговать из локальной сети узлы в интернете, например ya.ru должен проходить dns-запрос для этого сделаем проброс этих запросов:
iptables -A FORWARD -p tcp -m multiport --ports 53 -s 192.168.0.0/24 -j ACCEPT
iptables -A FORWARD -p udp -m multiport --ports 53 -s 192.168.0.0/24 -j ACCEPT
#ключ -p protocol, multiport - когда указываем несколько портов
чтобы удалить правило в цепочке (-D delete):
iptables -D FORWARD -p udp -m multiport --ports 53 -s 192.168.0.0/24 -j ACCEPT
или указав номер правила в цепочке (считаем сверху) посмотрев командой iptables-save:
iptables -D FORWARD 4
чтобы открывать страницы в интернете нужно разрешить прох. пакетов с протоколом http:
iptables -A FORWARD -p tcp -m multiport --ports 53,80,8080,443,110,25,21 -s 192.168.0.0/24 -j ACCEPT
сохраним изменения в iptables-persistent командой:
netfilter-persistent save
если эта команда не сработает, можно так:
dpkg-reconfigure iptables-persistent

проброс портов во внутрь локальной сети DNAT (если мы хотим чтобы к-то сервис был доступен снаружи)
создадим правило, которое будет пробрасывать по порту 80 извне в локальную сеть:
iptables -t nat -A PREROUTING -i enp0s3 -p tcp -m tcp --dport 80 -j DNAT --to-destination 192.168.0.101
#внешний интерфес enp0s3, если кто-то стучится по протоколу -p tcp -m marker tcp на порт назначения destination port --dport
#то выполнить действие -j DNAT перенаправить --to-destination 192.168.0.101
этого правила недостаточно, потому-что мы перехватываем соединение по порту 80 и пробрасываем в лок.сеть,
но в цепочке FORWARD у нас не разрешен проброс порта 80 извне, а разрешет только из лок. сети,
поэтому добавим проброс порта в цепочку FORWARD:
iptables -A FORWARD -i enp0s3 -p tcp --dport 80 -j ACCEPT
также пробросим соединение по 81 порту, но с трансляцией на порт 80:
iptables -t nat -A PREROUTING -i enp0s3 -p tcp -m tcp --dport 81 -j DNAT --to-destination 192.168.0.102:80
в цепочку FORWARD уже правило добавлять не нужно, т.к. в цепочке PREROUTING уже сразу порт 81 б. меняться на порт 80
и в цепочку FORWARD уже б. попадать пакеты с портом назначения 80

Настраиваем bind для простейшего приема и переадрессации dns-запросов (DNS-FORWARDING)
основной конф. файл bind находится: /etc/bind/named.conf.options
в нем разкомментируем и допишем:
forwarders {
	10.0.1.1 #вышестоящий dns, например адрес шлюза, маршрутизатора
};
#скажем чтобы сервер все запросы не пытался сам обработать, а переадресовывал (в первую очередь)
forward first;
#по какому порту ему прослушивать запросы, но по внутреннему интерфейсу 192.168.0.10, чтобы из интернета никто не мог слать запросы
#и через него узнавать что у нас в локалке
listen-on port 53 {192.168.0.10;};
#отключаем dnssec
#dnssec-validation auto;
после нам нужно настроить rndc ключи командой:
rndc-confgen -r /dev/urandom #/dev/urandom - устройство, кот-е поможет сгенерировать ключ
часть вывода нужно сохранить в rndc.conf:
#Start of rndc.conf
key "rndc-key" {
	algorithm hmac-md5;
	secret "NGLaqUEqZ69JxB1p0SO/lg==";
};
options {
	default-key "rndc-key";
	default-server 127.0.0.1;
	default-port 953;
};
#End of rndc.conf
часть вывода которую нужно сохранить в named.conf:
#Use with the following in named.conf, adjusting the allow list as needed:
#key "rndc-key" {
#	algorithm hmac-md5;
#	secret "NGLaqUEqZ69JxB1p0SO/lg==";
#};
#controls {
#	inet 127.0.0.1 port 953 #потом нужно разрешить в iptables этот порт
#		allow { 127.0.0.1; } keys { "rndc-key"; };
#};
#End of named.conf
создаем ф-л /etc/bind/rndc.conf и вставляем в него нужный кусок
#выделяем кусок нажимаем enter, открываем ф-л редактором и правой кнопкой мыши вставляем
создаем ф-л /etc/bind/named.conf и вставляем в него нужный кусок и раскомментируем
разрешим в iptables порт 953 для петлевого ин-фейса 127.0.0.1:
iptables -A INPUT -i lo -j ACCEPT
можно перезапустить сервер bind9:
service bind9 restart
проверим как проверяются dns-имена командой nslookup
nslookup google.com
теперь на машине внутри сети прописываем адрес dns-сервера этой машины Linux, адрес б. одинаковый со шлюзом
страница интернета не откроется, т.к. в цепочке INPUT у iptables не разрешен 53 порт, а также удалим правило
с пробросом dns-запросов:
iptables -A INPUT -p udp -m multiport --ports 53 -s 192.168.0.0/24 -j ACCEPT
iptables -A INPUT -p tcp -m multiport --ports 53 -s 192.168.0.0/24 -j ACCEPT
iptables -D FORWARD -p udp -m multiport --ports 53 -s 192.168.0.0/24 -j ACCEPT
из второго правила выдерним 53 порт, для этого сначала его удалим, а потом добавим без 53 порта:
iptables -D FORWARD -p tcp -m multiport --ports 53,80,8080,443,110,25,21 -s 192.168.0.0/24 -j ACCEPT
iptables -A FORWARD -p tcp -m multiport --ports 80,8080,443,110,25,21 -s 192.168.0.0/24 -j ACCEPT
после чего сохраняем правила iptables:
dpkg-reconfigure iptables-persistent
<Yes>

настройка прокси squid
посмотрим версию squid, запустим исполняемый ф-л с ключом -v:
/usr/sbin/squid -v
показал версию:
Squid Cache: Version 3.5.12
сделаем бэкап конф. файла squid:
cp /etc/squid/squid.conf /etc/squid/squid.conf.backup
отредактируем его:
vi /etc/squid/squid.conf
сделаем поиск слова localnet (/localnet) #означает лок.сеть
раскомментируем строчку:
acl localnet src 192.168.0.0/24 #указываем адрес лок.сети
ниже указано:
acl SSL_ports port 443 #safe-ports (безопасные порты) считаем порты перечисленные
acl Safe_ports port 80
acl Safe_ports port 21
acl Safe_ports port 443
acl Safe_ports port 70
acl Safe_ports port 210
acl Safe_ports port 1025-65535
acl Safe_ports port 280
ищем строчку http_access (кому разрешается доступ)
http_access deny !Safe_ports #политика http_access запрещает все, кроме безопасных портов
http_access deny CONNECT !SSL_ports #запрещает подключение по всем портам, кроме SSL
http_access allow localhost manager #разрешается доступ к кэш-менеджеру только лок.хосту
http_access deny manager #всем остальным доступ запрещен
разкомментируем строчку:
http_access allow localnet #разрешаем доступ из лок.сети
ищем строчку http_port
т.к. 2 ин-фейса, укажем по какому и-фейсу б.прослушивать порт:
http_port 192.168.0.10:3128 intercept
сейчас по умолчанию сейчас прокси-сервер б. являться непрозрачным, чтобы ничего не указывать в браузерах - сделаем его прозрачным
для этого добавим слово intercept
можно также сделать один порт для непрозрачного прокси, для https
сохр.,выходим
перезапускаем службу squid
service squid restart #загрузка до нескольких минут
теперь удалим правило проброса портов в iptables:
iptables -D FORWARD -p tcp -m multiport --ports 80,8080,443,110,25,21 -s 192.168.0.0/24 -j ACCEPT
создадим заново, но без web портов (слушаем порты 110,25,21):
iptables -D FORWARD -p tcp -m multiport --ports 110,25,21 -s 192.168.0.0/24 -j ACCEPT
добавим в цепочку INPUT порт прокси 3128: 
iptables -A INPUT -s 192.168.0.0/24 -p tcp -m multiport --ports 3128 -j ACCEPT
т.к. клиенты не знают, что им нужно обращаться по порту 3128, добавим:
iptables -t nat -A PREROUTING -s 192.168.0.0/24 -p tcp -m multiport --dports 80,8080 -j REDIRECT --to-ports 3128
#действие -j перенаправлять REDIRECT на порт --to-ports 3128

настроим squid для работы с https (проксировать https соединения)
проверим открытые порты:
netstat -ntulp
т.к. стандартный squid не умеет работать с ssl, нам нужно его скомпилировать для работы с ssl
для этого вначале удалим текущий скрипт:
apt remove squid
соберем squid из исходников
для начала нам нужно убедиться, что включены репозитории для исходников
откроем информацию о репозиториях (в ubuntu):
vim /etc/apt/sources.list
в нем есть много строчек, которые содержат (начинаются) с deb-src, разкомментируем их
обновим информацию о репозиториях:
apt-get update
для сборки squid нам понадобятся пакеты:
openssl - для работы с ssl и б.генерировать сертификаты
devscripts - скрипты которые помогают при сборке пакетов
build-essential - все пакеты необходимые для сборки пакетов
dpkg-dev - содержит инструменты для распаковки, построения, закачки пакетов
libssl-dev - библиотека для сборки
apt install openssl devscripts build-essential dpkg-dev libssl-dev
подкачаем зависимости, которые б. использоваться при сборке нашего squid3:
apt-get build-dep squid3
#он из пакета dpkg-dev
качаем исходник squid3:
apt-get source squid3
в ходе скачивания вышла ошибка:
W:Невозможно сбросить права для скачивания, так как файл "squid3_3.5.12-lubuntu7.4.dsc" недоступен для пользователя "_apt". - pkgAcquire::Run (13: Отказано в доступе)
Это вышло потому-что закачка идет в папку пол-ля
изменим права на этот ф-л:
chmod 777 squid3 3.5.12-lubuntu7.4.dsc
и снова запускаем скачивание:
apt-get source squid3
установим tree, чтобы видеть дерево ф-лов:
apt install tree
покажет дерево директорий
нас интересует директория из папки пользователя squid3-3.5.12 в ней находится все, что нужно для сборки пакетов
откроем ф-л ~/squid3-3.5.12/debian/rules (правила сборки пакета)
допишем в секции DEB_CONFIGURE_EXTRA_FLAGS
после флага --with-large-files \
	--enable-ssl \
	--enable-ssl-crtd \ #сертификат-демон
	--with-openssl \ #скомпилировать пакет с openssl
сохр.,выходим
выполним сборку пакетов из текущей (~/squid3-3.5.12/)директории (ключ -d):
dpkg-buildpackage -d
поднимемся на уровень выше cd ..
и видим, что появились необходимые нам deb-пакеты
установим (ключ -i) все пакеты *.deb:
dpkg -i *.deb
могут выходить вопросы по зависимостям:
Файл настройки "/etc/squid/squid.conf"
==> Изменен с момента установки (вами или сценарием).
==> Автор пакета предоставил обновленную версию.
Что нужно сделать? Есть след.варианты:
Y или I: установить версию, предлагаемую сопровождающим пакета
N или O: оставить установленную на данный момент версию
D: показать различия между версиями
Z: запустить оболочку командной строки для проверки ситуации
По умолчанию сохр.текущая версия ф-ла настройки.
*** squid.conf (Y/I/N/O/D/Z)[по умолчанию N]? y
показал
При обработке след.пакетов произошли ошибки:
squid3_3.5.12-lubuntu7.4_all.deb
squid-cgi
чтобы он установил эти зависимости запустим (ключ -f fix починить/исправить):
apt-get install -f
он подкачает зависимости, после чего снова выполняем команду:
dpkg -i *.deb
после выполнения (возможно несколько прогонов) установки проверим версию squid:
squid -v
покажет:
Squid Cache: Version 3.5.12
configure options: среди флагов покажет наши флаги
--enable-ssl --enable-ssl-crtd --with-openssl
перейдем в директорию squid и сгенерируем необходимые сертификаты:
cd /etc/squid/
выполним команду:
#openssl req -new -newkey rsa:1024 -days 365 -nodes -x509 -keycut squidCA.pem -out squidCA.pem #возможно ошибка
openssl req -new -newkey rsa:1024 -days 365 -nodes -x509 -keyout squidCA.key -out squidCA.pem
Запросит базовые вещи для создания сертификата: страну,город...
сделаем бэкап ф-ла конфиг. squid:
cp squid.conf squid.conf.backup
выберем все не коментированные строчки (которые не начинаются с # и $ ) и направим содержимое в squid.conf
cat squid.conf.backup | grep -v "^#" | grep -v "^$" > squid.conf
получим красивый рабочий squid.conf, добавим в ф-л:
acl localnet src 192.168.0.0/24 #адрес лок.сети
http_access allow localnet #разрешим доступ из лок.сети
http_port 192.168.0.10:3128 intercept #прозрачный прокси
https_port 192.168.0.10:3129 intercept ssl-bump cert=/etc/squid/squidCA.pem
ssl_bump peek all
ssl_bump splice all
sslcrtd_program /usr/lib/squid/ssl_crtd -s /var/lib/ssl_db -M 4MB
сохр.,выходим
проверим конф.файл:
squid -k pars
переконфигурируем squid согласно новых настроек:
squid -k reconfigure
проверим прослушиваемые лок.порты:
netstat -ntulp
должны присутствовать:
Proto	Recv-Q	Send-Q	Local address		Foreign address 	State	PID/Program name
tcp	0	0	192.168.0.10:3128	0.0.0.0:*		Listen	600/(squid-l)
tcp	0	0	192.168.0.10:3129	0.0.0.0:*		Listen	600/(squid-l)
в iptables добавим в цепочку INPUT порт 3129:
iptables -A INPUT -s 192.168.0.0/24 -p tcp -m multiport --ports 3129 -j ACCEPT 
а также в таблице nat в цепочке PREROUTING переадресацию пакетов по порту 443 на порт 3129:
iptables -t nat -A PREROUTING -s 192.168.0.0/24 -p tcp -m multiport --dports 443 -j REDIRECT --to-ports 3129
------------------------------------------------------------------------------------------------------------

СЕРВЕР PUPPET
=============
имя нашего хоста devops
устанавливаем службу времени ntp:
apt-get -y install ntp
настроем конф. ф-л:
/etc/ntp.conf
укажем пул серверов точного времени
перезапускаем службу ntp:
service ntp restart
временно отключим фаервол:
ufw disable
скачаем информацию о репозитории, переходим в домашнюю папку и выполняем команду wget для скачивания дистрибутива:
cd ~ && wget https://apt.puppetlabs.com/puppetlabs-release-pcl-trusty.deb
устанавливаем скаченный пакет (устанавливаем инф-ю о репозиториях):
dpkg -i puppetlabs-release-pcl-trusty.deb
обновим информацию о репозиториях
apt-get update
установим puppetserver:
apt-get install puppetserver
посмотрим настройки процесса puppetserver:
/etc/default/puppetserver
в нем параметры:
JAVA_ARGS="-Xms2g -Xmx2g -XX:MaxPermSize=256m" #-Xms2g(сколько оперативки съест при старте) -Xmx2g(до скольки м.увеличивать) лучше исп. одинаковые параметры (изменим под свои требования)
#-XX:MaxPermSize=256m - кол-во памяти в кот-й хранятся явовские классы
теперь настроим конф.файл самого puppet:
/etc/puppetlabs/puppet/puppet.conf
добавим в файл информацию об агенте:
[main]
certname = devops #имя сертификата для нашей машины devops
server = devops #сервер с которым машина devops б. связываться
#в дальнейшем, когда б. подключать к-то узлы в certname б.указывать имя сертификата, servername останется неизменным
прежде чем запускать puppetmaster посмотрем сколько ОЗУ ест сервер изначально:
free -m
запускаем службу puppetserver:
service puppetserver start
проверим ОЗУ, покажет, что 1Гб он занял
теперь puppetserver поставить в автозагрузку
для этого воспользуемся его командой:
/opt/puppetlabs/bin/puppet resource service puppetserver ensure=running enable=true
где:
/opt/puppetlabs/bin/puppet - путь к программе
resource - команда, кот-я говорит, что service(служба) puppetserver ensure=running(д.б. включена) enable=true(поставлена в автозапуск)
установим puppet-agent:
apt-get install puppet-agent (он уже установился с puppetserver)
аналогичная команда, чтобы запустить агент и поставить его в автозапуск:
/opt/puppetlabs/bin/puppet resource service puppet ensure=running enable=true
посмотрим сертификаты, какие у нас есть:
/opt/puppetlabs/bin/puppet cert list #д. показать запрашиваемые подтверждения сертификаты, если к нам постучалисб к-либо машины, то мы д.б. их одобритиь или отклонить
пока ничего не показывает
/opt/puppetlabs/bin/puppet cert list --all
покажет локальный сертификат машины:
+"devops" (SHA256) 81:45:D1:E7... (alt names: "DNS:puppet", "DNS:devops")
запустим puppet-agent для синхронизации с puppetserver:
/opt/puppetlabs/bin/puppet agent --test

установим агент на клиентские машины
настроим на клиентской машине точное время, далее
зайдем в ф-л /etc/hosts на клиентской ubuntu (ubsrv) и добавим в него:
10.0.1.6	devops
для debian-подобных ОС
заходим на сайт apt.puppetlabs.com
ищем пакет с репозиторием для своей ОС и скачиваем его командой:
wget https://apt.puppetlabs.com/puppetlabs-release-pcl-xenial.deb
скачивает его в домашнюю папку пол-ля
теперь нужно установить инф-ю о репозиториях:
dpkg -i puppetlabs-release-pcl-xenial.deb
обновим инф-ю о репозиториях:
apt-get update
устанавливаем puppet-agent:
apt-get install puppet-agent
изменим его ф-л конфигурации:
vim /etc/puppetlabs/puppet/puppet.conf
добавим в него информацию об имени агента:
[agent]
server = devops
сохр,вых
запускаем puppet-agent:
/opt/puppetlabs/bin/puppet resource service puppet ensure=running enable=true
идем на puppet-server devops
узнаем версию агента сервера:
puppet --version
покажи нам все сертификаты:
/opt/puppetlabs/bin/puppet cert list
покажет нам сертификат машины ubsrv с агентом:
"ubsrv" (SHA256) 43:7C:E1....
для того, чтобы его подписать:
/opt/puppetlabs/bin/puppet cert sign ubsrv
или
/opt/puppetlabs/bin/puppet cert sign --all #подпишет сертификаты всех машин
возвращаеемся на ubsrv
делаем тест, который проверяет связь с сервером
/opt/puppetlabs/bin/puppet agent --test
идем на машину с CentOS
на сайте docs.puppet.com/puppet/latest/install_linux.htm находим инф. о репозиториях, ссылку на пакет для установщиков yum
yum.puppetlabs.com
установим wget
yum install wget
скачиваем информацию о репозиториях:
wget https://yum.puppetlabs.com/puppetlabs-release-pcl-el-5.noarch.rpm
напишет
...
Saving to: 'puppetlabs-release-pcl-el-5.noarch.rpm'
установим данную информацию:
rpm -Uvh puppetlabs-release-pcl-el-5.noarch.rpm
установим puppet-agent:
yum install puppet-agent
редактируем ф-л конфигурации агента:
vim /etc/puppetlabs/puppet/puppet.conf
добавим в него информацию об имени агента:
[agent]
server = devops
сохр,вых   
добавим в hosts информацю о адресе сервера
(исходим из того, что у нас нет dns-сервера)
10.0.1.6	devops
самим паппетом запускает службу puppet-agent:
/opt/puppetlabs/bin/puppet resource service puppet ensure=running enable=true
возвращаемся на сервер devops и смотрим сертификаты
/opt/puppetlabs/bin/puppet cert list
видим сертификат машины cnt3 с агентом:
"cnt3" (SHA256) 43:7C:E1....
подписываем сертификат
/opt/puppetlabs/bin/puppet cert sign --all
возвращаемся на CentOS и тестируем подключение:
/opt/puppetlabs/bin/puppet agent --test

мануал по серверу: https://puppet.com/docs/puppetserver/2.7/index.html
по средам: https://puppet.com/docs/puppet/4.8/environments_creating.html
по ресурсу типа "пакет": https://puppet.com/docs/puppet/5.5/types/package.html
по файлу конфигурации агента: https://puppet.com/docs/puppet/5.5/configuration.html

создадим тестовую среду с тестовым сценарием
создадим манифест со сценарием для установки пакетов на клиентах
идем на сервер devops
узнаем версию агента:
puppet --version
узнаем версию сервера:
puppetserver --version
откроем ф-л конфигурации puppet-сервера:
/etc/puppetlabs/puppet/puppet.conf
в нем:
смотрим параметр
codedir = /etc/puppetlabs/code
переходим по этому пути:
там есть 3 подпапки, нас интересует environments, заходим туда
там лежит одна попка среды production, с ней не будем работать, а создадим тестовую
скопируем рекурсивно папку production в папку test:
cp -R production/ test
просмотрим папку test при помощи tree, но вначале установим его:
apt-get install tree
смотрим текущую директорию test при помощи tree:
tree
переименуем environment.conf в test.conf:
mv environment.conf test.conf
в этом ф-ле мы м. назначать отдельные параметры, которые б. переписывать глубже параметры указанные в манифесте
перейдем в папку с манифестами:
cd /etc/puppetlabs/code/environments/test/manifests
создадим манифест (должен оканчиваться на .pp):
vim test.pp
запишем в него:
package { 'tree': #пакет tree
ensure => installed #ensure(находиться в состоянии) installed (установить)
}
#б.говорить узлам перейти в такое состояние, при котором пакет "tree" будет установлен
т.о в манифестах паппита мы описываем желательное состояние системы и все узлы к этому желательному состоянию себя приводят
идем на ubuntu
здесь уже есть базовый манифест паппета, зайдем в конф. файл:
vi /etc/puppetlabs/puppet/puppet.conf
добавим:
environment = test #что среда теперь не environment, а test
runinterval = 1h #агенты забирают с puppet-server 1 раз в час
сразу пытаемся эти изменения применить (синхронизируемся с сервером):
/opt/puppetlabs/bin/puppet agent --test
покажет:
...
Notice: /Stage[main]/Main/Package[tree]/ensure: created
Notice: Applied catalog in 3.95 seconds
#пакет установлен
тоже самое делаем на машине CentOS

управление польз-лями при помощи puppet
на сервере puppet поменяем на более корректное название созданного нами манифеста:
/etc/puppetlabs/code/environments/test/manifests/test.pp на site.pp
отредактируем данный пакет (создание базового пол-ля) и дабавим в нем:
user { 'engin': #имя ресурса создаваемого пол-ля, б. виден в логах puppet 
name => 'engineer', #имя пол-ля
home => '/home/engineer', #домашняя папка пол-ля
managehome => true, #создать дом. папку
shell => '/bin/bash' #оболочка по умолчанию
ensure => present, #чтобы пол-ль появился
password => '12345',
groups => [sudo, wheel], #присутсвие пол-ля в группах
}
переходим на клиентский ubuntu
/opt/puppetlabs/bin/puppet agent --test
выходит ошибка, об отсутствии у клиента группы wheel (на убунте ее нет)
поэтому переделываем скрипт, приводим к виду:
node 'ubsrv' { #имя хоста, имеет значение имя сертификата (м.посмотреть командой /opt/puppetlabs/bin/puppet cert list --all)
	user { 'engin':
	name => 'engineer',
	home => '/home/engineer',
	managehome => true,
	shell => '/bin/bash',
	ensure => present,
	password => '12345',
	groups => sudo,
	}
}
node 'cnt3' {
	user { 'engin':
	name => 'engineer',
	home => '/home/engineer',
	managehome => true,
	shell => '/bin/bash',
	ensure => present,
	password => '12345',
	groups => wheel,
	}
}
чтобы не прописывать открытый пароль восп-ся утилитой mkpasswd (создает хэши паролей)
для ее установки ставим пакет whois
apt-get install whois
запускаем mkpasswd и набираем пароль, она его хэширует, копируем созданный хэш в конфиг и вставляем вместо пароля
password => 'fk4h46IKSuJbs',
#аналог  " mkpasswd "   for CENTOS7 openssl passwd -1
запускаем  /opt/puppetlabs/bin/puppet agent --test
открываем ф-л /etc/passwd и видим, действительно пол-ль добавился
проверяем входит ли он в группу sudo:
cat /etc/group | grep sudo
тоже проводим на машине CentOS
#Что писать в password => '..' зависит от целевой ОС.
#Если это windows, то открытым текстом:
#password => '12345'
#Если Linux то только хэш.
#Тип хэша пароля зависит от системы (в большенстве Linux и других Unix-like системах это SHA-512)
#Убедиться в этом можно посмотрев /etc/shadow если хэш начинается с $6 то это SHA-512, $5 - SHA-256, $1 - MD5. У меня, например, выглядит так
#root:$6$vxvlL31...
#Если всё таки нужно в манифесте (для *nix) хранить пароль в открытом виде то можно сделать так:
#user { 'user':
#    password => generate('/bin/bash', '-c', "mkpasswd -m sha-512 '12345' | tr -d '\n'"),
#}
#(tr удаляет перевод строки)

управление ф-лами в puppet
задача пробросить профиль bash на клиентские машины
настроим конфигурацию файл-сервера на puppet server для управления распределения ф-лов по сети 
перейдем в директорию /etc/puppetlabs/puppet и здесь создадим ф-л fileserver.conf, кот-ый б. отвечать за настройки файл.сервера
если в этой папке существует ф-л fileserver.conf, то сервер считается настроенным
отредактируем его
[files]
path /etc/puppetlabs/code/files #директория, где б. находиться ф-лы
allow * #разрешить всем доступ
создадим директорию для ф-лов среды test:
mkdir /etc/puppetlabs/code/files/test
создадим в этой папке ф-л конфигурации bash

sudo vim .bashrc
#managed by puppet	(это правило хорошего тона, говорит, что ф-л управляется puppet и все изменения б. стерты при след. синхронизации с puppet server)
#ком. tput управляет цветом вывода setaf - установить цвет текста 2(зеленый) sgr 0 - вернуть цвет background на 0 - белый
echo $(tput setaf 2) "Hello!" $(tput sgr 0)
echo "Точное время: $(date)"
echo "Место на дисках:"
df -h | sed -n'/^\/dev/p' #показать только те строки которые начинаются с /dev их покажи -p print
#Также чтобы не экранировать слеши, можно использовать другой разделитель (в примере нижнее подчеркивание).
#Для этого команду нужно начать с обратного слеша: df -h | sed -n '\_^/dev_p'?
echo "Имя хоста: $(tput setaf 3)$(hostname -f)$(tput sgr 0)"
сохр, выходим
открываем ф-л манифеста:
/etc/puppetlabs/code/environments/test/manifests/site.pp
добавим секцию:
file { 'bashrc':
ensure => file, #проверяем, что ф-л присутствует в системе
path => '/home/engineer/.bashrc',
source => 'puppet:///files/test/.bashrc', #источник ф-ла, вначале указываем, что есть puppet server/имя_секции/путь_к_ф-лу(test/.bashrc)
#т.к. по умолчанию puppet синхронизируется от имени пол-ля root, поэтому в конечной системе необходимо задать владельца создаваемого ф-ла:
owner => 'engineer',
group => 'engineer', #группа владельца
mode => '0644', #режим доступа к ф-лу
}
сохр,выходим
переходим в CentOS, делаем синхронизацию с puppet server
чтобы проверить, что профиль применился подменяем юзера на engineer:
su engineer

вопрос:
Не получается удалять пакеты через ресурс package. В манифесте есть:
package { 'nginx':
 ensure => 'purged',
}
ответ:
Удаление пакета не факт что приведет к остановке демона. НУжно остановить демон, убрать его из автозапуска, а потом удалять пакет, если хочется?
------------------------------------------------------------------------------------------------------------------------------------------------

СБОРКА ЯДРА LINUX
=================
https://habr.com/post/199490/
https://habr.com/post/211751/
на примере CentOS

узнаем версию linux:
cat /etc/*release*
узнаем версию ядра Lnux:
uname -r
Необходимо скачать ядро, для этого перходим на сайт kernel.org
скачиваем ссылку последнего стабильного ядра "Latest Stable Kernel"
перейдем в папку /usr/src (создадим для работы с исходниками)
установим базовые программы:
yum install wget top vim
скачиваем ссылку с пом. команды wget:
wget https://cdn.kernel.org/pub/linux/kernel/v4.x/linux-4.19.12.tar.xz
в тек. директорию скачивается ф-л linux-4.19.12.tar.xz
разархивируем его
(ключи: J-работает с архивами xzip, x-extract извлечь, v-verbose показывать, f-file):
tar -Jxvf linux-4.19.12.tar.xz
в текущую директорию распаковалась папка linux-4.19.12
удаляем исходный архив:
rm -rf linux-4.19.12.tar.xz
Для удобства работы создадим ссылку с именем Linux, на папку которую мы распаковали:
ln -s linux-4.19.12/ Linux
Проверим создание ссылки:
ls -la
переходим по этой ссылке:
cd Linux
и видим, что мы находимся в этой папке с распакованным ядром:
pwd
/usr/src/Linux
ls
для сборки нам нужно установить группу (в yum ключ - groupinstall) пакетов "Development Tools" (инструмент разработки)
yum groupinstall "Development Tools"
раньше данного пакета хватало, но теперь дополнительно нужно поставить еще пакеты
ncurses-devel - библиотека позволяющая управлять вводом/выводом на экран
yum install ncurses-devel
или можно поставить еще графический фреймворк (если есть графическая среда X) позволяющий собирать ядро в режиме диалога и галочек:
yum install qt3-devel
в процессе сборки м. выходить сообщения, что не хватает к-либо инструментов
забежим вперед и поставим необходимые (hmaccalc-калькулятор для вычисления hmac-кодов, zlib-devel-библиотека для работы с архивами gzip,
elfutils-libelf-devel-библиотека для работы с elf-файлами, binutils-devel-утилита для работы с прогр.кодом):
yum install hmaccalc zlib-devel binutils-devel elfutils-libelf-devel
почистим все утилитой make:
make mrproper
конфигурируем будущее ядро:
make menuconfig
#откроется граф. меню в котором б.выбирать из чего б. состоять наше ядро
#напр-р исключим из ядра звуковую карту
#для этого зайдем в Device drivers(становимся на него и нажимаем enter)
#в конце находим <M> Sound card support ---> (<M>-поддержка звук.карт доступна как модуль)
#выделив нажимаем пробел - появится * - говорит о том что это теперь будет модуль, который встроен в ядро
#если еще раз нажать пробел, то * исчезнет и не будет ничего, это говорит о том что драйвера б. исключены из ядра 
#Т.е. можно поисключать все лишнее.
#Перейдем на уровень выше, для этого выберем кнопку <Exit> и нажмем enter
#Выберем File systems ---> нажимаем enter (выбрана кнопка по умолчанию <Select>)
#Исключим из поддержки файловую систему XFS filesystem support, GFS2 filesystem support
#После внесенных изменений сохраняем конфигурацию. Выбираем кнопку <Save>
#По умолчанию это б.файл .config в текущей директории. Говорит, что ф-л сохранился
#Выираем <Exit> и <Exit>, т.е. поднимаемся на 2 уровня выше и <Exit> закрываем приложение
посмотрим созданный ф-л:
less .config
выходим буквой q
если мы повыбирали что-то новое, чего по умолчанию не было выбрано нужно посмотреть какие есть зависимости:
#если эти зависимости действительно есть - их нужно подгрузить
make dep
написал:
Makefile:595: include/config/auto.conf: Нет такого файла или каталога
HOSTCC script/kconfig/conf.o
HOSTLD script/kconfig/conf
script/kconfig/conf --syncconfig Kconfig
make: *** Нет правила для сборки цели 'dep'. Останов.
показало что никаких зависимостей -нет
можем начать собирать ядро:
make bzImage
...
/bin/sh: bc: команда не найдена
make[1]: ***[include/generated/timeconst.h] Ошибка 1
make: *** [prepare0] Ошибка 2
#не хватает калькулятора bc
установим калькулятор и библиотеку для работы с ssl (предвидя будущую ошибку):
yum install bc openssl-devel
и снова запускаем make bzImage
в итоге собралось ядро, написал:
Setup is 16860 bytes (padded to 16896).
System is 7557 kB
CRC dcb43b1e
Kernel: arch/x86/boot/bzImage is ready (#1)
проверяем там ли оно:
ls arch/x86/boot/
теперь нам нужно собрать модули, б. собираться в р-не 1 часа, в случае если в ходе сборки
разорвется связь по ssh - поставим утилиту screen и запустим в этой утилите
yum install screen
запускаем ее
screen
и делаем сборку модулей:
make modules
чтобы выйти из screen нажимаем ctrl+A затем D (deattach-отсоединиться)
проверим состояние:
screen ls
покажет
[screen is terminating]
подключимся к последнему скрину:
screen -x
если ssh-сессия прервется м. зайти в root и подсоединиться в screen
иногда прерывалось перезапускали заново make modules
закончил,написал:
MODPOST 2225 modules
переложим созданные модули в директорию (по умолчанию корневая директория /libmodules):
make modules_install
установим ядро в нашу текущую систему:
make install
посмотрим загрузчик:
cat /boot/grub2/grub.cfg
посмотрим строки содержащие menuentry
cat /boot/grub2/grub.cfg | grep menuentry
видим что ссылка на запуск нашего ядра указана первой в списке
для того чтобы она грузилась по умолчанию изменяем строку в загрузчике:
vim /etc/default/grub
GRUB_DEFAULT=saved #последнее сохраненное значение
исправим на:
GRUB_DEFAULT=0 #т.е. загружалось первое значение
пересоздаем конфиг grub2 (ключ o-output в какой файл):
grub2-mkconfig -o /boot/grub2/grub.cfg
смотрим какое у нас ядро:
uname -r
3.10.0-957.1.3.el7.x86_64
перезагружаем машину
reboot
смотрим какое у нас ядро:
uname -r
4.19.12







